---
title: "Research Gap Matrix"
category: "Overview"
source_url: "https://github.com/example/llmattacks"
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

| attack_type | risk_id | source | covered | folder |
|-------------|---------|--------|---------|--------|
| Prompt Injection | LLM01 | OWASP LLM Top 10 | ❌ | - |
| Insecure Output Handling | LLM02 | OWASP LLM Top 10 | ❌ | - |
| Training Data Poisoning | LLM03 | OWASP LLM Top 10 | ❌ | - |
| Model Denial of Service | LLM04 | OWASP LLM Top 10 | ❌ | - |
| Supply Chain Vulnerabilities | LLM05 | OWASP LLM Top 10 | ❌ | - |
| Sensitive Information Disclosure | LLM06 | OWASP LLM Top 10 | ❌ | - |
| Insecure Plugin Design | LLM07 | OWASP LLM Top 10 | ❌ | - |
| Excessive Agency | LLM08 | OWASP LLM Top 10 | ❌ | - |
| Overreliance | LLM09 | OWASP LLM Top 10 | ❌ | - |
| Model Theft | LLM10 | OWASP LLM Top 10 | ❌ | - |
| Indirect Prompt Injection | HL-INDIRECT | HiddenLayer | ❌ | - |
| TokenBreak | HL-TOKENBREAK | HiddenLayer | ❌ | - |
| Homoglyph Obfuscation | HL-HOMOGLYPH | HiddenLayer | ❌ | - |
| Many-shot Jailbreaking | LLM01 | [Anthropic Research](https://www.anthropic.com/research/many-shot-jailbreaking); [Guardian report](https://www.theguardian.com/technology/2024/apr/03/many-shot-jailbreaking-ai-artificial-intelligence-safety-features-bypass) | ❌ | jailbreaking/many_shot |

