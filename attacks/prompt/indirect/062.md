---
attack_type: indirect_pi
source_url: http://arxiv.org/abs/2309.11751
---

[2309.11751] How Robust is Google's Bard to Adversarial Image Attacks?





























  



[Skip to main content](#content)


[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)

We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.
[Donate](https://info.arxiv.org/about/donate.html)

[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/) > [cs](/list/cs/recent) > arXiv:2309.11751

[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)

All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text

Search

[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)

[![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)

open search

GO

open navigation menu

## quick links

* [Login](https://arxiv.org/login)
* [Help Pages](https://info.arxiv.org/help)
* [About](https://info.arxiv.org/about)



# Computer Science > Computer Vision and Pattern Recognition

**arXiv:2309.11751** (cs)

[Submitted on 21 Sep 2023 ([v1](https://arxiv.org/abs/2309.11751v1)), last revised 14 Oct 2023 (this version, v2)]

# Title:How Robust is Google's Bard to Adversarial Image Attacks?

Authors:[Yinpeng Dong](https://arxiv.org/search/cs?searchtype=author&query=Dong,+Y), [Huanran Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+H), [Jiawei Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+J), [Zhengwei Fang](https://arxiv.org/search/cs?searchtype=author&query=Fang,+Z), [Xiao Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+X), [Yichi Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+Y), [Yu Tian](https://arxiv.org/search/cs?searchtype=author&query=Tian,+Y), [Hang Su](https://arxiv.org/search/cs?searchtype=author&query=Su,+H), [Jun Zhu](https://arxiv.org/search/cs?searchtype=author&query=Zhu,+J)

View a PDF of the paper titled How Robust is Google's Bard to Adversarial Image Attacks?, by Yinpeng Dong and 8 other authors

[View PDF](/pdf/2309.11751)
> Abstract:Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at [this https URL](https://github.com/thu-ml/Attack-Bard).
>   
> Update: GPT-4V is available at October 2023. We further evaluate its robustness under the same set of adversarial examples, achieving a 45% attack success rate.

|  |  |
| --- | --- |
| Comments: | Technical report |
| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG) |
| Cite as: | [arXiv:2309.11751](https://arxiv.org/abs/2309.11751) [cs.CV] |
|  | (or  [arXiv:2309.11751v2](https://arxiv.org/abs/2309.11751v2) [cs.CV] for this version) |
|  | <https://doi.org/10.48550/arXiv.2309.11751> Focus to learn more  arXiv-issued DOI via DataCite |

## Submission history

From: Yinpeng Dong [[view email](/show-email/ec65d530/2309.11751)]

Full-text links:

## Access Paper:

View a PDF of the paper titled How Robust is Google's Bard to Adversarial Image Attacks?, by Yinpeng Dong and 8 other authors

* [View PDF](/pdf/2309.11751)
* [TeX Source](/src/2309.11751)
* [Other Formats](/format/2309.11751)

[![license icon](https://arxiv.org/icons/licenses/by-nc-sa-4.0.png)
view license](http://creativecommons.org/licenses/by-nc-sa/4.0/ "Rights to this article")

Current browse context:

cs.CV

[< prev](/prevnext?id=2309.11751&function=prev&context=cs.CV "previous in cs.CV (accesskey p)")
  |   
[next >](/prevnext?id=2309.11751&function=next&context=cs.CV "next in cs.CV (accesskey n)")

[new](/list/cs.CV/new)
 | 
[recent](/list/cs.CV/recent)
 | [2023-09](/list/cs.CV/2023-09)

Change to browse by:

[cs](/abs/2309.11751?context=cs)  
[cs.AI](/abs/2309.11751?context=cs.AI)  
[cs.CR](/abs/2309.11751?context=cs.CR)  
[cs.LG](/abs/2309.11751?context=cs.LG)

### References & Citations

* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2309.11751)
* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2309.11751)
* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2309.11751)

[a](/static/browse/0.3.4/css/cite.css)
export BibTeX citation
Loading...

## BibTeX formatted citation

×

loading...

Data provided by:

### Bookmark

[![BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2309.11751&description=How Robust is Google's Bard to Adversarial Image Attacks? "Bookmark on BibSonomy")
[![Reddit logo](/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2309.11751&title=How Robust is Google's Bard to Adversarial Image Attacks? "Bookmark on Reddit")



Bibliographic Tools

# Bibliographic and Citation Tools

Bibliographic Explorer Toggle

Bibliographic Explorer *([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*

Connected Papers Toggle

Connected Papers *([What is Connected Papers?](https://www.connectedpapers.com/about))*

Litmaps Toggle

Litmaps *([What is Litmaps?](https://www.litmaps.co/))*

scite.ai Toggle

scite Smart Citations *([What are Smart Citations?](https://www.scite.ai/))*

Code, Data, Media

# Code, Data and Media Associated with this Article

alphaXiv Toggle

alphaXiv *([What is alphaXiv?](https://alphaxiv.org/))*

Links to Code Toggle

CatalyzeX Code Finder for Papers *([What is CatalyzeX?](https://www.catalyzex.com))*

DagsHub Toggle

DagsHub *([What is DagsHub?](https://dagshub.com/))*

GotitPub Toggle

Gotit.pub *([What is GotitPub?](http://gotit.pub/faq))*

Huggingface Toggle

Hugging Face *([What is Huggingface?](https://huggingface.co/huggingface))*

Links to Code Toggle

Papers with Code *([What is Papers with Code?](https://paperswithcode.com/))*

ScienceCast Toggle

ScienceCast *([What is ScienceCast?](https://sciencecast.org/welcome))*

Demos

# Demos

Replicate Toggle

Replicate *([What is Replicate?](https://replicate.com/docs/arxiv/about))*

Spaces Toggle

Hugging Face Spaces *([What is Spaces?](https://huggingface.co/docs/hub/spaces))*

Spaces Toggle

TXYZ.AI *([What is TXYZ.AI?](https://txyz.ai))*

Related Papers

# Recommenders and Search Tools

Link to Influence Flower

Influence Flower *([What are Influence Flowers?](https://influencemap.cmlab.dev/))*

Core recommender toggle

CORE Recommender *([What is CORE?](https://core.ac.uk/services/recommender))*

* Author
* Venue
* Institution
* Topic


About arXivLabs

# arXivLabs: experimental projects with community collaborators

arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

Have an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).

[Which authors of this paper are endorsers?](/auth/show-endorsers/2309.11751) |
[Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))



* [About](https://info.arxiv.org/about)
* [Help](https://info.arxiv.org/help)

* contact arXivClick here to contact arXiv
   [Contact](https://info.arxiv.org/help/contact.html)
* subscribe to arXiv mailingsClick here to subscribe
   [Subscribe](https://info.arxiv.org/help/subscribe)



* [Copyright](https://info.arxiv.org/help/license/index.html)
* [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)

* [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)
* [arXiv Operational Status](https://status.arxiv.org)   
  Get status notifications via
  [email](https://subscribe.sorryapp.com/24846f03/email/new)
  or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)
