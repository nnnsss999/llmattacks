---
attack_type: indirect_pi
source_url: http://arxiv.org/pdf/2012.07805
---

ExtractingTrainingDatafromLargeLanguageModelsNicholasCarlini1FlorianTramèr2EricWallace3MatthewJagielski4ArielHerbert-Voss5,6KatherineLee1AdamRoberts1TomBrown5DawnSong3ÚlfarErlingsson7AlinaOprea4ColinRaffel11Google2Stanford3UCBerkeley4NortheasternUniversity5OpenAI6Harvard7AppleAbstractIthasbecomecommontopublishlarge(billionparameter)languagemodelsthathavebeentrainedonprivatedatasets.Thispaperdemonstratesthatinsuchsettings,anadversarycanperformatrainingdataextractionattacktorecoverindividualtrainingexamplesbyqueryingthelanguagemodel.WedemonstrateourattackonGPT-2,alanguagemodeltrainedonscrapesofthepublicInternet,andareabletoextracthundredsofverbatimtextsequencesfromthemodel’strainingdata.Theseextractedexamplesinclude(public)personallyidentiﬁableinformation(names,phonenumbers,andemailaddresses),IRCconversations,code,and128-bitUUIDs.Ourattackispossibleeventhougheachoftheabovesequencesareincludedinjustonedocumentinthetrainingdata.Wecomprehensivelyevaluateourextractionattacktoun-derstandthefactorsthatcontributetoitssuccess.Worryingly,weﬁndthatlargermodelsaremorevulnerablethansmallermodels.Weconcludebydrawinglessonsanddiscussingpos-siblesafeguardsfortraininglargelanguagemodels.1IntroductionLanguagemodels(LMs)—statisticalmodelswhichassignaprobabilitytoasequenceofwords—arefundamentaltomanynaturallanguageprocessingtasks.Modernneural-network-basedLMsuseverylargemodelarchitectures(e.g.,175bil-lionparameters[7])andtrainonmassivedatasets(e.g.,nearlyaterabyteofEnglishtext[55]).ThisscalingincreasestheabilityofLMstogenerateﬂuentnaturallanguage[53,74,76],andalsoallowsthemtobeappliedtoaplethoraofothertasks[29,39,55],evenwithoutupdatingtheirparameters[7].Atthesametime,machinelearningmodelsarenotoriousforexposinginformationabouttheir(potentiallyprivate)train-ingdata—bothingeneral[47,65]andinthespeciﬁccaseoflanguagemodels[8,45].Forinstance,forcertainmodelsitisknownthatadversariescanapplymembershipinferenceattacks[65]topredictwhetherornotanyparticularexamplewasinthetrainingdata.GPT-2East Stroudsburg Stroudsburg...Prefix---  Corporation Seabank Centre------ Marine Parade SouthportPeter W--------- -----------@---.------------.com+-- 7 5--- 40-- Fax: +-- 7 5--- 0--0Memorized textFigure1:Ourextractionattack.Givenqueryaccesstoaneuralnetworklanguagemodel,weextractanindividualper-son’sname,emailaddress,phonenumber,faxnumber,andphysicaladdress.Theexampleinthisﬁgureshowsinforma-tionthatisallaccuratesoweredactittoprotectprivacy.Suchprivacyleakageistypicallyassociatedwithoverﬁtting[75]—whenamodel’strainingerrorissigniﬁcantlylowerthanitstesterror—becauseoverﬁttingoftenindicatesthatamodelhasmemorizedexamplesfromitstrainingset.Indeed,overﬁttingisasufﬁcientconditionforprivacyleakage[72]andmanyattacksworkbyexploitingoverﬁtting[65].Theassociationbetweenoverﬁttingandmemorizationhas—erroneously—ledmanytoassumethatstate-of-the-artLMswillnotleakinformationabouttheirtrainingdata.Becausethesemodelsareoftentrainedonmassivede-duplicateddatasetsonlyforasingleepoch[7,55],theyexhibitlittletonooverﬁtting[53].Accordingly,theprevailingwisdomhasbeenthat“thedegreeofcopyingwithrespecttoanygivenworkislikelytobe,atmost,deminimis”[71]andthatmodelsdonotsigniﬁcantlymemorizeanyparticulartrainingexample.1arXiv:2012.07805v2  [cs.CR]  15 Jun 2021Contributions.Inthiswork,wedemonstratethatlargelan-guagemodelsmemorizeandleakindividualtrainingexam-ples.Inparticular,weproposeasimpleandefﬁcientmethodforextractingverbatimsequencesfromalanguagemodel’strainingsetusingonlyblack-boxqueryaccess.Ourkeyin-sightisthat,althoughtrainingexamplesdonothavenotice-ablylowerlossesthantestexamplesonaverage,certainworst-casetrainingexamplesareindeedmemorized.Inourattack,weﬁrstgeneratealarge,diversesetofhigh-likelihoodsamplesfromthemodel,usingoneofthreegeneral-purposesamplingstrategies.Wethensorteachsampleusingoneofsixdifferentmetricsthatestimatethelikelihoodofeachsampleusingaseparatereferencemodel(e.g.,anotherLM),andrankhighestthesampleswithanabnormallyhighlikelihoodratiobetweenthetwomodels.Ourattacksdirectlyapplytoanylanguagemodel,includingthosetrainedonsensitiveandnon-publicdata[10,16].WeusetheGPT-2model[54]releasedbyOpenAIasarepresentativelanguagemodelinourexperiments.WechoosetoattackGPT-2tominimizereal-worldharm—theGPT-2modelandoriginaltrainingdatasourcearealreadypublic.Tomakeourresultsquantitative,wedeﬁneatestabledef-initionofmemorization.Wethengenerate1,800candidatememorizedsamples,100undereachofthe3×6attackconﬁg-urations,andﬁndthatover600ofthemareverbatimsamplesfromtheGPT-2trainingdata(conﬁrmedincollaborationwiththecreatorsofGPT-2).Inthebestattackconﬁguration,67%ofcandidatesamplesareverbatimtrainingexamples.Ourmostobviously-sensitiveattackextractsthefullname,phys-icaladdress,emailaddress,phonenumber,andfaxnumberofanindividual(seeFigure1).Wecomprehensivelyanalyzeourattack,includingstudyinghowmodelsizeandstringfre-quencyaffectsmemorization,aswellashowdifferentattackconﬁgurationschangethetypesofextracteddata.Weconcludebydiscussingnumerouspracticalstrategiestomitigateprivacyleakage.Forexample,differentially-privatetraining[1]istheoreticallywell-foundedandguaranteedtoproduceprivatemodelsifappliedatanappropriaterecordlevel,butitcanresultinlongertrainingtimesandtypicallydegradesutility.Wealsomakerecommendations,suchascarefullyde-duplicatingdocuments,thatempiricallywillhelptomitigatememorizationbutcannotpreventallattacks.2Background&RelatedWorkTobegin,weintroducetherelevantbackgroundonlarge(billion-parameter)neuralnetwork-basedlanguagemodels(LMs)aswellasdataprivacyattacks.2.1LanguageModelingLanguagemodelsareafundamentalbuildingblockofcur-rentstate-of-the-artnaturallanguageprocessingpipelines[12,31,50,52,55].Whiletheunsupervisedobjectivesusedtotrainthesemodelsvary,onepopularchoiceisa“next-stepprediction”objective[5,31,44,52].ThisapproachconstructsagenerativemodelofthedistributionPr(x1,x2,...,xn),wherex1,x2,...,xnisasequenceoftokensfromavocabularyVbyapplyingthechainruleofprobabilityPr(x1,x2,...,xn)=Πni=1Pr(xi|x1,...,xi−1).State-of-the-artLMsuseneuralnetworkstoestimatethisprobabilitydistribution.Weletfθ(xi|x1,...,xi−1)denotethelikelihoodoftokenxiwhenevaluatingtheneuralnet-workfwithparametersθ.Whilerecurrentneuralnetworks(RNNs)[26,44]usedtobeacommonchoicefortheneu-ralnetworkarchitectureofLMs,attention-basedmodels[4]haverecentlyreplacedRNNsinstate-of-the-artmodels.Inparticular,TransformerLMs[70]consistofasequenceofat-tentionlayersandarethecurrentmodelarchitectureofchoice.Becausewebelieveourresultsareindependentoftheexactarchitectureused,wewillnotdescribetheTransformerarchi-tectureindetailhereandinsteadrefertoexistingwork[3].TrainingObjective.Alanguagemodelistrainedtomax-imizetheprobabilityofthedatainatrainingsetX.Inthispaper,eachtrainingexampleisatextdocument—forexample,aspeciﬁcnewsarticleorwebpagefromtheinternet.Formally,traininginvolvesminimizingthelossfunctionL(θ)=−logΠni=1fθ(xi|x1,...,xi−1)overeachtrainingexampleinthetrainingdatasetX.Becauseofthistrainingsetup,the“optimal”solutiontothetaskoflanguagemodelingistomemorizetheanswertotheques-tion“whattokenfollowsthesequencex1,...,xi−1?”forev-erypreﬁxinthetrainingset.However,state-of-the-artLMsaretrainedwithmassivedatasets,whichcausesthemtonotexhibitsigniﬁcantformsofmemorization:empirically,thetraininglossandthetestlossarenearlyidentical[7,53,55].GeneratingText.Alanguagemodelcangeneratenewtext(potentiallyconditionedonsomepreﬁxx1,...,xi)byiterativelysamplingˆxi+1∼fθ(xi+1|x1,...,xi)andthenfeedingˆxi+1backintothemodeltosampleˆxi+2∼fθ(xi+2|x1,...,ˆxi+1).Thisprocessisrepeateduntiladesiredstoppingcriterionisreached.Variationsofthistextgenerationmethodincludedeterministicallychoosingthemost-probabletokenratherthansampling(i.e.,“greedy”sampling)orsettingallbutthetop-nprobabilitiestozeroandrenormalizingtheprobabilitiesbeforesampling(i.e.,top-nsampling1[18]).GPT-2.OurpaperfocusesontheGPTvariantofTrans-formerLMs[7,52,54].Speciﬁcally,wedemonstrateourtrain-ingdataextractionattacksonGPT-2,afamilyofLMsthat1Fornotationalclarity,wewritetop-ninsteadofthemorecommontop-kbecausewewillusetheconstantkforaseparatepurpose.2werealltrainedusingthesamedatasetandtrainingalgorithm,butwithvaryingmodelsizes.GPT-2usesaword-pieces[61]vocabularywithabytepairencoder[22].GPT-2XListhelargestmodelwith1.5billionparameters.Fortheremainderofthispaper,the“GPT-2”modelreferstothis1.5billionparametermodelor,whenwespeciﬁcallyindicatethis,itsSmallandMediumvariantswith124millionand334millionparameters,respectively.TheGPT-2modelfamilywastrainedondatascrapedfromthepublicInternet.Theauthorscollectedadatasetbyfollow-ingoutboundlinksfromthesocialmediawebsiteReddit.ThewebpageswerecleanedofHTML,withonlythedocumenttextretained,andthende-duplicatedatthedocumentlevel.Thisresultedinaﬁnaldatasetof40GBoftextdata,overwhichthemodelwastrainedforapproximately12epochs.2Asaresult,GPT-2doesnotoverﬁt:thetraininglossisonlyroughly10%smallerthanthetestlossacrossallmodelsizes.2.2TrainingDataPrivacyItisundesirableformodelstorememberanydetailsthatarespeciﬁctotheir(potentiallyprivate)trainingdata.Theﬁeldoftrainingdataprivacydevelopsattacks(toleaktrainingdatadetails)anddefenses(topreventleaks).PrivacyAttacks.Whenmodelsarenottrainedwithprivacy-preservingalgorithms,theyarevulnerabletonumer-ousprivacyattacks.Theleastrevealingformofattackisthemembershipinferenceattack[28,47,65,67]:givenatrainedmodel,anadversarycanpredictwhetherornotaparticularexamplewasusedtotrainthemodel.Separately,modelinver-sionattacks[21]reconstructrepresentativeviewsofasubsetofexamples(e.g.,amodelinversionattackonafacerecog-nitionclassiﬁermightrecoverafuzzyimageofaparticularpersonthattheclassiﬁercanrecognize).Trainingdataextractionattacks,likemodelinversionat-tacks,reconstructtrainingdatapoints.However,trainingdataextractionattacksaimtoreconstructverbatimtrainingexam-plesandnotjustrepresentative“fuzzy”examples.Thismakesthemmoredangerous,e.g.,theycanextractsecretssuchasverbatimsocialsecuritynumbersorpasswords.TrainingdataextractionattackshaveuntilnowbeenlimitedtosmallLMstrainedonacademicdatasetsunderartiﬁcialtrainingsetups(e.g.,formoreepochsthantypical)[8,66,68,73],orsettingswheretheadversaryhasaprioriknowledgeofthesecrettheywanttoextract(e.g.,asocialsecuritynumber)[8,27].ProtectingPrivacy.Anapproachtominimizingmemoriza-tionoftrainingdataistoapplydifferentially-privatetrainingtechniques[1,9,43,60,64].Unfortunately,trainingmodelswithdifferentially-privatemechanismsoftenreducesaccu-racy[34]becauseitcausesmodelstofailtocapturethelong2PersonalcommunicationwiththeGPT-2authors.tailsofthedatadistribution[19,20,67].Moreover,itincreasestrainingtime,whichcanfurtherreduceaccuracybecausecur-rentLMsarelimitedbythecostoftraining[35,38,55].Asaresult,state-of-the-artLMssuchasGPT-2[53],GPT-3[7],andT5[55]donotapplytheseprivacy-preservingtechniques.3ThreatModel&EthicsTrainingdataextractionattacksareoftenseenastheoreticaloracademicandarethusunlikelytobeexploitableinpractice[71].Thisisjustiﬁedbytheprevailingintuitionthatprivacyleakageiscorrelatedwithoverﬁtting[72],andbecausestate-of-the-artLMsaretrainedonlarge(nearterabyte-sized[7])datasetsforafewepochs,theytendtonotoverﬁt[53].Ourpaperdemonstratesthattrainingdataextractionattacksarepractical.Toaccomplishthis,weﬁrstpreciselydeﬁnewhatwemeanby“memorization”.Wethenstateourthreatmodelandourattackobjectives.Finally,wediscusstheethicalconsiderationsbehindtheseattacksandexplainwhytheyarelikelytobeaseriousthreatinthefuture.3.1DeﬁningLanguageModelMemorizationTherearemanywaystodeﬁnememorizationinlanguagemodeling.Asmentionedearlier,memorizationisinmanywaysanessentialcomponentoflanguagemodelsbecausethetrainingobjectiveistoassignhighoveralllikelihoodtothetrainingdataset.LMsmust,forexample,“memorize”thecorrectspellingofindividualwords.Indeed,thereisaresearchdirectionthatanalyzesneuralnetworksasrepositoriesof(memorized)knowledge[51,59].Forexample,whenGPT-2ispromptedtocompletethesen-tence“Myaddressis1MainStreet,SanFranciscoCA”,itgenerates“94107”:acorrectzipcodeforSanFrancisco,CA.Whilethisisclearlymemorizationinsomeabstractform,weaimtoformalizeourdeﬁnitionofmemorizationinordertorestrictittocasesthatwemightconsider“unintended”[8].3.1.1EideticMemorizationofTextWedeﬁneeideticmemorizationasaparticulartypeofmem-orization.3Informally,eideticmemorizationisdatathathasbeenmemorizedbyamodeldespiteonlyappearinginasmallsetoftraininginstances.Thefewertrainingsamplesthatcon-tainthedata,thestrongertheeideticmemorizationis.Toformalizethisnotion,weﬁrstdeﬁnewhatitmeansforamodeltohaveknowledgeofastrings.Ourdeﬁnitionislooselyinspiredbyknowledgedeﬁnitionsininteractiveproofsystems[24]:amodelfθknowsastringsifscanbeextractedbyinteractingwiththemodel.Moreprecisely,wefocusonblack-boxinteractionswherethemodelgeneratessasthemostlikelycontinuationwhenpromptedwithsomepreﬁxc:3Eideticmemory(morecommonlycalledphotographicmemory)istheabilitytorecallinformationafterseeingitonlyonce.3Deﬁnition1(ModelKnowledgeExtraction)Astringsisextractable4fromanLMfθifthereexistsapreﬁxcsuchthat:s←argmaxs(cid:48):|s(cid:48)|=Nfθ(s(cid:48)|c)Weabusenotationslightlyheretodenotebyfθ(s(cid:48)|c)thelikelihoodofanentiresequences(cid:48).SincecomputingthemostlikelysequencesisintractableforlargeN,theargmaxinDeﬁnition1canbereplacedbyanappropriatesamplingstrat-egy(e.g.,greedysampling)thatreﬂectsthewayinwhichthemodelfθgeneratestextinpracticalapplications.Wethendeﬁneeideticmemorizationasfollows:Deﬁnition2(k-EideticMemorization)Astringsisk-eideticmemorized(fork≥1)byanLMfθifsisextractablefromfθandsappearsinatmostkexamplesinthetrainingdataX:|{x∈X:s⊆x}|≤k.Keytothisdeﬁnitioniswhat“examples”means.ForGPT-2,eachwebpageisused(initsentirety)asonetrainingexam-ple.Sincethisdeﬁnitioncountsthenumberofdistincttrainingexamplescontainingagivenstring,andnotthetotalnumberoftimesthestringoccurs,astringmayappearmultipletimesononepagewhilestillcountingask=1memorization.Thisdeﬁnitionallowsustodeﬁnememorizationasaspec-trum.Whilethereisnodeﬁnitivevalueofkatwhichwemightsaythatmemorizationisunintentionalandpotentiallyharm-ful,smallervaluesaremorelikelytobeso.Foranygivenk,memorizinglongerstringsisalso“worse”thanshorterstrings,althoughourdeﬁnitionomitsthisdistinctionforsimplicity.Forexample,underthisdeﬁnition,memorizingthecorrectspellingsofoneparticularwordisnotsevereifthewordoc-cursinmanytrainingexamples(i.e.,kislarge).Memorizingthezipcodeofaparticularcitymightbeeideticmemorization,dependingonwhetherthecitywasmentionedinmanytrain-ingexamples(e.g.,webpages)orjustafew.ReferringbacktoFigure1,memorizinganindividualperson’snameandphonenumberclearly(informally)violatesprivacyexpectations,andalsosatisﬁesourformaldeﬁnition:itiscontainedinjustafewdocumentsontheInternet—andhencethetrainingdata.3.2ThreatModelAdversary’sCapabilities.Weconsideranadversarywhohasblack-boxinput-outputaccesstoalanguagemodel.Thisallowstheadversarytocomputetheprobabilityofarbitrarysequencesfθ(x1,...,xn),andasaresultallowstheadversarytoobtainnext-wordpredictions,butitdoesnotallowtheadversarytoinspectindividualweightsorhiddenstates(e.g.,attentionvectors)ofthelanguagemodel.4Thisdeﬁnitionadmitspathologicalcornercases.Forexample,manyLMswhenwhenpromptedwith“Repeatthefollowingsentence:_____.”willdosocorrectly.Thisallowsanystringtobe“known”underourdeﬁnition.Simplereﬁnementsofthisdeﬁnitiondonotsolvetheissue,asLMscanalsobeaskedto,forexample,down-caseaparticularsentence.WeavoidthesepathologicalcasesbypromptingLMsonlywithshortpreﬁxes.ThisthreatmodelishighlyrealisticasmanyLMsareavailablethroughblack-boxAPIs.Forexample,theGPT-3model[7]createdbyOpenAIisavailablethroughblack-boxAPIaccess.Auto-completemodelstrainedonactualuserdatahavealsobeenmadepublic,althoughtheyreportedlyuseprivacy-protectionmeasuresduringtraining[10].Adversary’sObjective.Theadversary’sobjectiveistoex-tractmemorizedtrainingdatafromthemodel.Thestrengthofanattackismeasuredbyhowprivate(formalizedasbeingk-eideticmemorized)aparticularexampleis.Strongerattacksextractmoreexamplesintotal(bothmoretotalsequences,andlongersequences)andexampleswithlowervaluesofk.Wedonotaimtoextracttargetedpiecesoftrainingdata,butratherindiscriminatelyextracttrainingdata.Whiletargetedattackshavethepotentialtobemoreadversariallyharmful,ourgoalistostudytheabilityofLMstomemorizedatagenerally,nottocreateanattackthatcanbeoperationalizedbyrealadversariestotargetspeciﬁcusers.AttackTarget.WeselectGPT-2[54]asarepresentativeLMtostudyforourattacks.GPT-2isnearlyaperfecttarget.First,fromanethicalstandpoint,themodelanddataarepublic,andsoanymemorizeddatathatweextractisalreadypublic.5Second,fromaresearchstandpoint,thedataset(despitebeingcollectedfrompublicsources)wasneveractuallyreleasedbyOpenAI.Thus,itisnotpossibleforustounintentionally“cheat”anddevelopattacksthatmakeuseofknowledgeoftheGPT-2trainingdataset.3.3RisksofTrainingDataExtractionTrainingdataextractionattackspresentnumerousprivacyrisks.Fromanethicalstandpoint,mostoftheserisksaremiti-gatedinourpaperbecauseweattackGPT-2,whosetrainingdataispublic.However,sinceourattackswouldapplytoanyLM,wealsodiscusspotentialconsequencesoffutureattacksonmodelsthatmaybetrainedonprivatedata.DataSecrecy.Themostdirectformofprivacyleakageoc-curswhendataisextractedfromamodelthatwastrainedonconﬁdentialorprivatedata.Forexample,GMail’sauto-completemodel[10]istrainedonprivatetextcommunica-tionsbetweenusers,sotheextractionofuniquesnippetsoftrainingdatawouldbreakdatasecrecy.ContextualIntegrityofData.Theaboveprivacythreatcorrespondstoanarrowviewofdataprivacyasdatasecrecy.5SincethetrainingdataissourcedfromthepublicWeb,alltheoutputsofourextractionattackscanalsobefoundviaInternetsearches.Indeed,toevaluatewhetherwehavefoundmemorizedcontent,wesearchforthecontentontheInternetandareabletoﬁndtheseexamplesrelativelyeasily.4Abroaderviewoftheprivacyrisksposedbydataextrac-tionstemsfromtheframeworkofdataprivacyascontextualintegrity[48].Thatis,datamemorizationisaprivacyin-fringementifitcausesdatatobeusedoutsideofitsintendedcontext.AnexampleviolationofcontextualintegrityisshowninFigure1.Thisindividual’sname,address,email,andphonenumberarenotsecret—theyweresharedonlineinaspeciﬁccontextofintendeduse(ascontactinformationforasoftwareproject)—butarereproducedbytheLMinaseparatecontext.Duetofailuressuchasthese,user-facingapplicationsthatuseLMsmayinadvertentlyemitdataininappropriatecontexts,e.g.,adialoguesystemmayemitauser’sphonenumberinresponsetoanotheruser’squery.Small-kEideticRisks.Weneverthelessfocusonk-eideticmemorizationwithasmallkvaluebecauseitmakesextractionattacksmoreimpactful.Whiletherearecaseswherelarge-kmemorizationmaystillmatter(forexample,acompanymayrefertothenameofanupcomingproductmultipletimesinprivate—andeventhoughitisdiscussedoftenthenameitselfmaystillbesensitive)westudythesmall-kcase.Moreover,notethatalthoughweframeourpaperasan“at-tack”,LMswilloutputmemorizeddataevenintheabsenceofanexplicitadversary.WetreatLMsasblack-boxgenerativefunctions,andthememorizedcontentthatweextractcanbegeneratedthroughhonestinteractionwiththeLM.Indeed,wehaveevendiscoveredatleastonememorizedtrainingexam-pleamongthe1,000GPT-3samplesthatOpenAIoriginallyreleasedinitsofﬁcialrepository[49].3.4EthicalConsiderationsInthispaper,wewilldiscussandcarefullyexaminespeciﬁcmemorizedcontentthatweﬁndinourextractionattacks.Thisraisesethicalconsiderationsassomeofthedatathatweex-tractcontainsinformationaboutindividualusers.Aspreviouslymentioned,weminimizeethicalconcernsbyusingdatathatisalreadypublic.WeattacktheGPT-2model,whichisavailableonline.Moreover,theGPT-2trainingdatawascollectedfromthepublicInternet[54],andisinprincipleavailabletoanyonewhoperformsthesame(documented)collectionprocessasOpenAI,e.g.,see[23].However,therearestillethicalconcernseventhoughthemodelanddataarepublic.Itispossible—andindeedweﬁnditisthecase—thatwemightextractpersonalinforma-tionforindividualsfromthetrainingdata.Forexample,asshowninFigure1,werecoveredaperson’sfullname,ad-dress,andphonenumber.Inthispaper,wheneverwesucceedinextractingpersonally-identifyinginformation(usernames,phonenumbers,etc.)wepartiallymaskoutthiscontentwiththetoken.Weareawareofthefactthatthisdoesnotprovidecompletemediation:disclosingthatthevulnerabilityexistsallowsamaliciousactortoperformtheseattacksontheirowntorecoverthispersonalinformation.Justasresponsibledisclosurestillcausessome(limited)harm,webelievethatthebeneﬁtsofpublicizingtheseattacksoutweighthepotentialharms.Further,tomakeourattackspublic,wemustnecessarilyrevealsomesensitiveinformation.WecontactedtheindividualwhoseinformationispartiallyshowninFigure1todisclosethisfacttotheminadvanceandreceivedpermissiontousethisexample.OurresearchﬁndingshavealsobeendisclosedtoOpenAI.Unfortunately,wecannothopetocontactallresearcherswhotrainlargeLMsinadvanceofourpublication.WethushopethatthispublicationwillsparkfurtherdiscussionsontheethicsofmemorizationandextractionamongothercompaniesandresearchteamsthattrainlargeLMs[2,36,55,63].4InitialTrainingDataExtractionAttackWebeginwithasimplestrawmanbaselineforextractingtrainingdatafromalanguagemodelinatwo-stepprocedure.•Generatetext.Wegeneratealargequantityofdatabyunconditionallysamplingfromthemodel(Section4.1).•Predictwhichoutputscontainmemorizedtext.Wenextremovethegeneratedsamplesthatareunlikelytocontainmemorizedtextusingamembershipinferenceattack(Section4.2).Thesetwostepscorresponddirectlytoextractingmodelknowledge(Deﬁnition1),andthenpredictingwhichstringsmightbek-eideticmemorization(Deﬁnition2).4.1InitialTextGenerationSchemeTogeneratetext,weinitializethelanguagemodelwithaone-tokenpromptcontainingaspecialstart-of-sentencetokenandthenrepeatedlysampletokensinanautoregressivefashionfromthemodel(seeSection2.1forbackground).Wehopethatbysamplingaccordingtothemodel’sassignedlikelihood,wewillsamplesequencesthatthemodelconsiders“highlylikely”,andthatlikelysequencescorrespondtomemorizedtext.Concretely,wesampleexactly256tokensforeachtrialusingthetop-nstrategyfromSection2.1withn=40.4.2InitialMembershipInferenceGivenasetofsamplesfromthemodel,theproblemoftrainingdataextractionreducestooneofmembershipinference:pre-dictwhethereachsamplewaspresentinthetrainingdata[65].Intheirmostbasicform,pastmembershipinferenceattacksrelyontheobservationthatmodelstendtoassignhighercon-ﬁdencetoexamplesthatarepresentinthetrainingdata[46].Therefore,apotentiallyhigh-precisionmembershipinferenceclassiﬁeristosimplychooseexamplesthatareassignedthehighestlikelihoodbythemodel.SinceLMsareprobabilisticgenerativemodels,wefollowpriorwork[8]anduseanaturallikelihoodmeasure:theper-5plexityofasequencemeasureshowwelltheLM“predicts”thetokensinthatsequence.Concretely,givenasequenceoftokensx1,...,xn,theperplexityisdeﬁnedasP=exp(cid:32)−1nn∑i=1logfθ(xi|x1,...,xi−1)(cid:33)Thatis,iftheperplexityislow,thenthemodelisnotvery“surprised”bythesequenceandhasassignedonaverageahighprobabilitytoeachsubsequenttokeninthesequence.4.3InitialExtractionResultsWegenerate200,000samplesusingthelargestversionoftheGPT-2model(XL,1558Mparameters)followingthetextgenerationschemedescribedinSection4.1.Wethensortthesesamplesaccordingtothemodel’sperplexitymeasureandinvestigatethosewiththelowestperplexity.Thissimplebaselineextractionattackcanﬁndawideva-rietyofmemorizedcontent.Forexample,GPT-2memorizestheentiretextoftheMITpubliclicense,aswellastheuserguidelinesofVaughnLive,anonlinestreamingsite.Whilethisis“memorization”,itisonlyk-eideticmemorizationforalargevalueofk—theselicensesoccurthousandsoftimes.Themostinteresting(butstillnoteideticmemorizationforlowvaluesofk)examplesincludethememorizationofpopu-larindividuals’Twitterhandlesoremailaddresses(omittedtopreserveuserprivacy).Infact,allmemorizedcontentweidentifyinthisbaselinesettingislikelytohaveappearedinthetrainingdatasetmanytimes.Thisinitialapproachhastwokeyweaknessesthatwecanidentify.First,oursamplingschemetendstoproducealowdiversityofoutputs.Forexample,outofthe200,000sampleswegenerated,severalhundredareduplicatesofthememo-rizeduserguidelinesofVaughnLive.Second,ourbaselinemembershipinferencestrategysuffersfromalargenumberoffalsepositives,i.e.,contentthatisassignedhighlikelihoodbutisnotmemorized.Themajorityofthesefalsepositivesamplescontain“repeated”strings(e.g.,thesamephraserepeatedmultipletimes).Despitesuchtextbeinghighlyunlikely,largeLMsoftenincorrectlyassignhighlikelihoodtosuchrepetitivesequences[30].5ImprovedTrainingDataExtractionAttackTheproof-of-conceptattackpresentedintheprevioussectionhaslowprecision(high-likelihoodsamplesarenotalwaysinthetrainingdata)andlowrecall(itidentiﬁesnok-memorizedcontentforlowk).Here,weimprovetheattackbyincorporat-ingbettermethodsforsamplingfromthemodel(Section5.1)andmembershipinference(Section5.2).5.1ImprovedTextGenerationSchemesTheﬁrststepinourattackistorandomlysamplefromthelan-guagemodel.Above,weusedtop-nsamplingandconditionedtheLMonthestart-of-sequencetokenasinput.Thisstrategyhasclearlimitations[32]:itwillonlygeneratesequencesthatarelikelyfrombeginningtoend.Asaresult,top-nsamplingfromthemodelwillcauseittogeneratethesame(orsimilar)examplesseveraltimes.BelowwedescribetwoalternativetechniquesforgeneratingmorediversesamplesfromtheLM.5.1.1SamplingWithADecayingTemperatureAsdescribedinSection2.1,anLMoutputstheprobabilityofthenexttokengiventhepriortokensPr(xi|x1,...,xi−1).Inpractice,thisisachievedbyevaluatingtheneuralnetworkz=fθ(x1,...,xi−1)toobtainthe“logit”vectorz,andthencom-putingtheoutputprobabilitydistributionasy=softmax(z)deﬁnedbysoftmax(z)i=exp(zi)/∑nj=1exp(zj).Onecanartiﬁcially“ﬂatten”thisprobabilitydistributiontomakethemodellessconﬁdentbyreplacingtheoutputsoftmax(z)withsoftmax(z/t),fort>1.Here,tiscalledthetemperature.Ahighertemperaturecausesthemodeltobelessconﬁdentandmorediverseinitsoutput.However,maintainingahightemperaturethroughoutthegenerationprocesswouldmeanthatevenifthesamplingprocessbegantoemitamemorizedexample,itwouldlikelyrandomlystepoffthepathofthememorizedoutput.Thus,weuseasoftmaxtemperaturethatdecaysovertime,startingatt=10anddecayingdowntot=1overaperiodoftheﬁrst20tokens(≈10%ofthelengthofthesequence).Thisgivesasufﬁcientamountoftimeforthemodelto“explore”adiversesetofpreﬁxeswhilealsoallowingittofollowahigh-conﬁdencepathsthatitﬁnds.5.1.2ConditioningonInternetTextEvenwhenapplyingtemperaturesampling,therearestillsomepreﬁxesthatareunlikelytobesampledbutneverthelessoccurinactualdata.Asaﬁnalstrategy,ourthirdsamplingstrategyseedsthemodelwithpreﬁxesfromourownscrapesoftheInternet.ThissamplingstrategyensuresthatwewillgeneratesampleswithadiversesetofpreﬁxesthataresimilarinnaturetothetypeofdataGPT-2wastrainedon.WefollowadifferentdatacollectionprocessasusedinGPT-2(whichfollowsRedditlinks)inordertoreducethelike-lihoodthatourdatasethasanyintersectionwiththemodel’strainingdata.Inparticular,weselectsamplesfromasubsetofCommonCrawl6tofeedascontexttothemodel.76http://commoncrawl.org/7Itispossiblethereissomeintersectionbetweenthesetwodatasets,effec-tivelyallowingthisstrategyto“cheat”.Webelievethisdoesnotconsiderablyaffectresults.First,anyoverlapbetweenthetwodatasetsisrareonaverage.Second,becauseweonlyusebetweentheﬁrst5to10tokensofeachsample,anypossibleoverlapwillbesmallinabsoluteterms.6 200,000 LM GenerationsLM (GPT-2)Sorted Generations(using one of 6 metrics)DeduplicateTraining Data Extraction AttackPreﬁxesEvaluationInternet SearchChoose Top-100Check MemorizationMatchNoMatchFigure2:Workﬂowofourextractionattackandevaluation.1)Attack.WebeginbygeneratingmanysamplesfromGPT-2whenthemodelisconditionedon(potentiallyempty)preﬁxes.Wethensorteachgenerationaccordingtooneofsixmetricsandremovetheduplicates.Thisgivesusasetofpotentiallymemorizedtrainingexamples.2)Evaluation.Wemanuallyinspect100ofthetop-1000generationsforeachmetric.Wemarkeachgenerationaseithermemorizedornot-memorizedbymanuallysearchingonline,andweconﬁrmtheseﬁndingsbyworkingwithOpenAItoquerytheoriginaltrainingdata.Anopen-sourceimplementationofourattackprocessisavailableathttps://github.com/ftramer/LM_Memorization.Asinpriorwork[55],weperformbasicdata-sanitizationbyremovingHTMLandJavaScriptfromwebpages,andwede-duplicatedataonaline-by-linebasis.Thisgivesusadatasetof50MBoftext.Werandomlysamplebetween5and10tokensofcontextfromthisscrapeddataandthencontinueLMgenerationwithtop-nsamplingasinSection4.1.5.2ImprovedMembershipInferencePerformingmembershipinferencebyﬁlteringoutsampleswithlowlikelihoodhaspoorprecisionduetofailuresintheunderlyinglanguagemodel:therearemanysamplesthatareassignedspuriouslyhighlikelihood.Therearepredominantlytwocategoriesofsuchsamples:•Trivialmemorization.WeidentifymanycaseswhereGPT-2outputscontentthatisuninterestingbecauseofhowcommonthetextis.Forexample,itrepeatsthenum-bersfrom1to100withhighprobability.•Repeatedsubstrings.OnecommonfailuremodeofLMsistheirpropensitytorepeatedlyemitthesamestringoverandover[30,37].Wefoundmanyofthehigh-likelihoodsamplesthatarenotmemorizedareindeedrepeatedtexts(e.g.,“Iloveyou.Iloveyou...”).Ourinsightisthatwecanﬁlterouttheseuninteresting(yetstillhigh-likelihoodsamples)bycomparingtoasecondLM.Givenasecondmodelthataccuratelycapturestextlikelihood,weshouldexpectitwillalsoassignhighlikelihoodtotheseformsofmemorizedcontent.Therefore,anaturalstrategyforﬁndingmorediverseandrareformsofmemorizationistoﬁltersampleswheretheoriginalmodel’slikelihoodis“unexpectedlyhigh”comparedtoasecondmodel.Belowwediscussfourmethodsforachievingthis.ComparingtoOtherNeuralLanguageModels.AssumethatwehaveaccesstoasecondLMthatmemorizesadifferentsetofexamplesthanGPT-2.Onewaytoachievethiswouldbetotrainamodelonadisjointsetoftrainingdata,inwhichcaseitisunlikelythatthetwomodelswillmemorizethesamedataforsmallk.Analternatestrategyistotakeamuchsmallermodeltrainedonthesameunderlyingdataset:becausesmallermodelshavelesscapacityformemorization,weconjecturethattherearesamplesthatarek-eideticmemorized(forsmallk)bythelargestGPT-2model,butwhicharenotmemorizedbysmallerGPT-2models.Speciﬁcally,weusetheSmall(117Mparameters)andMedium(345Mparameters)models.ComparingtozlibCompression.ItisnotnecessarythatwecomparetoanotherneuralLM;anytechniquethatquan-tiﬁessomenotionof“surprise”foragivensequencecanbeuseful.Asasimplebaselinemethod,wecomputethezlib[41]entropyofthetext:thenumberofbitsofentropywhenthesequenceiscompressedwithzlibcompression.WethenusetheratiooftheGPT-2perplexityandthezlibentropyasourmembershipinferencemetric.Althoughtextcompressorsaresimple,theycanidentifymanyoftheexamplesoftrivialmem-orizationandrepeatedpatternsdescribedabove(e.g.,theyareexcellentatmodelingrepeatedsubstrings).ComparingtoLowercasedText.Insteadofdetectingmemorizationbycomparingonemodeltoanothermodel,anotheroptiondetectsmemorizationbycomparingtheper-plexityofthemodeltotheperplexityofthesamemodelona“canonicalized”versionofthatsequence.Speciﬁcally,wemea-suretheratiooftheperplexityonthesamplebeforeandafterlowercasingit,whichcandramaticallyaltertheperplexityofmemorizedcontentthatexpectsaparticularcasing.7PerplexityonaSlidingWindow.Sometimesamodelisnotconﬁdentwhenthesamplecontainsonememorizedsub-stringsurroundedbyablockofnon-memorized(andhighperplexity)text.Tohandlethis,weusetheminimumperplex-itywhenaveragedoveraslidingwindowof50tokens.86EvaluatingMemorizationWenowevaluatethevariousdataextractionmethodsandstudycommonthemesintheresultingmemorizedcontent.6.1MethodologyAnoverviewofourexperimentalsetupisshowninFigure2.Weﬁrstbuildthreedatasetsof200,000generatedsamples(eachofwhichis256tokenslong)usingoneofourstrategies:•Top-n(§4.1)samplesnaivelyfromtheemptysequence.•Temperature(§5.1.1)increasesdiversityduringsampling.•Internet(§5.1.2)conditionstheLMonInternettext.Weordereachofthesethreedatasetsaccordingtoeachofoursixmembershipinferencemetrics:•Perplexity:theperplexityofthelargestGPT-2model.•Small:theratiooflog-perplexitiesofthelargestGPT-2modelandtheSmallGPT-2model.•Medium:theratioasabove,butfortheMediumGPT-2.•zlib:theratioofthe(log)oftheGPT-2perplexityandthezlibentropy(ascomputedbycompressingthetext).•Lowercase:theratioofperplexitiesoftheGPT-2modelontheoriginalsampleandonthelowercasedsample.•Window:theminimumperplexityofthelargestGPT-2modelacrossanyslidingwindowof50tokens.Foreachofthese3×6=18conﬁgurations,weselect100samplesfromamongthetop-1000samplesaccordingtothechosenmetric.9Thisgivesus1,800totalsamplesofpoten-tiallymemorizedcontent.Inreal-worldattacks,adversarieswilllooktouncoverlargeamountsofmemorizedcontentandthusmaygeneratemanymoresamples.Wefocusonasmallersetasaproof-of-conceptattack.DataDe-Duplication.Toavoid“double-counting”memo-rizedcontent,weapplyanautomatedfuzzyde-duplicationstepwhenweselectthe100samplesforeachconﬁguration.Givenasamples,wedeﬁnethetrigram-multisetofs,de-notedtri(s)asamultisetofallword-leveltrigramsins(withwordssplitonwhitespaceandpunctuationcharacters).Forexample,thesentence“mynamemynamemyname”hastwotrigrams(“mynamemy”and”namemyname”)eachof8Chosenafteracursoryhyper-parametersweepandmanualanalysis.9Tofavorlow-rankedsamples,whilealsoexploringsomeofthehigher-rankedsamples,weselectthe100samplessothatthefractionofselectedsampleswithrankbelowkis(cid:112)k/1000.multiplicity2.Wemarkasamples1asaduplicateofanothersamples2,iftheirtrigrammultisetsaresimilar,speciﬁcallyif|tri(s1)∩tri(s2)|≥|tri(s1)|/2.EvaluatingMemorizationUsingManualInspection.Foreachofthe1,800selectedsamples,oneoffourauthorsmanuallydeterminedwhetherthesamplecontainsmemo-rizedtext.SincethetrainingdataforGPT-2wassourcedfromthepublicWeb,ourmaintoolisInternetsearches.Wemarkasampleasmemorizedifwecanidentifyanon-trivialsubstringthatreturnsanexactmatchonapagefoundbyaGooglesearch.ValidatingResultsontheOriginalTrainingData.Fi-nally,giventhesamplesthatwebelievetobememorized,weworkwiththeoriginalauthorsofGPT-2toobtainlim-itedqueryaccesstotheirtrainingdataset.Todothiswesentthemall1,800sequencesweselectedforanalysis.Forefﬁ-ciency,theythenperformedafuzzy3-grammatchtoaccountformemorizationwithdifferentpossibletokenizations.Wemarkedsamplesasmemorizedifall3-gramsinthemem-orizedsequenceoccurredincloseproximityinthetrainingdataset.Thisapproacheliminatesfalsenegatives,buthasfalsepositives.Itcanconﬁrmthatoursamplesarememorizedbutcannotdetectcaseswherewemissedmemorizedsamples.Insomeexperimentsbelow,wereportexactcountsforhowoftenaparticularsequenceoccursinthetrainingdata.WeobtainedthesecountsbyaskingtheGPT-2authorstoperformaseparategrepovertheentiredatasettogetanexactcount.6.2ResultsIntotalacrossallstrategies,weidentify604uniquememo-rizedtrainingexamplesfromamongthe1,800possiblecan-didates,foranaggregatetruepositiverateof33.5%(ourbestvarianthasatruepositiverateof67%).Below,wecategorizewhattypesofcontentismemorizedbythemodel,andalsostudywhichattackmethodsaremosteffective.CategoriesofMemorizedContent.Wemanuallygroupedthememorizedsamplesintodifferentcategories(adescrip-tionofthesecategoriesisinAppendixA).TheresultsareshowninTable1.Mostmemorizedcontentisfairlycanonicaltextfromnewsheadlines,logﬁles,entriesfromforumsorwikis,orreligioustext.However,wealsoidentifyasigniﬁcantamountofuniquedata,containing128-bitUUIDs,(correctly-resolving)URLscontainingrandomsubstrings,andcontactinformationofindividualpeopleandcorporations.InSec-tion6.3,westudythesecasesinmoredetail.EfﬁcacyofDifferentAttackStrategies.Table2showsthenumberofmemorizedsamplesbrokendownbythedif-ferenttextgenerationandmembershipinferencestrategies.8CategoryCountUSandinternationalnews109Logﬁlesanderrorreports79License,termsofuse,copyrightnotices54Listsofnameditems(games,countries,etc.)54ForumorWikientry53ValidURLs50Namedindividuals(non-newssamplesonly)46Promotionalcontent(products,subscriptions,etc.)45Highentropy(UUIDs,base64data)35Contactinfo(address,email,phone,twitter,etc.)32Code31Conﬁgurationﬁles30Religioustexts25Pseudonyms15DonaldTrumptweetsandquotes12Webforms(menuitems,instructions,etc.)11Technews11Listsofnumbers(dates,sequences,etc.)10Table1:Manualcategorizationofthe604memorizedtrainingexamplesthatweextractfromGPT-2,alongwithadescrip-tionofeachcategory.Somesamplescorrespondtomultiplecategories(e.g.,aURLmaycontainbase-64data).Categoriesinboldcorrespondtopersonallyidentiﬁableinformation.SamplingconditionedonInternettextisthemosteffectivewaytoidentifymemorizedcontent,however,allgenerationschemesrevealasigniﬁcantamountofmemorizedcontent.Forexample,thebaselinestrategyofgeneratingwithtop-nsamplingyields191uniquememorizedsamples,whereasconditioningonInternettextincreasesthisto273.Asdiscussedearlier,lookingdirectlyattheLMperplexityisapoormembershipinferencemetricwhenclassifyingdatageneratedwithtop-nortemperaturesampling:just9%and3%ofinspectedsamplesarememorized,respectively.Thecomparison-basedmetricsaresigniﬁcantlymoreeffectiveatpredictingifcontentwasmemorized.Forexample,67%ofInternetsamplesmarkedbyzlibarememorized.Figure3comparesthezlibentropyandtheGPT-2XLperplexityforeachsample,withmemorizedexampleshigh-lighted.PlotsfortheotherstrategiesareshowninFigure4inAppendixB.Observethatmostsamplesfallalongadiagonal,i.e.,sampleswithhigherlikelihoodunderonemodelalsohavehigherlikelihoodunderanothermodel.However,therearenumerousoutliersinthetopleft:thesesamplescorrespondtothosethatGPT-2assignsalowperplexity(ahighlikelihood)butzlibissurprisedby.Thesepoints,especiallythosewhichareextremeoutliers,aremorelikelytobememorizedthanthoseclosetothediagonal.Thedifferentextractionmethodsdifferinthetypeofmem-orizedcontenttheyﬁnd.AcompletebreakdownofthedataisgiveninAppendixA;however,tobrieﬂysummarize:123456789GPT-2 Perplexity100200300400500600700800zlib EntropyAll SamplesSelectedMemorizedFigure3:ThezlibentropyandtheperplexityofGPT-2XLfor200,000samplesgeneratedwithtop-nsampling.Inred,weshowthe100samplesthatwereselectedformanualinspec-tion.Inblue,weshowthe59samplesthatwereconﬁrmedasmemorizedtext.AdditionalplotsforothertextgenerationanddetectionstrategiesareinFigure4.1.Thezlibstrategyoftenﬁndsnon-raretext(i.e.,hasahighk-memorization).Itoftenﬁndsnewsheadlines,licenseﬁles,orrepeatedstringsfromforumsorwikis,andthereisonlyone“highentropy”sequencethisstrategyﬁnds.2.Lower-casingﬁndscontentthatislikelytohaveirregularcapitalization,suchasnewsheadlines(wherewordsarecapitalized)orerrorlogs(withmanyuppercasewords).3.TheSmallandMediumstrategiesoftenﬁndrarecontent.Thereare13and10highentropyexamplesfoundbyus-ingtheSmallandMediumGPT-2variants,respectively(comparedtojustonewithzlib).6.3ExamplesofMemorizedContentWenextmanuallyanalyzecategoriesofmemorizedcontentthatweﬁndparticularlycompelling.(AdditionalexamplesarepresentedinAppendixC.)RecallthatsinceGPT-2istrainedonpublicdata,ourattacksarenotparticularlysevere.Nevertheless,weﬁnditusefultoanalyzewhatweareabletoextracttounderstandthecategoriesofmemorizedcontent—withtheunderstandingthatattackingamodeltrainedonasensitivedatasetwouldgivestrongerresults.PersonallyIdentiﬁableInformation.Weidentifynumer-ousexamplesofindividualpeoples’names,phonenumbers,addresses,andsocialmediaaccounts.9InferenceStrategyTextGenerationStrategyTop-nTemperatureInternetPerplexity9339Small414258Medium383345zlib594667Window332858Lowercase532260TotalUnique191140273Table2:Thenumberofmemorizedexamples(outof100candidates)thatweidentifyusingeachofthethreetextgen-erationstrategiesandsixmembershipinferencetechniques.Somesamplesarefoundbymultiplestrategies;weidentify604uniquememorizedexamplesintotal.Weﬁnd46examplesthatcontainindividualpeoples’names.Whencountingoccurrencesofnamedindividuals,weomitmemorizedsamplesthatrelatetonationalandin-ternationalnews(e.g.,ifGPT-2emitsthenameofafamouspolitician,wedonotcountthisasanamedindividualhere).Wefurtherﬁnd32examplesthatcontainsomeformofcontactinformation(e.g.,aphonenumberorsocialmediahandle).Ofthese,16containcontactinformationforbusinesses,and16containprivateindividuals’contactdetails.Someofthismemorizedcontentisexclusivetojustafewdocuments.Forexample,weextracttheusernamesofsixusersparticipatinginanIRCconversationthatappearedinexactlyonetrainingdocument.URLs.Weidentify50examplesofmemorizedURLsthatcorrectlyresolvetolivewebpages.ManyoftheseURLscon-tainuncommonpiecesoftext,suchasrandomnumbersorbase-64encodedstrings.WealsoidentifyseveralURLsthatresolvecorrectlybutwecannotidentifytheirsource(andwethusdonotcountthemas“memorized”inourevaluation).Code.Weidentify31generatedsamplesthatcontainsnip-petsofmemorizedsourcecode.Despiteourabilitytorecoverthesourcecodeverbatim,wearealmostalwaysunabletorecovertheoriginalauthorshipnoticesortermsofuse.Often,thisinformationisgiveneitherbeforethecodeitselforinaLICENSEﬁlethatappearsseparately.Formanyofthesesam-ples,wecanalsoextendtheirlengthandrecoverthousandsoflinesof(nearverbatim)sourcecode(seeSection6.4).UnnaturalText.Memorizationisnotlimitedtonatural-lookingtext.Weﬁnd21instancesofrandomnumberse-quenceswithatleast50bitsofentropy.10Forexample,we10Weestimatetheentropythroughmanualanalysisbyguessingtheentropyspacegiventheformatofthestring.MemorizedStringSequenceLengthOccurrencesinDataDocsTotalY2......y5871107C......1840122XM......WA54136ab......2c64149ff......af32164C7......ow431830x......C01019676......84171122a7......4b401311Table3:Examplesofk=1eideticmemorized,high-entropycontentthatweextractfromthetrainingdata.Eachiscontainedinjustonedocument.Inthebestcase,weextracta87-characters-longsequencethatiscontainedinthetrainingdatasetjust10timesintotal,allinthesamedocument.extractthefollowingUUID:1e4bd2a8-e8c8-4a62-adcd-40a936480059fromthemodel;aGooglesearchforthisstringidentiﬁesjust3documentscontainingthisUUID,anditiscontainedinjustoneGPT-2trainingdocument(i.e.,itis1-eideticmemorized).OthermemorizedrandomnumbersequencesincludeUUIDscontainedinonlyafewdocuments(notlistedtopreserveprivacy),gitcommithashes,randomIDsusedforadtracking,andproductmodelnumbers.Table3givesnineexamplesofk=1eideticmemorizedcontent,eachofwhichisarandomsequencesbetween10and87characterslong.Ineachofthesecases,thememorizedexampleiscontainedinexactlyonetrainingdocument,andthetotalnumberofoccurrenceswithinthatsingledocumentvariesbetweenjust10and311.DataFromTwoSources.Weﬁndsamplesthatcontaintwoormoresnippetsofmemorizedtextthatareunrelatedtooneanother.Inoneexample,GPT-2generatesanewsarticleaboutthe(real)murderofawomanin2013,butthenattributesthemurdertooneofthevictimsofanightclubshootinginOrlandoin2016.AnothersamplestartswiththememorizedInstagrambiographyofapornographyproducer,butthengoesontoincorrectlydescribeanAmericanfashionmodelasapornographyactress.Thistypeofgenerationisnotk-eideticmemorization(theseindependentpiecesofinformationneverappearinthesametrainingdocuments),butitisanexampleofacontextualintegrityviolation.RemovedContent.Finally,GPT-2memorizescontentthathassincebeenremovedfromtheInternet,andisthusnowprimarilyaccessiblethroughGPT-2.WeareawareofthiscontentasitisstillcachedbyGooglesearch,butisnolonger10presentonthelinkedwebpage.Someofthisdataisnotpar-ticularlyinterestinginitsownright,e.g.,errorlogsduetoamisconﬁguredwebserverthathassincebeenﬁxed.However,thefactthatthistypeofmemorizationoccurshighlightsthatLMsthataretrainedentirelyon(at-the-time)publicdatamayendupservingasanunintentionalarchiveforremoveddata.6.4ExtractingLongerVerbatimSequencesInourpreviousexperiments,weextractstringsof256tokensinlength.Here,webrieﬂyinvestigateifwecanextractlongersequences.Inparticular,weextendthelengthofsomeofthememorizedsequencesbyseedingthemodelwitheachsampleandcontinuingtogenerate.Todothis,weapplyabeam-search-likedecodingmethodintroducedinpriorwork[8]insteadofgreedydecodingwhichoftenfailstogeneratelongverbatimsequences.Wecanextendmanyofthememorizedsamples.Forexam-ple,weidentifyapieceofsourcecodetakenfromarepositoryonGitHub.Wecanextendthissnippettoextractanentireﬁle,namely1450linesofverbatimsourcecode.WecanalsoextracttheentiretyoftheMIT,CreativeCommons,andProjectGutenberglicenses.Thisindicatesthatwhilewehaveextracted604memorizedexamples,wecouldlikelyextendmanyofthesetomuchlongersnippetsofmemorizedcontent.6.5MemorizationisContext-DependentConsistentwithrecentworkonconstructingeffective“prompts”forgenerativeLMs[7,62],weﬁndthatthememo-rizedcontentishighlydependentonthemodel’scontext.Forexample,GPT-2willcompletetheprompt“3.14159”withtheﬁrst25digitsofπcorrectlyusinggreedysampling.However,weﬁndthatGPT-2“knows”(underDeﬁnition2)moredigitsofπbecauseusingthebeam-search-likestrategyintroducedaboveextracts500digitscorrectly.Interestingly,byprovidingthemoredescriptiveprompt“piis3.14159”,straightgreedydecodinggivestheﬁrst799digitsofπ—morethanwiththesophisticatedbeamsearch.Furtherprovidingthecontext“ebegins2.7182818,pibegins3.14159”,GPT-2greedilycompletestheﬁrst824digitsofπ.Thisexampledemonstratestheimportanceofthecontext:intherightsetting,ordersofmagnitudemoreextractionisfeasiblethanwhenthecontextisjustslightlysuboptimal.Weﬁndthatthisholdstrueforourmemorizedexamplesaswell.Noneofthe273extractedsamplesfoundusingInternetconditioningcanbereliablyreproducedwhenusingthesamepreﬁxinitiallyprovidedtoGPT-2thatproducedthissample.However,nearlyallcanbereproducedwithhighprobabilityifweprovidedtheentiresequenceofdataupto(butnotincluding)thebeginningofthememorizedcontent.Theimportantlessonhereisthatourworkvastlyunder-estimatesthetrueamountofcontentthatGPT-2memorized.Therearelikelypromptsthatwouldidentifymuchmoremem-orizedcontent,butbecausewesticktosimplepromptswedonotﬁndthismemorizedcontent.7CorrelatingMemorizationwithModelSize&InsertionFrequencyThusfar,wehaveshownthatlanguagemodelscanmemorizeverbatimtrainingstrings,evenwhentheyaretrainedforfewepochsandachievesmalltrain-testaccuracygaps.Anaturalquestionishowmanytimesastringmustappearforittobememorized(i.e.,kinDeﬁnition2).PriorworkhasinvestigatedLMmemorizationbyvaryingthenumberoftimesparticular“canary”tokenswereinsertedintoatrainingdataset[8].Themainlimitationofthisapproachisthatitissynthetic:canariesareinsertedartiﬁciallyafterthedatasethasbeencollectedandmaynotberepresentativeofnaturaldata.Here,westudyhowwellGPT-2memorizesnaturallyoc-curringcanariesinthetrainingdata.Inparticular,weconsiderapieceofmemorizedcontentwiththefollowingpreﬁx:{"color":"fuchsia","link":"https://www.reddit.com/r/The_Donald/comments/Thereddit.comURLaboveiscompletedbyaspeciﬁc6-characterarticleIDandatitle.WelocatedURLsinthisspeciﬁcformatinasingledocumentonpastebin.com.EachURLappearsavaryingnumberoftimesinthisdocument,andhenceintheGPT-2trainingdataset.11Table4showsasubsetoftheURLsthatappearmorethanonce,andtheirrespectivecountsinthedocument.12Thisallowsustoaskthequestion:howmanytimesmustanexampleappearinthetrainingdatasetforustoextractit?Methods.WeattempttwoapproachestoextractURLsofthisformat,andrunthreevariantsofGPT-2(XL,Medium,andSmall).Thetwoapproachesvarythe“difﬁculty”oftheattack,soevenifthemoredifﬁcultfailstheeasiermaysucceed.First,wedirectlyprompteachvariantofGPT-2withthepreﬁxabove,andusetop-nsamplingtogenerate10,000pos-sibleextensions.Then,wetestwhetheranyoftheURLsinthetrainingdocumentwereamongthosethatwereemittedbyGPT-2.WecountaURLasemittedifitmatchesverbatimwithoneofthe10,000generations.SomeURLsarenotextractablewiththistechnique,andsowemaketheproblemeasierforGPT-2byadditionallyprovidingGPT-2the6-characterrandomtokenthatbeginseachURL.Giventhisadditionalpreﬁx,wethensamplefrom11ThepurposeofthistextdumpwastotagusersofRedditwhopostedfrequentlyonspeciﬁctopics.Indoingso,thispagerepeatssomeofthesamelinksmanytimesbecausemanyuserscommentonthesamelinks.12WeconﬁrmedwithOpenAIthatthecountsherearewithin5%ofthetruecountsoftheseURLsinthetrainingdata.11OccurrencesMemorized?URL(trimmed)DocsTotalXLMS/r/51y/milo_evacua...1359(cid:88)(cid:88)1/2/r/zin/hi_my_name...1113(cid:88)(cid:88)/r/7ne/for_all_yo...176(cid:88)1/2/r/5mj/fake_news_...172(cid:88)/r/5wn/reddit_admi...164(cid:88)(cid:88)/r/lp8/26_evening...156(cid:88)(cid:88)/r/jla/so_pizzagat...151(cid:88)1/2/r/ubf/late_night...151(cid:88)1/2/r/eta/make_christ...135(cid:88)1/2/r/6ev/its_ofﬁcia...133(cid:88)/r/3c7/scott_adams...117/r/k2o/because_his...117/r/tu3/armynavy_ga...18Table4:WeshowsnippetsofRedditURLsthatappearavaryingnumberoftimesinasingletrainingdocument.WeconditionGPT-2XL,Medium,orSmallonapromptthatcontainsthebeginningofaRedditURLandreporta(cid:88)ifthecorrespondingURLwasgeneratedverbatimintheﬁrst10,000generations.Wereporta1/2iftheURLisgeneratedbyprovidingGPT-2withtheﬁrst6charactersoftheURLandthenrunningbeamsearch.themodelusingthebeamsearchprocedure.Thistaskiseas-ierintwoways:wehaveﬁrstprovidedmorecontextandadditionallyuseahigherrecallsamplingstrategy.Results.Table4summarizesthekeyresults.Underthemoredifﬁcultofthetwoapproaches,thefull-sized1.5billionparameterGPT-2modelemitsallexamplesthatareinserted33timesormore,themedium-sized345millionparametermemorizeshalfoftheURLs,andthesmallest117millionparametermodelmemorizesnoneoftheseURLs.Whengiventheadditionalcontextandusingbeamsearch,themediummodelcanemitfourmoreURLs,andthesmallmodelonlyemitstheoneURLthatwasinserted359times.TheseresultsillustratetwofundamentallessonsinLMmemorization.First,largermodelsmemorizesigniﬁcantlymoretrainingdata:evenhundredsofmillionsofparametersarenotenoughtomemorizesomeofthetrainingpoints.TheabilityofLMstoimprovewithmodelsizehasbeenexten-sivelystudied[35,38];weshowanegativetrendwheretheseimprovementscomeatthecostofdecreasedprivacy.Second,forthelargestLM,completememorizationoccursafterjust33insertions.Thisimpliesthatanypotentiallysensitiveinfor-mationthatisrepeatedanon-trivialamountoftimesisatriskformemorization,evenifitwasonlyrepeatedmultipletimesinasingletrainingdocument.8MitigatingPrivacyLeakageinLMsNowthatwehaveshownthatmemorizedtrainingdatacanbeextractedfromLMs,anaturalquestionishowtomitigatethesethreats.Herewedescribeseveralpossiblestrategies.TrainingWithDifferentialPrivacy.Differentialprivacy(DP)[13,14]isawell-establishednotionofprivacythatof-fersstrongguaranteesontheprivacyofindividualrecordsinthetrainingdataset.Privatemachinelearningmodelscanbetrainedwithvariantsofthedifferentiallyprivatestochasticgra-dientdescent(DP-SGD)algorithm[1]whichiswidelyimple-mented[17,25].LargecompanieshaveevenusedDPinpro-ductionmachinelearningmodelstoprotectusers’sensitiveinformation[15,69].Thetradeoffsbetweenprivacyandutilityofmodelshavebeenstudiedextensively:differentially-privatetrainingtypicallypreventsmodelsfromcapturingthelongtailsofthedatadistributionandthushurtsutility[19,20,67].Inthecontentoflanguagemodeling,recentworkdemon-stratestheprivacybeneﬁtsofuser-levelDPmodels[56].Un-fortunately,thisworkrequireslabelsforwhichuserscon-tributedeachdocument;suchlabelsareunavailablefordatascrapedfromtheopenWeb.ItmayinsteadseemnaturaltoaimforDPguaranteesatthegranularityofindividualweb-pages,butraresnippetsoftext(e.g.,anindividual’snameandcontactinformationasinFigure1)mightappearinmorethanonewebpage.ItisthusunclearhowtoapplyDPinaprincipledandeffectivewayonWebdata.CuratingtheTrainingData.OnecannotmanuallyvettheextremelylargetrainingdatasetsusedfortrainingLMs.How-ever,therearemethodstolimittheamountofsensitivecon-tentthatispresent,e.g.,byidentifyingandﬁlteringpersonalinformationorcontentwithrestrictivetermsofuse[11,58].Asidefromattemptingtoremovesensitivecontent,itisalsoimportanttocarefullyde-duplicatethedata.Manylan-guagemodelingdatasetsarede-duplicatedatthedocument-orparagraph-level,whichmeansthatasingledocumentcanstillcontainmanyrepeatedoccurrencesofasensitivepieceofcontent.Weenvisionmoresophisticatedstrategiestode-duplicatethetrainingdata,orlimitthecontributionofanysinglesourceoftrainingdata.Itisalsovitaltocarefullysourcethetrainingdata.Manyofthepotentially-sensitivetrainingexamplesthatweextracted(e.g.,individuals’personalinformation)camefromwebsitesthatareknowntohostsensitivecontent,e.g.,pastebinisthe12thmostpopulardomaininGPT-2’strainingset.Overall,sanitizingdataisimperfect—someprivatedatawillalwaysslipthrough—andthusitservesasaﬁrstlineofdefenseandnotanoutrightpreventionagainstprivacyleaks.LimitingImpactofMemorizationonDownstreamAppli-cations.Inmanydownstreamapplications,e.g.,dialogue12systems[76]andsummarizationmodels[29],LMsareﬁne-tunedontask-speciﬁcdata.Onthepositiveside,thisﬁnetun-ingprocessmaycausetheLMto“forget”[42,57]someofthedatathatismemorizedduringthepre-trainingstage.Onthenegativeside,ﬁne-tuningmayintroduceitsownprivacyleakagesifthetask-speciﬁcdataalsocontainsprivateinfor-mation.Aninterestingdirectionforfutureworkistoexplorehowmemorizationisinheritedbyﬁne-tunedmodels.Downstreamapplicationsbuiltontopoflanguagemodelscouldalsoattempttoﬁlteroutgeneratedtextthatcontainsmemorizedcontent,ifsuchcontentcanbereliablydetected(e.g.,usingvariousmembershipinferencestrategies).AuditingMLModelsforMemorization.Finally,aftermitigatingprivacyleaks,itisvitaltoauditmodelstoempiri-callydeterminetheprivacyleveltheyofferinpractice[33].Auditingisimportantevenwhenusingdifferentialprivacy,asitcancomplementtheoreticalupperboundsonprivacyleakage[1].Weenvisionusingourproposedmethods,aswellasexistingattacks[8,33,65,72],toauditLMs.9LessonsandFutureWorkExtractionAttacksAreaPracticalThreat.Priorworkshowsthat(100×to1000×smaller)languagemodelspoten-tiallymemorizetrainingdatainsemi-realisticsettings[8,73].Ourresultsshowthatstate-of-the-artLMsdomemorizetheirtrainingdatainpractice,andthatadversariescanextractthisdatawithsimpletechniques.Ourattacksarepracticalevenwhenthedatacontainsagivensequenceonlyafewtimes.Asourattacksinteractwithalanguagemodelasablack-box,ourresultsapproximatetheworst-casebehavioroflan-guagemodelswheninteractingwithbenignusers.Inparticu-lar,among600,000(honestly)generatedsamples,ourattacksﬁndthatatleast604(or0.1%)containmemorizedtext.Notethatthisislikelyanextremelylooselowerbound.Weonlymanuallyinspected1,800potentialcandidatememorizedsamples;ifwehadstartedwithmorecandidateswewouldlikelyhaveidentiﬁedsigniﬁcantlymorememorizedcontent.Developingimprovedtechniquesforextractingmemorizeddata,includingattacksthataretargetedtowardsspeciﬁccon-tent,isaninterestingareaforfuturework.MemorizationDoesNotRequireOverﬁtting.Itisoftenbelievedthatpreventingoverﬁtting(i.e.,reducingthetrain-testgeneralizationgap)willpreventmodelsfrommemorizingtrainingdata.However,largeLMshavenosigniﬁcanttrain-testgap,andyetwestillextractnumerousexamplesverbatimfromthetrainingset.Thekeyreasonisthateventhoughonaveragethetraininglossisonlyslightlylowerthanthevalidationloss,therearestillsometrainingexamplesthathaveanomalouslylowlosses.Understandingwhythishappensisanimportantproblemforfuturework[6,40].LargerModelsMemorizeMoreData.Throughoutourexperiments,largerlanguagemodelsconsistentlymemorizedmoretrainingdatathansmallerLMs.Forexample,inonesettingthe1.5billionparameterGPT-2modelmemorizesover18×asmuchcontentasthe124millionparametermodel(Section7).Worryingly,itislikelythatasLMsbecomebigger(infacttheyalreadyare100×largerthantheGPT-2modelwestudy[7]),privacyleakagewillbecomeevenmoreprevalent.MemorizationCanBeHardtoDiscover.Muchofthetrainingdatathatweextractisonlydiscoveredwhenprompt-ingtheLMwithaparticularpreﬁx.Currently,wesimplyattempttousehigh-qualitypreﬁxesandhopethattheymightelicitmemorization.Betterpreﬁxselectionstrategies[62]mightidentifymorememorizeddata.AdoptandDevelopMitigationStrategies.WediscussseveraldirectionsformitigatingmemorizationinLMs,in-cludingtrainingwithdifferentialprivacy,vettingthetrainingdataforsensitivecontent,limitingtheimpactondownstreamapplications,andauditingLMstotestformemorization.Alloftheseareinterestingandpromisingavenuesoffuturework,buteachhasweaknessesandareincompletesolutionstothefullproblem.MemorizationinmodernLMsmustbead-dressedasnewgenerationsofLMsareemergingandbecom-ingbuildingblocksforarangeofreal-worldapplications.10ConclusionForlargelanguagemodelstobewidelyadopted,theymustaddressthetrainingdatamemorizationproblemsthatwehaveidentiﬁed.Ourextractionattacksarepracticalandefﬁcient,andcanrecoverhundredsoftrainingexamplesfromamodel,evenwhentheyarecontainedinjustonetrainingdocument.OuranalysisisbestviewedasacautionarytaleofwhatcouldhappenwhentraininglargeLMsonsensitivedata.EventhoughourattackstargetGPT-2(whichallowsustoensurethatourworkisnotharmful),thesametechniquesapplytoanyLM.Moreover,becausememorizationgetsworseasLMsbecomelarger,weexpectthatthesevulnerabilitieswillbecomesigniﬁcantlymoreimportantinthefuture.Therewillthereforeneedtobetechniquesdevelopedtospeciﬁcallyaddressourattacks.Trainingwithdifferentially-privatetechniquesisonemethodformitigatingprivacyleak-age,however,webelievethatitwillbenecessarytodevelopnewmethodsthatcantrainmodelsatthisextremescale(e.g.,billionsofparameters)withoutsacriﬁcingmodelaccuracyortrainingtime.Moregenerally,therearemanyopenques-tionsthatwehopewillbeinvestigatedfurther,includingwhymodelsmemorize,thedangersofmemorization,andhowtopreventmemorization.13AcknowledgementsWearegratefulforcommentsonearlyversionsofthispaperbyDanBoneh,AndreasTerzis,CareyRadebaugh,DaphneIp-polito,ChristineRobson,KellyCooke,JanelThamkul,AustinTarango,JackClark,IlyaMironov,andOmThakkar.FlorianTramèrissupportedbyNSFawardCNS-1804222.SummaryofContributions•Nicholas,Dawn,Ariel,Tom,ColinandÚlfarproposedtheresearchquestionofextractingtrainingdatafromGPT-2andframedthethreatmodel.•Colin,Florian,Matthew,andNicholasstatedthememoriza-tiondeﬁnitions.•Florian,Ariel,andNicholaswrotecodetogeneratecandi-datememorizedsamplesfromGPT-2andverifythegroundtruthmemorization.•Florian,Nicholas,Matthew,andEricmanuallyreviewedandcategorizedthecandidatememorizedcontent.•Katherine,Florian,Eric,andColingeneratedtheﬁgures.•Adam,Matthew,andEricranpreliminaryinvestigationsinlanguagemodelmemorization.•Nicholas,Florian,Eric,Colin,Katherine,Matthew,Ariel,Alina,Úlfar,Dawn,andAdamwroteandeditedthepaper.•Tom,Adam,andColingaveadviceonlanguagemodelsandmachinelearningbackground.•Alina,Úlfar,andDawngaveadviceonthesecuritygoals.References[1]MartínAbadi,AndyChu,IanGoodfellow,HBrendanMcMahan,IlyaMironov,KunalTalwar,andLiZhang.Deeplearningwithdifferentialprivacy.InACMCCS,2016.[2]DanielAdiwardana,Minh-ThangLuong,DavidRSo,JamieHall,NoahFiedel,RomalThoppilan,ZiYang,ApoorvKulshreshtha,GauravNemade,YifengLu,etal.Towardsahuman-likeopen-domainchatbot.arXivpreprintarXiv:2001.09977,2020.[3]JayAlammar.Theillustratedtransformer.VisualizingMachineLearningOneConceptataTime,2018.[4]DzmitryBahdanau,KyunghyunCho,andYoshuaBen-gio.Neuralmachinetranslationbyjointlylearningtoalignandtranslate.InICLR,2015.[5]YoshuaBengio,RéjeanDucharme,PascalVincent,andChristianJauvin.Aneuralprobabilisticlanguagemodel.JMLR,2003.[6]GavinBrown,MarkBun,VitalyFeldman,AdamSmith,andKunalTalwar.Whenismemorizationofirrele-vanttrainingdatanecessaryforhigh-accuracylearning?arXivpreprintarXiv:2012.06421,2020.[7]TomBBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNee-lakantan,PranavShyam,GirishSastry,AmandaAskell,etal.Languagemodelsarefew-shotlearners.arXivpreprintarXiv:2005.14165,2020.[8]NicholasCarlini,ChangLiu,ÚlfarErlingsson,JernejKos,andDawnSong.Thesecretsharer:Evaluatingandtestingunintendedmemorizationinneuralnetworks.InUSENIXSecuritySymposium,2019.[9]KamalikaChaudhuriandClaireMonteleoni.Privacy-preservinglogisticregression.InNIPS,2009.[10]MiaXuChen,BenjaminNLee,GaganBansal,YuanCao,ShuyuanZhang,JustinLu,JackieTsay,YinanWang,AndrewMDai,ZhifengChen,TimothySohn,andYonghuiWu.Gmailsmartcompose:Real-Timeassistedwriting.InKDD,2019.[11]AndreaContinella,YanickFratantonio,MartinaLindor-fer,AlessandroPuccetti,AliZand,ChristopherKruegel,andGiovanniVigna.Obfuscation-ResilientPrivacyLeakDetectionforMobileAppsThroughDifferentialAnalysis.InNDSS,2017.[12]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.BERT:Pre-trainingofdeepbidi-rectionaltransformersforlanguageunderstanding.InNAACL,2019.[13]CDwork,FMcSherry,KNissim,andASmith.Cali-bratingnoisetosensitivityinprivatedataanalysis.InTCC,2006.[14]CynthiaDwork.Differentialprivacy:Asurveyofresults.InTAMC,2008.[15]ÚlfarErlingsson,VasylPihur,andAleksandraKorolova.RAPPOR:Randomizedaggregatableprivacy-preservingordinalresponse.InACMCCS,2014.[16]AndreEsteva,BrettKuprel,RobertoANovoa,JustinKo,SusanMSwetter,HelenMBlau,andSebastianThrun.Dermatologist-levelclassiﬁcationofskincancerwithdeepneuralnetworks.Nature,2017.[17]Facebook.Opacus.https://github.com/pytorch/opacus.[18]AngelaFan,MikeLewis,andYannDauphin.Hierarchi-calneuralstorygeneration.InACL,2018.14[19]VitalyFeldman.Doeslearningrequirememorization?Ashorttaleaboutalongtail.InSTOC,2020.[20]VitalyFeldmanandChiyuanZhang.Whatneuralnet-worksmemorizeandwhy:Discoveringthelongtailviainﬂuenceestimation.InNeurIPS,2020.[21]MattFredrikson,SomeshJha,andThomasRistenpart.Modelinversionattacksthatexploitconﬁdenceinforma-tionandbasiccountermeasures.InACMCCS,2015.[22]PhilipGage.Anewalgorithmfordatacompression.CUsersJournal,12(2):23–38,1994.[23]AaronGokaslanandVanyaCohen.OpenWeb-Textcorpus.http://Skylion007.github.io/OpenWebTextCorpus,2019.[24]ShaﬁGoldwasser,SilvioMicali,andCharlesRackoff.Theknowledgecomplexityofinteractiveproofsystems.SICOMP,1989.[25]Google.TensorﬂowPrivacy.https://github.com/tensorflow/privacy.[26]AlexGraves.Generatingsequenceswithrecurrentneu-ralnetworks.arXivpreprintarXiv:1308.0850,2013.[27]PeterHenderson,KoustuvSinha,NicolasAngelard-Gontier,NanRosemaryKe,GenevieveFried,RyanLowe,andJoellePineau.Ethicalchallengesindata-drivendialoguesystems.InProceedingsofthe2018AAAI/ACMConferenceonAI,Ethics,andSociety,pages123–129,2018.[28]SoramiHisamoto,MattPost,andKevinDuh.Member-shipinferenceattacksonsequence-to-sequencemodels:Ismydatainyourmachinetranslationsystem?InTACL,2020.[29]AndrewHoang,AntoineBosselut,AsliCelikyilmaz,andYejinChoi.Efﬁcientadaptationofpretrainedtrans-formersforabstractivesummarization.arXivpreprintarXiv:1906.00138,2019.[30]AriHoltzman,JanBuys,MaxwellForbes,andYejinChoi.Thecuriouscaseofneuraltextdegeneration.InICLR,2020.[31]JeremyHowardandSebastianRuder.Universallan-guagemodelﬁne-tuningfortextclassiﬁcation.InACL,2018.[32]DaphneIppolito,DanielDuckworth,ChrisCallison-Burch,andDouglasEck.Automaticdetectionofgener-atedtextiseasiestwhenhumansarefooled.InACL.[33]MatthewJagielski,JonathanUllman,andAlinaOprea.Auditingdifferentiallyprivatemachinelearning:HowprivateisprivateSGD?InNeurIPS,2020.[34]BargavJayaramanandDavidEvans.Evaluatingdiffer-entiallyprivatemachinelearninginpractice.InUSENIXSecuritySymposium,2019.[35]JaredKaplan,SamMcCandlish,TomHenighan,TomBBrown,BenjaminChess,RewonChild,ScottGray,AlecRadford,JeffreyWu,andDarioAmodei.Scal-inglawsforneurallanguagemodels.arXivpreprintarXiv:2001.08361,2020.[36]MikeLewis,YinhanLiu,NamanGoyal,MarjanGhazvininejad,AbdelrahmanMohamed,OmerLevy,VesStoyanov,andLukeZettlemoyer.Bart:Denois-ingsequence-to-sequencepre-trainingfornaturallan-guagegeneration,translation,andcomprehension.arXivpreprintarXiv:1910.13461,2019.[37]JiweiLi,MichelGalley,ChrisBrockett,JianfengGao,andBillDolan.Adiversity-promotingobjectivefunc-tionforneuralconversationmodels.InNAACL,2016.[38]ZhuohanLi,EricWallace,ShengShen,KevinLin,KurtKeutzer,DanKlein,andJosephEGonzalez.Trainlarge,thencompress:Rethinkingmodelsizeforefﬁcienttrain-ingandinferenceoftransformers.InICML,2020.[39]YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-darJoshi,DanqiChen,OmerLevy,MikeLewis,LukeZettlemoyer,andVeselinStoyanov.RoBERTa:Aro-bustlyoptimizedBERTpretrainingapproach.arXivpreprintarXiv:1907.11692,2019.[40]YunhuiLong,VincentBindschaedler,LeiWang,DiyueBu,XiaofengWang,HaixuTang,CarlAGunter,andKaiChen.Understandingmembershipinferencesonwell-generalizedlearningmodels.arXivpreprintarXiv:1802.04889,2018.[41]JeanloupGaillyandMarkAdler.zlibcompressionlibrary.[42]MichaelMcCloskeyandNealJCohen.Catastrophicinterferenceinconnectionistnetworks:Thesequentiallearningproblem.InPsychologyoflearningandmoti-vation.1989.[43]HBrendanMcMahan,DanielRamage,KunalTalwar,andLiZhang.Learningdifferentiallyprivaterecurrentlanguagemodels.InICLR,2018.[44]TomasMikolov,MartinKaraﬁát,LukasBurget,JanCer-nock`y,andSanjeevKhudanpur.Recurrentneuralnet-workbasedlanguagemodel.InInterspeech,2010.[45]RandallMunroe.Predictivemodels.https://xkcd.com/2169/,2019.15[46]MiladNasr,RezaShokri,andAmirHoumansadr.Ma-chinelearningwithmembershipprivacyusingadversar-ialregularization.InACMSIGSAC,2018.[47]MiladNasr,RezaShokri,andAmirHoumansadr.Com-prehensiveprivacyanalysisofdeeplearning:Passiveandactivewhite-boxinferenceattacksagainstcentral-izedandfederatedlearning.InIEEES&P,2019.[48]HelenNissenbaum.Privacyascontextualintegrity.WashingtonLawReview,2004.[49]OpenAI.Languagemodelsarefew-shotlearners.https://github.com/openai/gpt-3,2020.[50]MatthewEPeters,MarkNeumann,MohitIyyer,MattGardner,ChristopherClark,KentonLee,andLukeZettlemoyer.Deepcontextualizedwordrepresentations.InNAACL,2018.[51]FabioPetroni,TimRocktäschel,PatrickLewis,AntonBakhtin,YuxiangWu,AlexanderHMiller,andSebas-tianRiedel.Languagemodelsasknowledgebases?InEMNLP,2019.[52]AlecRadford,KarthikNarasimhan,TimSalimans,andIlyaSutskever.Improvinglanguageunderstandingbygenerativepre-training,2018.[53]AlecRadford,JeffreyWu,DarioAmodei,DanielaAmodei,JackClark,MilesBrundage,andIlyaSutskever.Betterlanguagemodelsandtheirimplications.OpenAIBlog,2019.[54]AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,andIlyaSutskever.Languagemodelsareunsupervisedmultitasklearners,2019.[55]ColinRaffel,NoamShazeer,AdamRoberts,KatherineLee,SharanNarang,MichaelMatena,YanqiZhou,WeiLi,andPeterJLiu.Exploringthelimitsoftransferlearningwithauniﬁedtext-to-texttransformer.InJMLR,2020.[56]SwaroopRamaswamy,OmThakkar,RajivMathews,GalenAndrew,HBrendanMcMahan,andFrançoiseBeaufays.Trainingproductionlanguagemodelswithoutmemorizinguserdata.arXivpreprintarXiv:2009.10031,2020.[57]RogerRatcliff.Connectionistmodelsofrecognitionmemory:constraintsimposedbylearningandforgettingfunctions.Psychologicalreview,1990.[58]JingjingRen,AshwinRao,MartinaLindorfer,ArnaudLegout,andDavidChoffnes.ReCon:Revealingandcon-trollingPIIleaksinmobilenetworktrafﬁc.InMobiSys,2016.[59]AdamRoberts,ColinRaffel,andNoamShazeer.Howmuchknowledgecanyoupackintotheparametersofalanguagemodel?InEMNLP,2020.[60]BenjaminIPRubinstein,PeterLBartlett,LingHuang,andNinaTaft.Learninginalargefunctionspace:Privacy-preservingmechanismsforSVMlearning.Pri-vacyandConﬁdentiality,2012.[61]RicoSennrich,BarryHaddow,andAlexandraBirch.Neuralmachinetranslationofrarewordswithsubwordunits.InACL,2016.[62]TaylorShin,YasamanRazeghi,RobertLLoganIV,EricWallace,andSameerSingh.AutoPrompt:Elicitingknowledgefromlanguagemodelswithautomaticallygeneratedprompts.InEMNLP,2020.[63]MohammadShoeybi,MostofaPatwary,RaulPuri,PatrickLeGresley,JaredCasper,andBryanCatanzaro.Megatron-lm:Trainingmulti-billionparameterlan-guagemodelsusingmodelparallelism.arXivpreprintarXiv:1909.08053,2019.[64]RezaShokriandVitalyShmatikov.Privacy-preservingdeeplearning.InACMCCS,2015.[65]RezaShokri,MarcoStronati,CongzhengSong,andVi-talyShmatikov.Membershipinferenceattacksagainstmachinelearningmodels.InIEEES&P,2017.[66]CongzhengSongandAnanthRaghunathan.Informationleakageinembeddingmodels.InACMCCS,2020.[67]CongzhengSongandVitalyShmatikov.Auditingdataprovenanceintext-generationmodels.InKDD,2018.[68]OmThakkar,SwaroopRamaswamy,RajivMathews,andFrançoiseBeaufays.Understandingunintendedmemorizationinfederatedlearning.arXivpreprintarXiv:2006.07490,2020.[69]AbhradeepGuhaThakurta,AndrewH.Vyrros,UmeshS.Vaishampayan,GauravKapoor,JulienFreudi-ger,VivekRangarajanSridhar,andDougDavidson.Learningnewwords,2017.USPatent9,594,741.[70]AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.Attentionisallyouneed.InNIPS,2017.[71]KitWalsh.USPTOrequestforcommentsonintellectualpropertyprotectionforartiﬁcialintelligenceinnovation–publiccommentbytheelectronicfrontierfounda-tion.https://www.uspto.gov/sites/default/files/documents/Electronic%20Frontier%20Foundation_RFC-84-FR-58141.PDF,2020.16[72]SamuelYeom,IreneGiacomelli,MattFredrikson,andSomeshJha.Privacyriskinmachinelearning:Analyz-ingtheconnectiontooverﬁtting.InIEEECSF,2018.[73]SantiagoZanella-Béguelin,LukasWutschitz,ShrutiTople,VictorRühle,AndrewPaverd,OlgaOhrimenko,BorisKöpf,andMarcBrockschmidt.Analyzinginfor-mationleakageofupdatestonaturallanguagemodels.InACMCCS,2020.[74]RowanZellers,AriHoltzman,HannahRashkin,YonatanBisk,AliFarhadi,FranziskaRoesner,andYejinChoi.Defendingagainstneuralfakenews.InNeurIPS,2019.[75]ChiyuanZhang,SamyBengio,MoritzHardt,BenjaminRecht,andOriolVinyals.Understandingdeeplearningrequiresrethinkinggeneralization.ICLR,2017.[76]YizheZhang,SiqiSun,MichelGalley,Yen-ChunChen,ChrisBrockett,XiangGao,JianfengGao,JingjingLiu,andBillDolan.DialoGPT:Large-scalegenerativepre-trainingforconversationalresponsegeneration.InACLDemoTrack,2020.ACategorizationofMemorizedDataTable5describesthehigh-levelcategoriesthatweassignedtothe604memorizedsamplesextractedfromGPT-2.Notethatasinglesamplecanbelongtomultiplecategories.Tables6and7(omittedforspace)showthecategorizationbrokendownbyattackstrategy.BDistributionofModelPerplexitiesFigure4showsthedistributionoftheperplexitiesofsamplesgeneratedwitheachofourthreetextgenerationstrategiesandorderedbasedonoursixmembershipinferencestrategies.CAdditionalCaseStudiesofMemorizationHerewepresentadditionalresultsfromourmanualanalysisofthememorizedcontent.MemorizedLeakedPodestaEmailsfromWikiLeaks.WeidentifyseveralmemorizedURLsthatoriginatedfromtheleakedPodestaEmailsavailableonWikiLeaks13.ThereisonlyonetrainingdocumentthatcontainsthesememorizedURLs.Duetothenatureofemail,thetextofonemessageisoftenincludedinsubsequentrepliestothisemail.Asaresult,aURLthatisused(intentionally)onlyoncecanbeincludedinthedatasettensoftimesduetothereplies.13https://en.wikipedia.org/wiki/Podesta_emailsMemorizedDonaldTrumpQuotesandTweets.TheGPT-2trainingdatasetwascollectedwhenthe2016USPres-identialelectionwasofteninthenews.Asaresult,weﬁndseveralinstancesofmemorizedquotesfromDonaldTrump,bothintheformofofﬁcialremarksmadeasPresident(foundintheofﬁcialgovernmentrecords),aswellasstatementsmadeonTwitter.MemorizedPromotionalContent.Weextractmemorizedsamplesofpromotionalcontent,suchasadvertisementsforbooks,beautyproducts,softwareproducts.Oneofthesesam-plesincludesalinktoanauthor’svalidPatreonaccount,alongwithalistofnamedandpseudonymouspriordonors.MemorizedNumberSequences.Weidentifymanyex-ampleswhereGPT-2emitscommonnumbersequences.Nearlytenexamplescontaintheintegerscountingupfromsomespeciﬁcvalue.Wealsoﬁndexam-plesofGPT-2countingthesquares1,2,4,8,16,25,36,Fibonaccinumbers1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,ordigitsofπ,3.14159265358979323846264.Noneoftheseexamplesshouldbeunexpected,butthequantityofmemorizednumbersequenceswassurprisingtous.MemorizedNewsHeadlines.Numerousmemorizedtextsnippetsareverbatimcopiesofnewsarticlesandheadlines.Alargenumberofthesememorizedsamplesareattributedtoasinglesource:thehill.com,anAmericannewswebsite.Interestingly,mostofthesesamplesfollowtheexactsametemplate:(1)theycontainalistofdifferentnewsheadlinesseparatedbya“pipe”symbol(|),(2)thesamplebeginswithtwomergedwords,e.g.,“TrumpJesuit”,(3)theheadlinelistendswiththeall-capsword“MORE”,and(4)thesamplecontainstheall-capsword“ADVERTISEMENT”.WeindeedﬁndpagesontheWebthatcontaincopiesofheadlinesfromthehill.comunderthisexacttemplate.Thepeculiaritiesofthesesnippetslikelycontributedtotheirmem-orization.Forexample,thetokenTrumpJesuitdoesnotappearinanyothercontextontheentireWeb.MemorizedBase-64Content.OneparticularlyinterestingformofmemorizationthatweidentifyistheabilityofGPT-2toemitbase-64encodedcontent.Forexample,weextractoutofthemodelthefollowingsequence:bWFzdGVyfGltYWdlc3w3OTkxOXxpbWFnZS9wbmd8aW1hZ2VzL2hkZS9oMDQvODg0NTY3MjYxMTg3MC5wbmd8ZmFkMTMlNmFiYWJhZjFiMjJlYTAyNzU0Zwhichdecodestothesequence“master|images|79919|image/png|images/hde/h04/8845672611870.png|...”.Despiteourat-tempts,weareunabletoidentifywherethiscontentoriginates.17(a)Top-n(2.6%duplicates)(b)Internet(7.1%duplicates)(c)Temperature(0.6%duplicates)Figure4:Foreachofourthreetextgenerationstrategies(Top-n,InternetandTemperature),wegenerate200,000samplesusingGPT-2andapplyade-duplicationprocedure.Thetwoleft-mostplotsshowthedistributionofperplexitiesforthefullsample,andthemostlikelywindowof50tokens.TheremainingplotscomparethedistributionofperplexitiesofGPT-2toothermeasureofsamplelikelihood:zlibentropy,perplexityunderGPT-2SmallandGPT-2Medium,andperplexityoflower-casedsamples.Eachplothighlightsthe100samplesweselectedformanualinspection(red)andthesubsetthatwasconﬁrmedasmemorized(blue).CategoryCountDescriptionUSandinternationalnews109Generalnewsarticlesorheadlines,mostlyaboutUSpoliticsLogﬁlesanderrorreports79LogsproducedbysoftwareorhardwareLicense,termsofuse,copyrightnotices54Softwarelicensesorwebsitetermsofuse,copyrightforcode,books,etc.Listsofnameditems54Orderedlists,typicallyalphabetically,ofgames,books,countries,etc.ForumorWikientry53UserpostsononlineforumsorentriesinspeciﬁcwikisValidURLs50AURLthatresolvestoalivepageNamedindividuals46Samplesthatcontainnamesofrealindividu-als.Welimitthiscategorytonon-newssam-ples.E.g.,wedonotcountnamesofpoliti-ciansorjournalistswithinnewsarticlesPromotionalcontent45Descriptionsofproducts,subscriptions,newsletters,etc.Highentropy35Randomcontentwithhighentropy,e.g.,UUIDsBase64data,etc.CategoryCountDescriptionContactinfo32Physicaladdresses,emailaddresses,phonenumbers,twitterhandles,etc.Code31Snippetsofsourcecode,includingJavaScriptConﬁgurationﬁles30Structuredconﬁgurationdata,mainlyforsoftwareproductsReligioustexts25ExtractsfromtheBible,theQuran,etc.Pseudonyms15ValidusernamesthatdonotappeartobetiedtoaphysicalnameDonaldTrumptweetsandquotes12QuotesandtweetsfromDonaldTrump,of-tenfromnewsarticlesWebforms11Listsofusermenuitems,Websiteinstruc-tions,navigationprompts(e.g.,“pleaseenteryouremailtocontinue”)Technews11NewsrelatedtotechnologyListsofnumbers10Listsofdates,numbersequences,π,etc.Sportsnews9NewsrelatedtosportsMoviesynopsis,cast5Listofactors,writers,producers.Plotsyn-opsis.Pornography5Contentofpornographicnature,oftenlistsofadultﬁlmactors.Table5:Descriptionsforthecategoriesofmemorizedtext.Categoriesinboldcorrespondtopersonallyidentiﬁableinformation.18CategoryCountUSandinternationalnews88ForumorWikientry34License,termsofuse,copyrightnotice28Namedindividuals25Promotionalcontent18Listsofnameditems15Contactinfo20DonaldTrumptweetsandquotes12Pseudonyms7ValidURLs7Sportsnews6Moviesynopsisorcast6(a)Top-n(191samples)CategoryCountLogﬁlesanderrorreports86Listsofnameditems53ValidURLs40License,termsofuse,copyrightnotice36Highentropy33Conﬁgurationﬁles32Code29Namedindividuals18Promotionalcontent14Contactinfo12Pseudonyms11ForumorWikientry9USandinternationalnews7Technews7Pornography5Webforms5Listsofnumbers5(b)Internet(273samples)CategoryCountUSandinternationalnews31Religioustexts28License,termsofuse,copyrightnotice24Promotionalcontent20ForumorWikientry17Namedindividuals12Listsofnameditems12ValidURLs12Technews8Contactinfo8Highentropy6Listsofnumbers6(c)Temperature(140samples)Table6:Memorizedcontentfoundinsamplesproducedbyeachoftheourthreetextgenerationstrategies.Weshowcategorieswithatleast5samples.CategoryCountLicense,termsofuse,copyrightnotice11Listsofnameditems8Logﬁlesanderrorreports7ValidURLs6Listsofnumbers5(a)Perplexity(51samples)CategoryCountUSandinternationalnews21Listsofnameditems18License,termsofuse,copyrightnotice16Promotionalcontent11ValidURLs11Logﬁlesanderrorreports10Namedindividuals8Highentropy8ForumorWikientry7Conﬁgurationﬁles6Code6(b)Window(119samples)CategoryCountUSandinternationalnews40License,termsofuse,copyrightnotice31Listsofnameditems17ForumorWikientry14Namedindividuals13Promotionalcontent13Contactinfo12Logﬁlesanderrorreports11ValidURLs10Code10Technews6Conﬁgurationﬁles6Pseudonyms5(c)zlib(172samples)CategoryCountUSandinternationalnews39Logﬁlesanderrorreports29Listsofnameditems17ForumorWikientry12Namedindividuals11License,termsofuse,copyrightnotice10Highentropy9Conﬁgurationﬁles6Promotionalcontent5Technews5(d)Lowercase(135samples)CategoryCountLogﬁlesanderrorreports17ForumorWikientry15Religioustexts14ValidURLs13Highentropy13Listsofnameditems12License,termsofuse,copyrightnotice12Promotionalcontent11Conﬁgurationﬁles11Namedindividuals11other9USandinternationalnews9Contactinfo8DonaldTrumptweetsandquotes7Code6(e)Small(141samples)CategoryCountValidURLs17Logﬁlesanderrorreports14USandinternationalnews13Contactinfo12Religioustexts12Namedindividuals11Promotionalcontent11Highentropy10ForumorWikientry9Listsofnameditems8License,termsofuse,copyrightnotice8Code5DonaldTrumptweetsandquotes5(f)Medium(116samples)Table7:Memorizedcontentfoundusingoursixmembershipinferencestrategies.Weshowcategorieswithatleast5samples.19
