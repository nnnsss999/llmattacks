---
title: https://aclanthology.org/2024.findings-emnlp.692/
source_url: https://aclanthology.org/2024.findings-emnlp.692/
date_collected: '2025-06-19'
license: Fair Use
---

Virtual Context Enhancing Jailbreak Attacks with Special Token Injection - ACL Anthology

[![ACL Logo](https://aclanthology.org/images/acl-logo.svg)
ACL Anthology](https://aclanthology.org/)


* [News(current)](/posts/)
* [FAQ(current)](/faq/)
* [Corrections(current)](/info/corrections/)
* [Submissions(current)](/info/contrib/)
* [Github](https://github.com/acl-org/acl-anthology/)

## [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692.pdf)

[Yuqi Zhou](/people/y/yuqi-zhou/),
[Lin Lu](/people/l/lin-lu/),
[Ryan Sun](/people/r/ryan-sun/),
[Pan Zhou](/people/p/pan-zhou/),
[Lichao Sun](/people/l/lichao-sun/)

##### Correct Metadata for

×

**Important**: The Anthology treat PDFs as authoritative. Please use this form only to correct data that is out of line with the PDF. See [our corrections guidelines](https://aclanthology.org/info/corrections/) if you need to change the PDF.

Title
Adjust the title. Retain tags such as <fixed-case>.

Authors
Adjust author names and order to match the PDF.Add Author

Abstract
Correct abstract if needed. Retain XML formatting tags such as <tex-math>.

Verification against PDF
Ensure that the new title/authors match the snapshot below. (If there is no snapshot or it is too small, consult [the PDF](#).)

[![]()](#)

Authors concatenated from the text boxes above:

ALL author names match the snapshot above—including middle initials, hyphens, and accents.

Submit

---

##### Abstract

Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40% across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security.

Anthology ID:
:   2024.findings-emnlp.692

Volume:
:   [Findings of the Association for Computational Linguistics: EMNLP 2024](/volumes/2024.findings-emnlp/)

Month:
:   November

Year:
:   2024

Address:
:   Miami, Florida, USA

Editors:
:   [Yaser Al-Onaizan](/people/y/yaser-al-onaizan/),
    [Mohit Bansal](/people/m/mohit-bansal/),
    [Yun-Nung Chen](/people/y/yun-nung-chen/)

Venue:
:   [Findings](/venues/findings/)

SIG:


Publisher:
:   Association for Computational Linguistics

Note:


Pages:
:   11843–11857

Language:


URL:
:   <https://aclanthology.org/2024.findings-emnlp.692/>

DOI:
:   [10.18653/v1/2024.findings-emnlp.692](https://doi.org/10.18653/v1/2024.findings-emnlp.692 "To the current version of the paper by DOI")

Bibkey:
:   zhou-etal-2024-virtual

Cite (ACL):
:   Yuqi Zhou, Lin Lu, Ryan Sun, Pan Zhou, and Lichao Sun. 2024. [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692/). In *Findings of the Association for Computational Linguistics: EMNLP 2024*, pages 11843–11857, Miami, Florida, USA. Association for Computational Linguistics.

Cite (Informal):
:   [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692/) (Zhou et al., Findings 2024)

Copy Citation:
:   BibTeX
    Markdown
    MODS XML
    Endnote
    More options…

PDF:
:   <https://aclanthology.org/2024.findings-emnlp.692.pdf>

[PDF](https://aclanthology.org/2024.findings-emnlp.692.pdf "Open PDF of 'Virtual Context Enhancing Jailbreak Attacks with Special Token Injection'")[Cite](# "Open dialog for exporting citations")[Search](https://www.semanticscholar.org/search?q=Virtual+Context+Enhancing+Jailbreak+Attacks+with+Special+Token+Injection "Search for 'Virtual Context Enhancing Jailbreak Attacks with Special Token Injection' on Semantic Scholar")[Fix data](# "Correct problems with title, author list, and abstract")

---

##### Export citation

×

* [BibTeX](#citeBibtex)
* [MODS XML](#citeMods)
* [Endnote](#citeEndnote)
* [Preformatted](#citeMarkdown)

```
@inproceedings{zhou-etal-2024-virtual,
    title = "Virtual Context Enhancing Jailbreak Attacks with Special Token Injection",
    author = "Zhou, Yuqi  and
      Lu, Lin  and
      Sun, Ryan  and
      Zhou, Pan  and
      Sun, Lichao",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.692/",
    doi = "10.18653/v1/2024.findings-emnlp.692",
    pages = "11843--11857",
    abstract = "Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40{\%} across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security."
}
```

Download as File
Copy to Clipboard

```
<?xml version="1.0" encoding="UTF-8"?>
<modsCollection xmlns="http://www.loc.gov/mods/v3">
<mods ID="zhou-etal-2024-virtual">
    <titleInfo>
        <title>Virtual Context Enhancing Jailbreak Attacks with Special Token Injection</title>
    </titleInfo>
    <name type="personal">
        <namePart type="given">Yuqi</namePart>
        <namePart type="family">Zhou</namePart>
        <role>
            <roleTerm authority="marcrelator" type="text">author</roleTerm>
        </role>
    </name>
    <name type="personal">
        <namePart type="given">Lin</namePart>
        <namePart type="family">Lu</namePart>
        <role>
            <roleTerm authority="marcrelator" type="text">author</roleTerm>
        </role>
    </name>
    <name type="personal">
        <namePart type="given">Ryan</namePart>
        <namePart type="family">Sun</namePart>
        <role>
            <roleTerm authority="marcrelator" type="text">author</roleTerm>
        </role>
    </name>
    <name type="personal">
        <namePart type="given">Pan</namePart>
        <namePart type="family">Zhou</namePart>
        <role>
            <roleTerm authority="marcrelator" type="text">author</roleTerm>
        </role>
    </name>
    <name type="personal">
        <namePart type="given">Lichao</namePart>
        <namePart type="family">Sun</namePart>
        <role>
            <roleTerm authority="marcrelator" type="text">author</roleTerm>
        </role>
    </name>
    <originInfo>
        <dateIssued>2024-11</dateIssued>
    </originInfo>
    <typeOfResource>text</typeOfResource>
    <relatedItem type="host">
        <titleInfo>
            <title>Findings of the Association for Computational Linguistics: EMNLP 2024</title>
        </titleInfo>
        <name type="personal">
            <namePart type="given">Yaser</namePart>
            <namePart type="family">Al-Onaizan</namePart>
            <role>
                <roleTerm authority="marcrelator" type="text">editor</roleTerm>
            </role>
        </name>
        <name type="personal">
            <namePart type="given">Mohit</namePart>
            <namePart type="family">Bansal</namePart>
            <role>
                <roleTerm authority="marcrelator" type="text">editor</roleTerm>
            </role>
        </name>
        <name type="personal">
            <namePart type="given">Yun-Nung</namePart>
            <namePart type="family">Chen</namePart>
            <role>
                <roleTerm authority="marcrelator" type="text">editor</roleTerm>
            </role>
        </name>
        <originInfo>
            <publisher>Association for Computational Linguistics</publisher>
            <place>
                <placeTerm type="text">Miami, Florida, USA</placeTerm>
            </place>
        </originInfo>
        <genre authority="marcgt">conference publication</genre>
    </relatedItem>
    <abstract>Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40% across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security.</abstract>
    <identifier type="citekey">zhou-etal-2024-virtual</identifier>
    <identifier type="doi">10.18653/v1/2024.findings-emnlp.692</identifier>
    <location>
        <url>https://aclanthology.org/2024.findings-emnlp.692/</url>
    </location>
    <part>
        <date>2024-11</date>
        <extent unit="page">
            <start>11843</start>
            <end>11857</end>
        </extent>
    </part>
</mods>
</modsCollection>

```

Download as File
Copy to Clipboard

```
%0 Conference Proceedings
%T Virtual Context Enhancing Jailbreak Attacks with Special Token Injection
%A Zhou, Yuqi
%A Lu, Lin
%A Sun, Ryan
%A Zhou, Pan
%A Sun, Lichao
%Y Al-Onaizan, Yaser
%Y Bansal, Mohit
%Y Chen, Yun-Nung
%S Findings of the Association for Computational Linguistics: EMNLP 2024
%D 2024
%8 November
%I Association for Computational Linguistics
%C Miami, Florida, USA
%F zhou-etal-2024-virtual
%X Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40% across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security.
%R 10.18653/v1/2024.findings-emnlp.692
%U https://aclanthology.org/2024.findings-emnlp.692/
%U https://doi.org/10.18653/v1/2024.findings-emnlp.692
%P 11843-11857
```

Download as File
Copy to Clipboard

##### Markdown (Informal)

[Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692/) (Zhou et al., Findings 2024)

* [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692/) (Zhou et al., Findings 2024)

##### ACL

* Yuqi Zhou, Lin Lu, Ryan Sun, Pan Zhou, and Lichao Sun. 2024. [Virtual Context Enhancing Jailbreak Attacks with Special Token Injection](https://aclanthology.org/2024.findings-emnlp.692/). In *Findings of the Association for Computational Linguistics: EMNLP 2024*, pages 11843–11857, Miami, Florida, USA. Association for Computational Linguistics.

Copy Markdown to Clipboard
Copy ACL to Clipboard

[![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)](http://creativecommons.org/licenses/by/4.0/)
ACL materials are Copyright © 1963–2025 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

The ACL Anthology is managed and built by the [ACL Anthology team](/info/credits/) of volunteers.

*Site last built on 19 June 2025 at 01:07 UTC with [commit b82b874](https://github.com/acl-org/acl-anthology/tree/b82b8741847c67f20b3e5737891b3eb4ed471c23).*
