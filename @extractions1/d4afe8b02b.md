---
title: https://alphaxiv.org
source_url: https://alphaxiv.org
date_collected: '2025-06-19'
license: Fair Use
---

Explore | alphaXiv

[alphaXiv](/)

### Explore

### Communities

### Login

[### Get extension](https://chromewebstore.google.com/detail/alphaxiv-open-research-di/liihfcjialakefgidmaadhajjikbjjab)

[Blog](/blog)|[Changelog](/changelog)|[Feedback](/channels/alphaxiv-feedback)|[Research Site](https://alphaxiv.io)|[Comment Guidelines](/commentguidelines)|[About Us](/about)

[#### Papers](/explore)[#### Activity](/activity)[#### People](/people)[#### Assistant](/assistant)

## Discover, Discuss, and Read arXiv papers

![Discover new, recommended papers](/assets/login-banner-discover.png)![Discover new, recommended papers](/assets/login-banner-discover.gif)

### Discover new, recommended papers

Create Account

All

Pinned

Browse

Browse

Suggested

test-time-inferenceagentsreasoning

## Filters

Hot

â€¢Showing all papers

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.13585v1.png)

2,725

16 Jun 2025

transformersefficient-transformersreinforcement-learning

[## MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention](/abs/2506.13585)

MiniMax

MiniMax developed MiniMax-M1, a large reasoning model leveraging a hybrid Mixture-of-Experts architecture with Lightning Attention to enable efficient scaling of test-time compute for extremely long contexts. It supports up to 1 million input tokens and 80,000 generation tokens while achieving substantial FLOPs reduction and competitive performance across various reasoning benchmarks.

Problem

Method

Results

Takeaways

Bookmark

84

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.13284v1.png)

526

16 Jun 2025

reasoningreinforcement-learningfine-tuning

[## AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](/abs/2506.13284)

![NVIDIA logo](https://static.alphaxiv.org/images/organizations/nvidia.png)NVIDIA

NVIDIA researchers developed AceReason-Nemotron 1.1, a Qwen2.5-7B based model, by systematically investigating the synergy between supervised fine-tuning (SFT) and reinforcement learning (RL) to enhance math and code reasoning. The model achieved new state-of-the-art performance for its size on challenging benchmarks like AIME25 (64.8%) and LiveCodeBench v6 (52.1%).

Problem

Method

Results

Takeaways

Bookmark

28

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.14758v1.png)

280

17 Jun 2025

reasoningreinforcement-learningdeep-reinforcement-learning

[## Reasoning with Exploration: An Entropy Perspective](/abs/2506.14758)

![Renmin University of China logo](https://static.alphaxiv.org/images/organizations/renmin.png)Renmin University of ChinaShanghai Jiao Tong University![Microsoft logo](https://static.alphaxiv.org/images/organizations/microsoft.png)MicrosoftBeijing Institute for General Artificial Intelligence

A method introduces entropy-based advantage shaping to enhance large language model reasoning, explicitly encouraging exploration during reinforcement learning fine-tuning. This approach leads to more robust, multi-step reasoning, achieving substantial gains in Pass@K scores on challenging mathematical benchmarks.

Problem

Method

Results

Takeaways

Bookmark

14

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.13759v1.png)

398

16 Jun 2025

generative-modelstransformersmulti-modal-learning

[## Discrete Diffusion in Large Language and Multimodal Models: A Survey](/abs/2506.13759)

National Univerisity of Singapore

This survey details discrete diffusion models as an emerging alternative to autoregressive models in large language and multimodal contexts, demonstrating competitive performance with up to 10x faster inference speeds through parallel decoding. The work consolidates the field's mathematical foundations, key models, and advanced techniques, highlighting broad applicability across generative AI tasks.

Problem

Method

Results

Takeaways

Bookmark

27

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.10943v1.png)

5,073

12 Jun 2025

continual-learningfine-tuningreinforcement-learning

[## Self-Adapting Language Models](/abs/2506.10943)

![MIT logo](https://static.alphaxiv.org/images/organizations/mit.jpg)MIT

The Self-Adapting Language Models (SEAL) framework enables Large Language Models (LLMs) to autonomously adapt their internal knowledge and capabilities by generating their own training data and finetuning directives. From MIT's Improbable AI Lab, SEAL demonstrates a 72.5% success rate in few-shot learning tasks and achieves 47.0% accuracy in knowledge incorporation, outperforming synthetic data generated by GPT-4.1.

Problem

Method

Results

Takeaways

Bookmark

187

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.09250v2.png)

24,433

16 Jun 2025

reasoningtransformersagents

[## Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](/abs/2506.09250)

Open Philanthropy

A. Lawsen's paper re-evaluates claims of an "accuracy collapse" in Large Reasoning Models (LRMs) on planning puzzles, demonstrating that perceived failures stem from experimental design flaws rather than inherent model limitations. The work shows that LRMs can solve complex problems like Tower of Hanoi with 15 disks when evaluated with flexible output formats, indicating maintained reasoning capabilities.

Problem

Method

Results

Takeaways

Bookmark

402

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.13351v1.png)

278

16 Jun 2025

reasoningreinforcement-learningfine-tuning

[## Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks](/abs/2506.13351)

University of California, Los Angeles![Microsoft logo](https://static.alphaxiv.org/images/organizations/microsoft.png)Microsoft

Researchers from Microsoft and UCLA developed Direct Reasoning Optimization (DRO), an RL-based framework that allows large language models to self-refine their reasoning for open-ended tasks by using a novel internal Reasoning Reflection Reward (R3). This method leverages the model's self-certainty about a reference outcome given its Chain-of-Thought, leading to superior reasoning quality on tasks like paragraph revision and comparable performance to explicit verifiers on structured QA.

Problem

Method

Results

Takeaways

Bookmark

20

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.12609v1.png)

413

14 Jun 2025

vision-language-modelsattention-mechanismstransformers

[## Not All Tokens and Heads Are Equally Important: Dual-Level Attention Intervention for Hallucination Mitigation](/abs/2506.12609)

![Peking University logo](https://static.alphaxiv.org/images/organizations/peking.png)Peking University

Researchers at Peking University developed VisFlow, a training-free framework that mitigates visual hallucinations in Large Vision-Language Models (LVLMs) by intelligently manipulating attention patterns during inference, leading to improved factual accuracy on benchmarks like CHAIR and POPE. This approach intervenes at both token and head levels to enhance visual grounding and reduce reliance on linguistic priors, demonstrating efficiency comparable to standard decoding methods.

Problem

Method

Results

Takeaways

Bookmark

39

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.14202v1.png)

245

17 Jun 2025

generative-modelsparameter-efficient-trainingoptimization-methods

[## DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion](/abs/2506.14202)

Sakana AI

DiffusionBlocks, developed by Sakana AI, proposes a training framework for generative models that reinterprets neural network blocks as independent denoising operations within a continuous-time diffusion process. This approach achieves up to a 4x memory reduction during training while yielding competitive or superior performance on image generation (FID 15.55 on ImageNet-256) and language modeling (MAUVE 0.779 on LM1B).

Problem

Method

Results

Takeaways

Bookmark

15

![Paper thumbnail](https://paper-assets.alphaxiv.org/image/2506.14429v1.png)

185

17 Jun 2025

transformersgenerative-modelssequence-modeling

[## LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs](/abs/2506.14429)

Shanghai Jiao Tong UniversityFudan University

Fudan University and Shanghai AI Lab researchers conducted the first systematic analysis of long-context capabilities in diffusion-based Large Language Models (LLMs), observing stable perplexity and 'local perception' in extended contexts. They introduced LongLLaDA, a training-free method that effectively extends the context window of diffusion LLMs like LLaDA-8B by up to 6x, enabling near 100% recall at 24k tokens.

Problem

Method

Results

Takeaways

Bookmark

12

### Popular Communities

Login
