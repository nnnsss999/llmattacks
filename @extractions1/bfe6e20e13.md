---
title: http://arxiv.org/pdf/2411.18191
source_url: http://arxiv.org/pdf/2411.18191
date_collected: '2025-06-19'
license: Fair Use
---

InputSnatch:StealingInputinLLMServicesviaTimingSide-ChannelAttacksXinyaoZheng1,2,3,HushengHan1,2,3,ShangyiShi1,2,3,QiyanFang1,3,6,ZidongDu1,5,XingHu1,4*,QiGuo11SKLP,InstituteofComputingTechnology,ChineseAcademyofSciences2UniversityofChineseAcademyofSciences3CambriconTechnologies4ZGCLAB5ShanghaiInnovationCenterforProcessorTechnologies,SHIC6UniversityofScienceandTechnologyofChina{zhengxinyao22s,hanhusheng20z,shishangyi22s}@ict.ac.cn{qiyanfang}@mail.ustc.edu.cn{duzidong,guoqi,huxing}@ict.ac.cnAbstract—Largelanguagemodels(LLMs)possessextensiveknowledgeandquestion-answeringcapabilities,havingbeenwidelydeployedinprivacy-sensitivedomainslikefinanceandmedicalconsultation.DuringLLMinferences,cache-sharingmethodsarecommonlyemployedtoenhanceefficiencybyreusingcachedstatesorresponsesforthesameorsimilarinferencerequests.However,weidentifythatthesecachemechanismsposeariskofprivateinputleakage,asthecachingcanresultinobservablevariationsinresponsetimes,makingthemastrongcandidateforatiming-basedattackhint.Inthisstudy,weproposeanoveltiming-basedside-channelattacktoexecuteinputtheftinLLMsinference.Thecache-basedattackfacesthechallengeofconstructingcandidateinputsinalargesearchspacetohitandstealcacheduserqueries.Toaddressthesechallenges,weproposetwoprimarycomponents.TheinputconstructoremploysmachinelearningtechniquesandLLM-basedapproachesforvocabularycorrela-tionlearningwhileimplementingoptimizedsearchmechanismsforgeneralizedinputconstruction.Thetimeanalyzerimple-mentsstatisticaltimefittingwithoutliereliminationtoidentifycachehitpatterns,continuouslyprovidingfeedbacktorefinetheconstructor’ssearchstrategy.Weconductexperimentsacrosstwocachemechanismsandtheresultsdemonstratethatourapproachconsistentlyattainshighattacksuccessratesinvariousapplications.Ourworkhighlightsthesecu-rityvulnerabilitiesassociatedwithperformanceoptimizations,underscoringthenecessityofprioritizingprivacyandsecurityalongsideenhancementsinLLMinference.1.IntroductionSincethereleaseofChatGPT[86],largelanguagemodels(LLMs)havegarneredwidespreadattentionduetotheirexceptionalreasoningandnaturallanguagegenera-tioncapabilities,leadingtotheirextensiveapplicationinprivacy-sensitiveareassuchasmedical[117],finance[131],law[19],andofficeassistance[107].Thesemodelsdemon-strateremarkableproficiencyinunderstandingcomplexqueries,generatingcontextuallyappropriateresponses,andprovidingdomain-specificinsightsacrossvariousfields.Usersincreasinglyrelyontheseintelligentagentsforprivacy-criticalscenarioslikemedicaladvice,financialplan-ning,andlegalconsultationtasks.ThisgrowingdependenceonLLM-basedsystemsforprocessingsensitivepersonalinformationraisessignificantprivacyandsecurityconcerns.LLMs’privacyandsecurityarerapidlygainingattentionasthesemodelsbecomeincreasinglyintegratedintocom-mercialapplications.Buildingupontraditionaldeeplearningprivacyconcerns,theenhancedmemorizationcapabilitiesofLLMsexacerbateexistingprivacyriskssuchasmember-shipinferenceattacks(MIAs)[13],[71],[72],[106]andpersonallyidentifiableinformation(PII)leakage[55],[66],[108].Theserisksscaleproportionallywithmodelsize,aslargermodelsdemonstratestrongermemorizationoftrainingdata[13].Beyondthesetraditionalconcerns,LLMsintroduceanovelprivacychallenge:prompttheftattacks,whichthreatenintellectualpropertyrightsandpersonalprivacy.Theseprompttheftattackshaveemergedinvariousforms,in-cludingextractingsystempromptsbyadversarialprompt-ing[63],[91],[141],[144],invertingpromptsfromem-beddingvectors[16],[16],[59],[79],[105]ormodelresponses[67],[97],[101],[138],andrecoveringin-putpromptsbyexploitingnext-tokenprobabilitydistribu-tions[78]ortoken-lengthsequences[129].TheseattacksposesignificantriskstothegrowingpromptmarketplaceanduserprivacyindownstreamLLMapplications,particularlywhenpromptscontainsensitiveinformationorproprietaryinstructions.AlthoughpreviousworkshavedemonstratedtheprompttheftattacksinLLM-basedsystems,theyhaveseverallimitations:1)Inabilitytorecoverexactprivacy:currentapproachesrelyoneitherresponsefeatureanalysis[68],[101],[138]orembeddingvectors[16],[105],canonlyachievepartialsemanticrecovery.Thisisattributedtothecomplexityofestablishingpreciseinversemappingsinhigh-dimensionalspaces,resultinginthelossofcrucialinfor-mation.2)Limitedattackscenarios:existingattacksaredesignedforspecificapplicationsbasedontask-specificarXiv:2411.18191v2  [cs.CR]  29 Nov 2024methodologies[68],[101],[138].Whileeffectiveintheirtargeteddomains,thesespecializedapproachescannottransfertootherLLM-basedapplications,leadingtolimitedattackscenarios.3)Impracticalassumptions:currentattacksoftenrelyonunrealisticassumptions,suchaswhite-boxaccesstomodels[105]orunlimitedqueryingcapabilitiestoobtainnext-tokenprobabilitydistributionsacrosstheentirevocabulary[78].Inthiswork,wepresentInputSnatch,whichaddressesthelimitationsofexistingattacksbyexploitingtiming-basedsidechannelsarisingfromthecommonlyusedcache-sharingoptimization(prefixcachingandsemanticcaching).Prefixcaching[52],[56],[56],[139]enablesthereuseofcachedattentionstatesintwodifferentrequestswiththesameprefixprompts,havingbeenwidelydeployedintheindustryenvironment.Semanticcaching[7],[37],[61],[76]allowsrequestswithidenticalcontentorsimilarsemanticstosharecachedresponses,especiallyinLLMapplicationsequippedwithRetrieval-AugmentedGeneration(RAG).Ourprimaryobservationisthatdifferentrequestsonthesamecomputingnodessharethesamecache,whichresultsinanobservabletimereductionwhenmeetingsharingcriteria.Figure1illustratesapronouncedtimedifferencebetweenhitsandmisses,despitefluctuationscausedbyscheduleissuesandnetworkvariability.Theobservabletimedifferencesprovideattackhintsforattackerstoobtaincachestatesandinfersecretinputsofotherusers,potentiallydisclosingpersonalprivacyinformation,tradesecrets,orotherenterprisedata.Notedthat,ourproposedcache-basedattackvectorispow-erfulbecause(1)itenablesexactinputreconstructionduetothestrictmatchingrequirementsinprefixcaching,(2)itgeneralizeswellforitswideimplementationindiversemainstreamLLMinferencebackends[49],[49],[82]andAPIproviders[3],[4],[40],[54],[89],(3)itispracticalsincenoprivilegedaccessbeyondstandardAPIcapabilitiesisrequired.(a) Prefix caching            (b) Semantic caching            Figure1:TheprefilltimedifferencebetweencachehitsandmissesforvaryinginputlengthswithOpenAIAPIcallsGPT-4o-miniLLM.(a)PrefixcachingimplementedbyOpenAI.(b)SemanticcachingwithGPTCache.Thecache-basedattackrequiresinputconstructionforthedesiredcachehit.Forthispurpose,ourattackframeworkcomprisestwocomponents:aInputConstructor,whichgen-eratesinputsattemptingtohitcachedcontent,andtheTimeAnalyzer,whichdetermineswhetheramatchhasoccurredbasedonthemeasuredtime.However,fullyrecoveringpromptspresentseveralsignificantchallenges.First,thecomplexityofinputconstructionescalatesexponentiallyasthevocabularysizereaches1000,000tokens[115]andthecontextwindowscalesto128K[84],substantiallyincreas-ingthesearchspace.Second,theobservedtimesareinflu-encedbynoisecomingfromnetworklatencyandmemoryschedulingdelays,complicatingaccuratelydeterminingthecachestate.Moreover,practicaldeploymentconstraintssuchasavailablememory,ratelimit,andcache’sTimeToLive(TTL),poseadditionalchallengestoourattack.Toaddressthesechallenges,weintroduceacompre-hensivetiminganalysisframework.First,theframeworkestablishestemporalpatternsoftargetservicesbystrate-gicsamplingmethodandmitigatesnoiseinterferencewithproposedpointprocessingalgorithms.Second,tomitigatethelargesearchspaceissue,ourframeworkleveragesad-vancedmachinelearningtechniquestoextractcontextualinformationandsemanticrelationshipsfromopen-sourcedatasets,therebyenhancingconstructionefficiency.Besides,weincorporateamulti-stagecandidateevaluationprocesstoprioritizecandidatesexhibitinghighercachehitprobabili-ties.Intheprocess,theconstructedtextsundergoadaptivefilteringmechanismsandprobabilisticrankingalgorithmstooptimizetheselectionofhigh-potentialcandidateswhilemaintainingcomputationalefficiency.Experimentalevaluationsacrossdiversedeploymentsce-nariosdemonstratetheeffectivenessofourattackframe-work.Forrequestsofspecifiedlengths,ourtiminganalyzerachieves87.13%accuracyindeterminingcachehitprefixlengths.Inmedicalquestion-answeringsystemswithstaticpromptengineering,ourattacksachievea62%successrateinextractingexactdiseaseinputsand13.5%forpre-cisesymptomdescriptions.ForlegalconsultationservicesimplementingRAG,thesemanticextractionsuccessratesrangefrom43%to100%.Theseresultshighlightsignificantprivacyvulnerabilitiesacrossdeploymentcontexts,empha-sizingthecriticalbalancebetweenperformanceoptimizationandsecurityinLLMservices.Contributions.Themaincontributionsofthisworkare:•Firstsystematicinvestigationoftime-basedsidechannelsinLLMinferencecausedbycache-sharingoptimization,analyzingprivacyleakagerisksoftwocachemechanismsandexaminingtheirperformance-privacytrade-offs.•Implementationofacomprehensiveattackmethod-ologycombiningdiverseinputconstructionstrate-gies(MLmodels,LLM-basedanalysis,andopti-mizedsearch)withrobusttiminganalysis(statisticalfittingandanomalydetection),demonstratingeffec-tiveinputreconstructionacrossvariousdeploymentscenarios.•Developmentofarobustattackframeworkthatachieves62%successrateinexactpartialinputrecoveryand12.5%inexactcompleteinputex-traction,whiledemonstrating79.5%effectivenessinsemantic-levelcontentreconstructionunderreal-worlddeploymentconstraints.2.Background2.1.Transformer-BasedLLMInferenceTransformer-basedlargelanguagemodels(LLMs)suchasGPT-3[11]andPaLM[17]haverevolutionizednaturallanguageprocessingbyleveragingthetransformerarchitec-ture[121].Acorecomponentofthesemodelsistheself-attentionmechanism,whichenablesthecaptureoflong-rangedependenciesandcomplexcontextualrelationshipswithininputsequences.Theself-attentionmechanismmainlycontainsthepro-jectionandattentionoperations.GivenatokensequenceX=[x1,...,xn],eachtokenxiistransformedintoquery(qi),key(ki),andvalue(vi)vectorsthroughlearnedlinearprojectionsasqi=Wqxi,ki=Wkxi,vi=Wvxi,whereWq,Wk,andWvaretrainableweightmatrices.Then,theattentionoperationswithQ,K,andVarepro-cessedasshowninEuqation1.Afterthis,alinearlayerperformsre-projectiontogeneratetheinputforthenextlayer.Thecomputationalcomplexityofself-attentionin-creasesquadraticallywiththelengthofthetokens.Attention(Q,K,V)=softmax(cid:18)QK⊤√dk(cid:19)V(1)LLMsgeneratetextautoregressively,producingoneto-kenatatimeconditionedontheinitialpromptandtheprecedinggeneratedtokens.Thegenerationprocesstypi-callyinvolvestwophases:prefillanddecoding.Theprefillphasecomputesinputpromptsintermediatestates(keysandvalues)forinputpromptsandgeneratesthefirstnexttoken.Thedecodingphasegeneratesoutputtokensautore-gressivelyonebyoneuntilastoppingtokenismet.Duetodatadependencies,theautoregressivegenerationcannotbeparallelized,resultingintheunderutilizationofGPUresourcesandmemoryconstraints,contributingsignificantlytothelatencyofindividualrequests.It’simperativetoenhancemetricslikeTimeToFirstToken(TTFT)andTimePerOutputToken(TPOT),aslatencycanbecalculatedasLatency=TTFT+(TPOT∗N),whereNrepresentsthenumberofgeneratedtokens.2.2.CacheOptimizationinLLMInferenceLLMinferenceservicesdeployedonthecloudresourcesrequiremanagingahighvolumeofreal-timerequestswhileensuringhighthroughputandlowlatency.Theconcurrentrequestsarescheduledacrossdifferentcomputingnodesandcomputedinoptimizedbatching[20],[83]toincreasethroughput.ModernLLMsutilizetheKey-Value(KV)Cachemechanism[92]tooptimizeTPOTbystoringeachtoken’skeyandvaluevectorsaftertheirinitialcomputation.AspresentedinFigure2,whengeneratingtokenvectoron+k+1,theattentionstatesofprevioustokenscanbecachedtoavoidrecomputation.However,asthesequencelengthandbatchsizeincrease,theKVcacheconsumesmoreGPUmemory.ManyinferenceoptimizationstechnologiesTABLE1:CacheMechanismsComparisonofDifferentLLMAPIVendorsVendorStreamCachingMechanismsCacheLifetimeOpenAI[89]YPrefixCaching5-10minutesDeepSeek[23]YPrefixCachingHourstodaysAnthropicClaude[3]YPrefixCaching5minutesGoogleGemini[40]YPrefixCachingDefault1hourMoonShotKimi[77]YPrefixCachingCustomizationPortkey[93]YSemanticCachingDefault7daysGoogleCloud[98]YSemanticCachingUncertainMicrosoftAzure[4]YSemanticCachingUncertainUnKey[32]YSemanticCachingUncertainAmazon[54]YSemanticCachingUncertainhavebeenproposedtooptimizeKVCache,includingspar-sity[28],[143],[145],quantization[24],[34],[65],[99],[142],windowing[43],[134],andsharing[52],[56],[139],[148].LeadingLLMAPIprovidersextensivelyimplementcache-sharingmechanisms(detailedinTable1),whichcanbeclassifiedintoprefixandsemanticcachingapproaches,tooptimizeTTFTandmemoryutilizationthroughcross-requestcontentreuse.k 1k 2...kn+k×QKT×v1v2...vn+kV＝k 1k 2...kn+k×QKT×v1v2...vn+kV＝Values that will be taken from cacheWithout CacheWith Cacheqn+kValues that will be computed＝＝qn+kon+k+1qn+kk1qn+kk2...qn+kkn+kon+k+1qn+kk1qn+kk2...qn+kkn+kLonger TimeShorter TimeFigure2:Comparisonofself-attentioncomputationmecha-nisms.Thetraditionalapproach(upper)performsfullrecom-putationforeachtoken,whiletheKVcache(lower)reusesstoredkey-valuevectorstoaccelerateinference.TheKVCachereducesthecomputationalcomplexityperdecodingstepfromO(n2)toO(n).PrefixCaching.Prefixcaching[52],[56],[139],[148]reusestheKVcachewithidenticalprefixesacrossdifferentrequestsorwithinmultiplesequencesgeneratedfromasinglerequest.Forinstance,vLLM[56]introducesnon-contiguousmemoryallocationandefficientprefixsharingacrossdifferentsequences.Itisimportanttonotethatonlyconsistentcontentfromthebeginningqualifiesasaprefix;thesamesegmentsstartingmid-sequencecannotbematched.PrefixcachinghasbeenanindustrynormintegratedintomainstreaminferenceframeworkssuchasHuggingFaceTGI[49],NVIDIATensorRT-LLM[82],andLMDeployTurboMind[51].OthernotableimplementationsincludeSGLang[148],whichemploysaradixtreetoreusetheKVcacheinvariousscenarios,ChunkAttention[139],whichintroducesaprefix-awareKVcachepartitioningmechanism,andHydragen[52],whichefficientlymanagessharedprefixes.SemanticCaching.Semanticcachingmechanism[7],[37],[61],[76]enablesconsistentoutputsforidenticalorse-manticallysimilarqueries.Thisapproachoptimizesserverresourceutilization,minimizesdataretrievallatency,reducesAPIcosts,andenhancessystemscalability.Byleveragingembeddingsimilaritymetrics[149],[150],responsescanbereusedforsemanticallyequivalentqueries.Aprominentopen-sourceimplementation,GPTCache[7],demonstratesthisconceptbycachingrequest-responsepairs.Uponcachehits,thesystemdirectlyretrievesstoredresponses,reducingredundantLLMinvocationsandresponselatency.Recentresearchefforts[61],[76]havefocusedonenhancingse-manticcachingoptimizationstrategiestoimprovecachehitratesandminimizeoperationalcosts.However,thesecachingmechanismsarepotentialattacktargets,asdifferentusers’requestscansharethesamecachinginfrastructure.OurfocusisonstreamingresponsessupportedbytheAPIs,wheregeneratedtokensaresentbacksequentially,thusenablinguserstoreceivereal-timefeedbackandmeasureper-tokengenerationtimesprecisely.Wehavedesignedattackstrategiestargetingtwoscenar-ios,aimingtoextractinformationaboutinputpromptsbymeasuringtimingsidechannelsassociatedwiththecachemechanisms.Specifically,wefocusontwoapplicationsce-narios:staticpromptengineeringusingprefixcachingandRAGemployingsemanticcaching.Bytimingside-channelattacks,wecaninferpartialorcompleteinformationaboutuserinputs,posingasecuritythreatasunauthorizedaccesstosensitiveinputinformation.2.3.TargetedAttackScenariosManyapplicationsleverageLLMs’advancedreasoningandnaturalprocessingcapabilitiesbycustomizingmodelsforspecifictasks.TheyoftencombinetechnologiessuchaspromptengineeringorRetrieval-AugmentedGeneration(RAG)atahighlevel,offeringadvancedfunctionalityandexceptionaladaptabilityacrossvariousindustries,includinghealthcare[95],[103],[104],[120],[137],legalconsult-ing[19],[102],[110],[132],e-commerce[33],[42],[136],[151],andeducation[12],[64],[73],[130].PromptEngineering.Promptengineeringhasbecomein-dispensableforextendingthemodel’scapabilitiesthroughtask-specificinstructions,allowingintegrationintodown-streamtasks[94].Thesetechniquesincludefew-shotprompting[11],[35],[41],whereexamplesguidethemodel’sresponsesfornewtaskswithoutextensivetrain-ing;chain-of-thoughtprompting[60],[126],[146],[147],whichencouragesstep-by-stepreasoning.Recentstudieshaveshownthatcarefullycraftedpromptscansignificantlyimprovemodelperformanceacrossvarioustasks,fromques-tionanswering[100],[104],[113],[123]tocodegenera-tion[15],[26].Forexample,ChatGPTo1[88]leveragesreinforcementlearningtorefineitsCoTstrategies,allowingittoidentifyandcorrecterrorseffectively.Ourattackstrategyfocusesonapplicationsthatusestaticpromptengineering,likeGPTstore[87],whereuserscandesignsystempromptsforspecifictaskstodefinetheirapps.Userinputisusuallyembeddedorconcatenatedintothesystemprompt,whichcanbereusedwithprefixcaching.It’spossibletorecoverpartialorcompleteinputaccuratelyduetoKVCachesegmentedmanagementandpreciseprefixmatchingdeployedbymainstreaminferenceframeworks(asdetailedinsection4.2).RAG DatabasesUserEmbedding ModelSimilarity>Threshold?Semantic CacherequestMatched FilesLLM ServiceFileEmbeddingsVector Searchresponserequest<hash>: <requests>Longer TimeShorter TimeRequestsCache IndexVector SearchYNStoreCache Hit FlowCache Miss FlowTime-consuming Process<hash>: <responses>responseresponseFigure3:OverviewoftheRAG-assistedLLMsystemwiththesemanticcachingmechanism.Userqueriesarefirstmatchedagainstcachedrequestsbasedonsemanticsimi-larity.Responsesareretrieveddirectlyfromthecacheifthesimilarityscoreexceedsthethreshold;otherwise,thesystemproceedswithvectordatabaseretrievalandLLMinference.Retrieval-AugmentedGeneration(RAG).RAG[58]en-hancesLLMsbyretrievingrelevantexternalknowledgetoaddresstheinherentlimitationsofLLMs,includingknowl-edgeconstraintsandhallucinationissues.Thisapproachhasdemonstratedsignificantvalueacrossvariousdomains,includingimprovingaccuracyinmedicaldiagnostics[133]andlegalanalysis[53]andintegratingexternalinformationinopen-domainquestions[81],[124].However,eachinter-actionrequiringdataretrievalcanbecomputationallyinten-siveandtime-consuming,particularlywithlargedatasets.Developersexploitsemanticcachingtosolvelatencyandcostchallenges.AsillustratedinFigure3,incominguserrequestsaretranslatedintovectorsbyembeddingmodelsandcomparedagainstrequestembeddingvectorsthroughsemanticsimilaritycomputation.Ifthesimilarityscoreex-ceedsthepredefinedthreshold,thesystemdirectlyretrievesthecorrespondingresponsefromthesemanticcache,by-passingthetime-consumingretrievalandinferencestages.Whennosemanticallysimilarcachedqueriesarefound,thesystemfollowsthetraditionalpipeline:retrieverelevantpassagesfromthevectordatabase,whicharecombinedwiththeoriginalqueryvectorsandfedintoLLMsforresponsegeneration.Thissemanticcachingmechanismsignificantlyreducesresponselatencyforfrequentlyaskedquestions.Thedistincttemporalpatternsbetweencachehitsandmissescreateanobservabletimingdifferential,ascachinghitsmitigatecostlyretrievalandgenerationoperationslatency.Thisdiscrepancyinresponsetimespotentiallyrevealssensitiveinformationabouttheexistenceandnatureofpreviouslycachedre-quests.3.AttackHintsandThreatModel3.1.AttackHintsLLMinferencesystemsleveragecachingmechanismstooptimizecomputation,whilethecache-sharingstrategyinadvertentlyintroducesvulnerabilitiesfortime-basedside-channelattacks.AsdemonstratedinFigure1,despitesignifi-canttimingvariationsduetonetworklatencyandschedulingdelays,thereexistsevidenttimedifferencesinreal-worldAPIdeployments.Inthissection,weanalyzethetimingcharacteristicscausedbytwocachemechanismsatdifferentphases(prefillanddecodephase)todeterminethespecificattackvectorandattacktiming.Weadoptedtwopromi-nentopen-sourceimplementations:vLLM[56]andGPT-Cache[7]asourexperimentplatforms,whichwerechosenbasedontheirwidespreadadoption,activedevelopment,androbusttechnicalimplementations.Ourempiricalanalysisrevealeddistincttemporaldis-paritiesbetweenprefixcachehitsandmissesintheprefillanddecodephases.Basedonthisobservation,weselectedtheprefilltimeasaneffectiveattackvectorasitenablesearlyterminationoftheinferenceprocessafterthefirsttokengeneration,significantlyreducingtheoverallattackduration.AsillustratedinFigure4,ourexperimentsrevealdistincttimingpatternsbetweencachehitsandmisseswithnooverlappingorambiguouscasesobserved.Figure4(a)showsthatthetimingdifferenceintheprefillphasepositivelycorrelateswiththelengthofcachedrequests.Figure4(b)demonstratesthatthetimingdifferenceinthedecodephaseprimarilystemsfromthetimesavedbyreusinginputtokencomputations.(a)Prefill phase          (b) Decode phase        Figure4:Timedifferencebetweenhitsandmissesforprefixcaching:100experimentsinvLLMbyalocalAPIdeploy-mentusingtheLLaMa-270Bmodel.(a)Timeforinputwithvaryinglengthstakentogenerateonetoken.(b)Timeforinputwiththesamelengthtogeneratedifferentnumbersoftokens.Similarly,weidentifydistinguishabletemporalpatternsinsemanticcachingoperationsandselectprefilltimeastheattackvector.Whencachehitsoccur,theresponsesareretrievedfromthecache,eliminatingtheneedfortoken-by-tokengeneration.Thisresultsinnegligibleprefilltimeandoveralllatency,asdemonstratedinFigure5.Forcachemisses,theresponselatencyvariesdramaticallyfordifferentgeneratedtokens,whiletheprefilltimefluctuatesslightlyduetonetworklatency.(a)Prefill time(b) Response Latency   Figure5:Timedifferencebetweenhitsandmissesforsemanticcaching:conductedinGPTCachebyinvokingAPItoaccessGPT-4o-mini.(a)Timefordifferentinputswithvaryinglengthstogenerateonetoken.(b)Timeforinputwithvaryinglengthstogeneratecompleteresponses.Giventhecleartimedifferenceinbothprefixandse-manticcachingmechanisms,weselectedprefilltimeasourattackvector,allowingustominimizethetotalattackduration.WeconductedfurtherexperimentsacrossvariousconfigurationsasFigure6,witheachdatapointrepresentingtheaverageof30runsonvLLM.WhileourresultsindicatethatTTFTcorrelateswithmodelsize,hardwarespecifica-tions,tensorparallelismscale,andsamplingparameters,asignificanttimingdifferentialbetweenhitandmisspersistsacrossallexperimentalconfigurations.Thisinsightenablesustoconstructarobusttimeanalyzerthatcaneffectivelycharacterizeanddifferentiatecachingbehaviors,regardlessoftheunderlyingmodelarchitecture,hardwareconfigura-tions,orsamplingparametersininferencedeployments.3.2.ThreatModelAttackScenario.OurattackscenarioispresentedasFig-ure7,theapplicationwascustomizedbydeveloperstoinvoketheLLMsinferenceserviceprovidedbythecloudservicevendorthroughtheAPI.Ordinaryusersinteractwiththeinferenceservicethroughawebbrowserorotherappli-cationinterface,sendingtheirprivacyinputandreceivinggeneratedresponses.Thecommunicationchannelscanbeencryptedtoensuredatasecurity.Weconsiderthecloudinfrastructureoftenimplementssharedcachingmechanismsineachcomputingnode,whererequestsfrommultipleuserssharecachedstatesorre-sponses.Whencachehitsoccur,thecomputingnodescanbypasscomputationanddirectlyuseexistingcachedvaluestoimprovethroughputandreducelatency.Theexperimentalanalysisdemonstratesthatsystemswithlongsharedprefixesachievea70%-90%reductioninmemoryutilization[139]andsemanticcachingcaneffectivelyhandle20-30%ofuserqueries[109]inproductiondeployments.Attacker’sObjective.Theprimaryobjectiveoftheattackeristoconstructinputtomatchinputsfromnormalusersonthesamecomputingnode.Withmeasuredresponselatency,theattackercandeterminetheoccurrenceofcachehits,indicatingthesuccessfulmatchofanotheruser’sinput.Forcontextretentionandreusemaximization,requestsfromthesameuseraretypicallyroutedtothesamecomputingnode,whichenablesmultipleattemptsforattackers.Incases(a)Model Size(b)Tensor Parallel(c)Different GPUs(d)Different Parameters Figure6:Prefilltimecharacteristicsunderdifferentconfigurations.Thehorizontalaxisrepresentsthenumberofinputtokens,andtheverticalaxisrepresentstheprefilltime(s).(a)Threemodelsofdifferentparameterscales(LLaMa-38B[29],Qwen14B[5],andLLaMa-270B[119])deployedoneightA30GPUs.(b)LLaMa-38Bundervaryingtensorparallelismsizes(1,4,and8)acrossdifferentnumbersofA30GPUs.(c)LLaMa-270BdeployedacrosseightdifferentGPUarchitectures(A30,A100,andL40).(d)LLaMa-270BdeployedacrosseightA30withdifferentsamplingdiversity:low(temperature=0,topk=1,topp=1),medium(temperature=0.2,topk=2,topp=0.3),andhigh(temperature=1.0,topk=100,topp=1.0)."Age":** ,"Gender":** ,"Disease History":**,"Symptoms":**,VictimApplicationsCache SearchSecret InputsUSERLLM SERVICESATTACKERPrompt Constructor Time AnalyzerPromptTimesFeedback informationHitMissReuseComputeAPIAPIFigure7:Overviewofourattackscenario.UsersinteractwiththeLLMscloudservicethroughtheinteractioninter-face,anddifferentuserrequestsareroutedtosharethecachethroughencryptedAPIchannels.ofcachemisses,theattackeremploysaniterativerequestmodificationandresubmissionstrategy.Tomaintainattackaccuracyandpreventfalsepositives,avoidinginteractionswithpreviouslycachedcontentfromtheattacker’srequestsiscrucial.Therefore,eachconstructedinputquerymustincorporateuniqueprefixes,ensuringdistinctivecachesig-naturesacrossiterations.Notably,theattackersfocusonextractingprivateinputsfromuserssharingthesamecacheanddonottargetthevictimusers’identificationinformation.Attacker’sCapability.WeconsiderarealisticattackerwhoaccessestheLLMserviceasanordinaryuserthroughthepublicinterfacesprovidedbythecloudservice.Theattackerdoesnotpossessspecialprivilegesandisunawareofthetrainingdata,modelparameters,orspecifichardwareconfig-urations.Theattacker’scapabilitiesareconfinedtosendingrequestsandmeasuringtheresponsetimes,aspermittedbytheAPI.3.3.ChallengesThecontrolledexperimentsenableustoanalyzecache-relatedtimingcharacteristicsinanenvironmentfreefromremoteAPIandestablishafoundationforunderstandingexploitabletimingpatternsinreal-worldscenarios.Whileadversariescantheoreticallycraftinputpromptstoalignwithcachedcontentfromotherusers,severalsignificantchallengesemergeinreal-worldenvironments.ExpansiveSearchSpace.Modernlanguagemodelsmayin-corporatevocabularysizesexceeding100,000tokens[115],withcontextwindowsextendingtotwomilliontokens[25].Thisexponentialgrowthinsearchspacewithincreasinginputlengthrendersaccurateinputreconstructioncompu-tationallyintractable,presentingafundamentalchallengetoeffectiveinputconstruction.Moreover,thediversityofnaturallanguageexpressionsandthepotentialvariationsinuserpromptsfurtherexpandthissearchspace,makingexhaustiveexplorationimpracticalevenforrelativelyshortprompts.InterferencefromTimeNoise.Responsetimemeasure-mentsaresubjecttovariousenvironmentalfactors,includ-ingnetworklatencyandmemoryschedulingdelays.Theseexternalinfluencesintroducenoisethatobscuresthetruere-sponsetime,potentiallycompromisingtheaccuracyofcachestatusjudgment.Additionalfactorssuchasloadbalancing,resourcecontention,andsystemloadvariationscanfurthercomplicatetimingmeasurementsindistributedsystems.Thechallengebecomesparticularlyacuteincloud-baseddeploy-mentswheremultiplelayersofvirtualizationandsharedresourcesintroduceadditionaltiminguncertainties.Real-worldConstraints.Severalconstraintscomplicateourattack.Firstly,ratelimitsarecommonlyimposedtopreventAPIabuseandensurefairserviceforallusers,restrictingthenumberofattemptswecanmakewheninter-actingwiththeAPI.Secondly,limitedGPUmemoryandthecostsassociatedwithAPIusageconstrainthetotalnumberoftokensanattackercantry,preventingcontinuousattemptsthatmightevictthetargetrequestfrommemory.Finally,asnotedbyOpenAI,cachedcontenttypicallyremainsactiveduringinactivityperiodslastingfrom5to10minutesandcanpersistforuptoonehourduringoff-peakperiods[89].Consequently,thedurationoftheend-to-endattackislim-itedbythecache’sTimeToLive(TTL).Additionally,dynamicpricingmodelsandusagequotasimplementedbyserviceprovidersfurtherrestrictthefeasibilityoflarge-scaleattackattempts,whilesophisticatedrate-limitingalgorithmsmaydetectandblocksuspiciouspatternsofAPIusage.4.Attack1:PromptEngineeringThissectionintroducesourinputtheftattacksinap-plicationsassistedbypromptengineeringoptimizedwiththeprefixcachingmechanism.Wewilldemonstratetheef-fectivenessofourattacksthroughexperiments,highlightingtheprivacyinformationleakagerisksassociatedwithLLM-basedapplications.4.1.IntroductiontoAttackScenarioPromptengineeringmayinfluencethegenerativeper-formanceofLLMs[70],[96].Theparameterizedpromptisaformatofprompttemplatethatenablesdynamicvaluesubstitutionbasedonuserinput[38],whichhasbeenadvo-catedinapplicationssuchasGPTforWork[112]andvariouspromptgenerationutilities[2],[36].Inourattacks,thesystemsintegrateuser-providedinformationintopredefinedpositionswithinhiddenprompts,facilitatingpersonalizedresponsegeneration.Userinteractioninvolvessensitivedatasubmissions,suchasmedicalrecords,personalpreferences,financialinformation,andproprietarybusinessdata.WefocusonamedicalconsultationsysteminspiredbytheZuoshoudoctorplatform[116],whereusersprovidesensitiveinputacrosssixfieldsillustratedasFigure8.WhileAgeandGen-derfieldshavenumericalconstraints,theDiseaseHistoryandSymptomsfieldshaveunlimitedamountswithuser-customizableitems.Thesystemmaintainsconsistentitemorderingwhenpopulatingtheprompttemplatebasedonresearchindicatingtheimpactofinputsequencingongen-erationquality[18].Durationfieldacceptsfree-forminput.ChiefComplaintsofferstenpredeterminedoptionsbasedonthemodel’scapabilities,coveringaspectssuchastreatmentapproaches,medicationmanagement,dietaryconsiderations,etc.Forstandardizationpurposes,bothDiseaseHistoryandSymptomsarerestrictedto100characters,withplaceholdertextautomaticallyfillinganyunusedcapacity.4.2.AttackMethodologyOurattackframeworkcomprisestwoprimarycompo-nents:thetimeanalyzerandtheinputconstructor,asillus-tratedinFigure9.Duringtheofflineattackphase,theinputconstructorlearnstherelationshipsbetweeninputfieldsfromopen-sourcedatasets,andthetiminganalyzerobtainstheassociationbetweenresponsetimeandhitratiosbytheappropriatequery.Intheonlineattackphase,theconstructorgeneratestheinputsembeddedintothesystempromptforLLMinference.Theresponsetimeisthenmeasuredandfedintothetimeanalyzertodeterminewhetherthecurrentfieldishit.Medical Services   Please enter your consultation informationAgeGenderDisease HistorySymptomsDurationCustom inputChief Complaints     Please select from the drop-down menu     Please select from the drop-down menuCustom input▽     Please select from the drop-down menuCustom input▽▽Male   ×33       ×(Up to 5 inputs)(Up to 5 inputs)Input completed, please generate a response to my situationFigure8:Medicalconsultationinterface.Collectinguserin-formationthroughsixfields,featuringstructuredselectionsandflexiblecustominputs,supportingpredefinedoptionsandfree-formtextentryforfriendlyuserinteraction.Opensource DatasetsInput Dataset LearningVictim ServiceTTFTProcessingSamplingTime FittingOnline Attack StageTime AnalyzerAttack InputInference PromptMeasuredTimeHit RatioOffline Attack StageVictim ServiceInput ConstructorFigure9:Attackoverview.Theinputconstructorleveragesfieldcorrelationlearningtooptimizeonlineinputgenera-tion,whilethetiminganalyzerestablishestemporalpatternsduringtheofflinephasetofacilitateonlinetiminganalysis.Theinferencebackend,exemplifiedbyvLLM,employsblock-levelmemorymanagementfortheKVCache.Specif-ically,vLLMallocatesandmanagesKVCachememoryinfixed-sizeblocks,enablingefficientmemoryutilizationandcachemanagement.DifferentLLMserviceprovidersimplementvaryingblocksizes,OpenAIutilizes128-tokenblocks[89],whileDeepSeekemploys64-tokenblocks[23].Thestandardizedblock-basedcacheallowsustoverifycachehitsonablockgranularity,makingitpossibletoconductinputsfieldbyfieldsequentially.Oncewesuccess-fullyhitoneinputfield,thenextfieldcanbeconstructedgiventhecontext,significantlyreducingthesearchspaceandimprovingattackefficiency.TimeAnalyzer.Through30experimentaltrials,weana-lyzedtemporaldistributionpatterns,revealingdistinctre-sponsetimevariationscorrespondingtodifferentcacheblockhitcounts.AsillustratedinFigure10,theblueregionsrepresenttemporaldistributionsforcurrenthitblocks,withdistinguishabletimeintervalsenablinghitratioestimationforfield-levelconstruction.Theredregionshighlighttempo-raloverlapsbetweendifferenthitratios,presentingasignif-icantchallengeassimilarresponsetimesmaycorrespondtomultipledistincthitratios.Theseoverlappingpatternspredominantlyoccurbetweenadjacenthitblockcountsandareexacerbatedbytemporalnoisearisingfromconcurrentrequestprocessingandhardwareschedulingvariations.Thistemporalambiguityconstitutesafundamentalchallengetoourattackmethodology,necessitatingthedevelopmentofrobustpredictionstrategies.Figure10:RelationshipbetweenTTFTandhitblocks.Atotalof30experimentswereconductedwithapromptlengthof800tokens,whereeachblockconsistsof16tokens.Thegraylineindicatestheprefilltimenoblockhitsandthebluesectionrepresentsthetimerangefordifferenthitblocksobtainedfrommultipleexperiments.Theredsectionindicatestheoverlappingtimeintervalsfordifferenthitblockcounts,whicharepronetomisjudgment.Theprefillcomputationtimeexhibitsarelationshipcon-cerningthepromptlengthandhitratio,expressedastimeisproportionalto(n-k)×n,wherendenotesthetotaltokencountandkrepresentshittokencounts.Assumingminimalsystemnoise,thisrelationshipenablesprecisepredictionofhitratiosbasedonobservedresponsetimes.Duringtheofflinephase,weconductsamplingofthetargetser-vicetogetthisfunctionalrelationship,employingpost-processingtechniquestofilteranomalousmeasurements.Thenoiseisinherentandunavoidableduetosystemvaria-tionsandconcurrentrequestinterference.Insteadofmakingdeterministicpredictions,wemaintainmultiplecandidatehitratiosweightedbytheirlikelihoodgiventheobservedtime.Thisstatisticalframeworkproveseffectiveinpracticesinceadjacentinputfieldsareseparatedbymorethanoneblocklength,andfieldcontentcontainsmultipleblocks.Thesestructuralinputcharacteristicshelpisolatepotentialmisclassifications,preventingerrorpropagationfromblockstofieldsandensuringthatoccasionalblock-levelpredictionerrorsdonotsignificantlyimpacttheoverallattacksuccessrate.InputConstructor.Theblock-levelmanagementmecha-nismenableinputconstructortoconstructinputfield-by-field,asillustratedinFigure11.Whenconstructingthei−thfield,theprecedingfieldsremainunchanged,andthefollowingfieldsarerandomlyfilled.Subsequentfieldsareconstructediftheprecedingfieldshit.Ifthecurrentfieldfailstohit,theinputconstructorcontinuestogeneratedifferentalternativecontenttoavoiderroneoussuccessfuljudgmentscausedbyhittingpreviousattackinputs.Uponasuccessfulhitofthecurrentfield,theprocessadvancestoconstructingthenextfield.Theattackerlacksfine-grainedinformationcorrespond-ingtouserinputs,andexhaustivelysearchingthevocabularyspaceforeachpositionwouldresultinaprohibitivelylargesearchspace.Toreducethiscomplexity,weleverageopen-sourcedatasetstolearnpotentialfieldcontentsandtheirprobabilities.Weanalyzethesedatasetstoconstructatargetedvocabularysubsetforeachfieldbasedonitssemanticcontextandtypicalusagepatterns.Thiscontext-awareapproachsubstantiallynarrowsthesearchspacebyconsideringonlycontextuallyrelevanttokensratherthantheentirevocabulary.Furthermore,wecanreducethesearchspaceforsubsequentfieldsbycombininghitinputswiththelearnedfieldcorrelations,makingtheattackcomputationallyfeasible.Forexample,aspecificageorgenderisoftenstronglycorrelatedwithcertaindiseases,andknowndiseaseinformationcanaidinconstructingsubsequentsymptoms.③ The hit ratio is increased. Proceed to construct the next field.1~i-1i(miss)i~N① Predict the hit ratio based on time.1~i-1i(miss)i~N1~i-1i(miss)i~N1~i-1i(hit)i~N...1~ii+1i+1~N②Based on the time feedback and re-predict the current field.Figure11:Partialpredictionmechanismwithblockratioestimation.Theconstructionofthenextfieldcanonlyproceedafterhittingthecurrentfield.4.3.ExperimentalSetupExperimentalSetup.WeconductexperimentsonvLLM0.6.2astheLLMinferenceframework,whichimplementsblock-basedmemorymanagementandprefixcaching.Wesimulatemulti-userscenariosbyinvokingtheOpenAI-compatiblelocalAPIthroughvariousprocesses.Theat-tackercontinuouslyattemptstoconstructinputtohitcachedcontentfromotheruserswithinthesamecomputingnode.WedeployLLaMA-270Bastheservicemodelonan8×A40GPUcluster(40GBmemoryperGPU),representingatypicalproductiondeployment.Themodelisconfiguredwithdeterministicsamplingparameters:temperature=0,topk=1,andtopp=1.Datasets.Welearndomain-specificvocabularyandinter-fieldcorrelationsfromopen-sourceChatdoctor[62]datasets,whichcomprise110Krealpatient-doctorconversations.Weextractage-containingdialoguesamplesfromthepatient’sinputandemployChatGPT-4otoextractandstructureinfor-mationacrosssixdistinctfieldstogetourFormattedInputFielddatasetscontaining16,276samples.Tofacilitatelargelanguagemodelfine-tuning,weprocessedthreecustomizedfields,wheretheinputconsistsofsuccessfullypredictedfieldsandtheoutputcorrespondstothetargetfieldforprediction.Thisprocessingresultedinthreedatasetsofequalsize,eachdesignedtotrainthemodelonspecificfieldpredictiontaskswhileleveragingtheinformationfrompreviouslyidentifiedfields.OurcomplexityanalysisrevealsthatthesearchspaceoftheFormattedInputFielddatasetexceeds2×1042,highlightingthecomputationalchallengesinvolved.Toensurecomprehensiveevaluation,weimplementpost-processingvalidationmechanismsformaintainingstructuralconsistencywhilepreservingsemanticintegrity,specificallyaddressingformatinconsistenciesandfieldomissionsinlargelanguagemodeloutputs.Theevaluationmethodologyincorporates200randomlyselectedsamplesfromtheFormattedInputFielddatasettosimulatereal-worlduserinputs,withtheremainingdataallocatedforconstructortraining.Additionally,toenhanceevaluationfairnessandassessgeneralizationcapabilities,wesupple-mentedourtestsetwith200ChatGPT-4generatedsamples,simulatingdiverseuserexpressionsandensuringunbiasedperformanceassessment.EvaluationMetrics.Ourevaluationframeworkencom-passesbothidealizedscenariosandpracticalconstraints.Thesystemoperateswithinamemoryallocationof128GBformodelparameters,with80%oftheremainingmemory(153GB)dedicatedtoKV-cachestorage,accommodating250Ktokens’worthofKVvectors.Thisconfigurationestablishesourupperboundfortotalinputtokencapac-ity.Weimplementapragmatic5-minuteattackdurationlimit,whichalignswithtypicalprefixcachelifetimesinproductionenvironments[89].Forratelimiting,weadopttheTier2userconstraintsfromOpenAI’sspecificationof5,000requestsperminute(RPM),whileacknowledgingthatratelimitsvarysubstantiallyacrossdifferentAPIproviders,withsomeofferingunrestrictedaccess.Weevaluatesteal-ingsuccessratesfordisease(ASRdisease)andsymptom(ASRsymptoms)prediction,overallinputstealingsuccessrates(ASRall),numberofattempts(Attempts),requiredmemoryutilization(Tokens)andtimeconsumption(Time).Theexperimentalevaluationencompassestwodistinctscenarios:anunconstrainedsetting(Ideal)representingthe-oreticalmaximumperformance,andaconstrainedsetting(All)thatincorporatesallthreepracticallimitations(mem-ory,time,andrateconstraints).Thisdual-scenarioevaluationframeworkenablesustoquantifyboththetheoreticalupperboundsofsystemperformanceanditspracticalefficacyunderreal-worldoperationalconstraints,wheretheperfor-mancedeltabetweenscenariosprovidesvaluableinsightsintoconstraintimpactsandhighlightspotentialoptimizationopportunities.4.4.EvaluationResultsTimingAnalyzerEvaluation.Weevaluateourtiminganalyzeronpromptsof800and1,600tokensasshowninTable2andTable3.Foreachpromptlength,weconductexperimentswithvaryingsamplingquantities(10,300,600,and900samples)andevaluatethreemachinelearningmeth-ods:GradientBoosting,RandomForest,andXGBoost.Themodelsaretestedonadatasetof1,000samples,measuringtwokeymetrics:SRBlock(successrateinpredictingthenumberofcache-hitblocks)andSRField(successrateinpredictinghitsforfourfields,assumingfieldstartingpositionsareseparatedbyatleast16tokens,whichalignswithrealisticusagepatterns).Thiscomprehensiveevaluationframeworkallowsustoassesstheimpactofsamplingquan-tityandtheeffectivenessofdifferentpredictionmethods.Theresultsdemonstratethatourtiminganalyzercanachievehighaccuracywithmoderatesamplingoverhead,makingitefficientforreal-worldattacks.AsshowninTable2,for800-tokeninputs,ouranalyzerachievesoptimalperformancewith600samplingpoints,demonstratingan86.34%successrateinpredictingcache-hitblockcountsandanear-perfect97.25%accuracyinfield-levelhitdetection.Notably,increasingsamplingbeyondthispointyieldsdimin-ishingreturns,indicatingthatmoderatesamplingquantitiesaresufficientforeffectivetiminganalysis.Similarpatternsemergefor1600-tokeninputsasshowninTable3,where600samplesachieveoptimalperformancewith87.13%accuracyinblockhitpredictionand100%accuracyinfield-levelhitdetection.TABLE2:PerformanceoftheTimeAnalyzerWithInputTokenNumberis800QueryNumbersPredictionMethodsSRBlockSRField100GradientBoosting68.43%95.42%RandomForest64.64%94.58%XGBoost56.27%95.88%300GradientBoosting81.83%96.41%RandomForest78.76%95.69%XGBoost72.55%96.01%600GradientBoosting86.34%97.25%RandomForest79.28%96.21%XGBoost81.63%96.67%900GradientBoosting80.13%97.45%RandomForest81.18%96.86%XGBoost82.35%96.80%TABLE3:PerformanceoftheTimeAnalyzerWithInputTokenNumberis1600QueryNumbersPredictionMethodsSRBlockSRField100GradientBoosting48.51%93.07%RandomForest43.47%91.29%XGBoost36.04%95.05%300GradientBoosting75.84%100%RandomForest74.95%100%XGBoost64.06%100%600GradientBoosting87.13%99.70%RandomForest84.65%100%XGBoost79.31%100%900GradientBoosting86.73%100%RandomForest84.54%100%XGBoost82.97%100%End-to-EndAttackEvaluation.Weintegrateourinputconstructorandtimeanalyzerforend-to-endattackassess-mentinasharedprefixKVcache,whereregularusersandattackerscoexistonthesamenode.Attackerscandeterminecachehitsandinferotherusers’inputsbyanalyzingTTFTpatternsofconstructedrequests.Theattackproceedsbyconductingexhaustivesearchesforbasicfieldslikeageandgender,thenleveragingthesesuccessfullymatchedfieldstosequentiallypredictsubsequententries,withcustomcontentfieldspresentingthehighestcomplexity.Weimplementfourapproachestoimplementtheinputconstructor.(1)Thebaselineapproachemploysrandomcon-structionbasedonknowledgelearnedfromFormattedInputFielddatasets.(2)Additionally,wedevelopedamachinelearningmethodusingGaussianNaiveBayes,comprisingtworandomconstructorsforAgeandGenderandfourdis-tinctmodelstrainedonFormattedInputFieldforsubsequentfieldprediction.(3)Theframeworkalsoincorporatesprob-abilisticlearningimplementedatfine-grainedvocabularylevels,focusingonvocabularyprobabilitiesandcombinationrelationships.(4)Weutilizefine-tunedLLaMA-38BmodelstrainedonthreeFormattedInputFielddatasets,specificallytargetinghigh-complexityfields(DiseaseHistory,Symp-toms,Duration).Eachmodelspecializesinpredictingitsdesignatedfieldbasedonpreviouslymatchedinputs.Toensurediverseoutputsmatchuserinputpatterns,wecon-figurethemodelswithhighsamplingparameters(temper-ature=0.99,topp=0.99,maxtokens=100)andgenerate30candidatesperinference.Giventheinherentoutputdiversityandpotentialduplications,weperform50inferenceitera-tionsforeachtestsample,removeduplicates,andemployarankingmechanismtoprioritizethepredictions.Theserankedoutputsarethensequentiallysubmittedtothevictimserviceforcachehitattempts.ThecomprehensiveresultsarepresentedinTable4.Theexperimentalresultsdemonstratetheperformancevariationsacrossdifferentscenariosandmethods.Underidealcon-ditions,theProbability-basedVocabularyapproachdemon-stratessuperiorperformance,achievingthehighestattacksuccessratesacrossdiseaseprediction(67.5%),symptomprediction(53.75%),andoverallfieldprediction(49%).However,duetoitsword-levelsearchmechanismandrela-tivelypoorgraspofcoarse-grainedcorrelations,thismethodincurssubstantialcomputationaloverhead.Incontrast,theGaussianNBmethodstrikesanoptimalbalancebetweenre-sourceutilizationandperformance,showingapproximatelytwofoldefficiencyimprovementcomparedtothebaselineapproach.Whensubjectedtoreal-worldconstraints,whiletheProbability-basedVocabularymethodmaintainsitslead-ershipindiseaseprediction(62%),itsadvantagesinsymp-tomandoverallpredictionbecomelesspronounced.TheGaussianNBmethodexhibitsremarkablestability,achievingthehighestoverallpredictionaccuracy(12.50%).TheFinetunedLLMapproach,hamperedbyoutputvari-abilityanduncertainty,requiresextensiveattackattempts,resultinginexcessivememoryandtimeconsumption,yield-ingperformancedroppingfrom54.00%inidealconditionstocompletefailureundercomprehensiveconstraints.Thesefindingssuggestthattraditionalmachinelearningmethodsofferamorereliableandefficientsolutionforprecisematch-ingtasksunderpracticalconstraintsthanlargelanguagemodels,particularlywhenconsideringthetrade-offbetweenaccuracy,resourceutilization,andoperationalstability.TheFinetunedLLMshowspromisingpotentialinunrestrictedenvironments,itssubstantialresourcerequirementsandper-formanceinstabilityunderconstraintsmakeitlesssuitableforreal-worldattacks.5.Attack2:RetrievalAugmentedGenerationThissectionintroducesourinputtheftattacks,whichtargetsemanticcachinginapplicationsassistedbyretrieval-augmentedgeneration.Wewilldemonstratetheeffective-nessofourattacksthroughexperiments,highlightingtheprivacyinformationleakagerisksassociatedwithLLM-basedapplications.5.1.IntroductiontoAttackScenarioSemanticcachingrepresentsacrucialoptimizationforLLMandRAGapplications,offeringdeveloperssignifi-cantpracticaladvantages.Researchindicatesthatupto31%ofLLMcallsareredundant,whichcanbeeffectivelyeliminatedthroughsemanticcaching[37].Thisoptimiza-tionisparticularlyvitalinRetrieval-AugmentedGenera-tion(RAG)systems,whererapidandaccurateresponsegenerationiscriticalforperformance.IntelligentlycachingsemanticallysimilarqueriessubstantiallyreducesdatabaseretrievalandLLMinferencewhiledramaticallyimprovingresponsetimes.Forapplicationdevelopers,thistranslatesintomorecost-effectivescaling,improvedsystemreliability,andenhanceduserexperience.ThegrowingadoptionofsemanticcachingisevidentinLLM-basedtoolslikeGPTforWork[111]plugin,attracting6.88millionusers.AsLLMapplicationscontinuetogrowinpopularity,semanticcachingemergesasanessentialarchitecturalpatternthatef-fectivelybridgesthegapbetweenpowerfulLLMcapabilitiesandreal-worlddeploymentconstraints.WeidentifyanovelprivacyvulnerabilityinRAG-assistedLLMsystemswithsemanticcaching.Incontrasttoexactmatchingapproaches,ourstudyexaminessemanticcachingsystemsthatleveragesimilaritymatchingmech-anisms,whereresponsesarecachedandretrievedbasedonsemanticproximityratherthanexactmatches.Throughsystematicprobingwithcarefullycraftedqueries,attackerscanexploitthetimingside-channeltoinferthepresenceofspecifictopicsorquestionsinthecache,potentiallyreveal-ingsensitiveinformationaboutotherusers’interactionswiththesystem.Wedemonstrateourattackscenariointhecontextofon-linelegalconsultationservices,whereRAG-enhancedLLMsystemsarecommonlydeployedtosupplementresponseswithup-to-dateregulationsandrelevantcaselaw.Theseservicestypicallyimplementsemanticcachingtooptimizeperformanceandreducecomputationaloverheadwhenhan-dlingsimilarinquiriesfrommultipleusers.Byexploitingthesharedcachearchitecture,ourattackframeworktargetslegalconsultationqueriesspanningvariousdomains,enablingattackerstoinferthesemanticcontentandtopicalnatureTABLE4:End-to-EndAttackPerformanceComparisonAcrossDifferentMethodsUnderVariousConstraints.Weevaluatesuccessratesfordiseaseprediction(ASRdisease),symptomprediction(ASRsymptoms),andoverallfieldprediction(ASRall),alongwithrequiredattemptcounts(Attempts),memoryusage(Tokens),andtimeconsumption(Time).Theevaluationisconductedundertwoscenarios:Idealrepresentsthetheoreticalupperboundwithoutanypracticallimitations,Allreflectsreal-worldperformanceundermemoryconstraints(250Ktokens),ratelimits(5,000RPM),andtimerestrictions(5-minuteduration).IdealMethodsASRdiseaseASRsymptomsASRallAttemptsTokensTimeBaseline60.00%23.50%22.00%6868±6855283799±2739691751±1747GaussianNB59.00%27.50%26.50%2904±2830108650±94450730±622Probvocabulary67.50%53.75%49.00%502720±242651911507996±5696663577918±376100FinetunedLLM54.00%18.00%10.00%659920±68178286599206±6817828101500±101001AllMethodsASRdiseaseASRsymptomsASRallAttemptsTokensTimeBaseline45.50%9.00%8.00%1350±117355926±48139232±166GaussianNB54.00%13.50%12.50%1086±89840207±33421276±228Probvocabulary62.00%12.50%9.50%2247±98357526±26768348±152FinetunedLLM00.00%00.00%00.00%0±00±00±0ofotherusers’legalinquiries.Thisrepresentsasignificantprivacyconcernasitexposessensitiveinformationaboutusers’legalcircumstancesandconsultationtopics.5.2.MethodologiesOurattackmethodologycomprisestwokeycomponents:ainputconstructorandatimeanalyzer.DuetothereductioninretrievalandLLMinferenceprocesseswhensemanticre-sponsesarecached,thereisasignificanttemporaldisparitybetweencachehitsandmisses,asillustratedinFigure5.Throughtemporalfeatureextractionfromsampleddata,ourtiminganalyzerachieves100%accuracyindistinguishingbetweencachehitsandmisses.However,theinputcon-structorfacessubstantialchallengesincraftinginputswithinaninfinitesearchspace,asitmustgeneratesemanticallyrelevantqueriesthateffectivelyprobethecachecontents.Weproposeanintelligentconstructorthatsystemati-callyexploresanextensive,unknowninputspacetohitthecacheduserinput.Ourapproachbeginswithsemanticspacepartitioningthroughhierarchicalclusteringofthetrainingdataset,establishingafoundationalunderstandingoftheinputspacestructure.Toefficientlynavigatethispartitionedspace,weimplementaweightedbinarytreewhoseweightsarederivedfromclustercardinality,enablingdepth-firstex-plorationofsemanticclusters.Thesearchstrategycarefullybalancesexploitationandexploration.Whilefocusingonpromisingregionsnearclustercentroidstoleveragelearnedpatterns,theconstructorsimultaneouslyconductsperipheralexplorationaroundclusterstomaintainsearchbreadth.Thisdual-focusapproachisgovernedbyparametersthatdynam-icallyadjusttheexploration-exploitationtrade-offbasedonsearchprogress.Ineachiteration,theconstructorgeneratesmultiplecan-didateinputs,subjectingthemtoasophisticatedrankingprocess.Thisrankingmechanismintegratesmultiplefac-tors:historicalattemptpatterns,similarityrelationshipswithpreviousattempts,andthecandidate’srepresentativenesswithinthecurrentpool.Tomaintainattackefficiencyandpreventredundantattempts,theconstructorenforcesdiver-sityconstraintsthroughsimilaritythresholds,ensuringeachnewattemptissufficientlydistinctfrompreviousoneswhileremainingrepresentativeofthecurrentsearchregion.Theeffectivenessofourconstructorliesinitsabilitytosystematicallyexplorehigh-dimensionalsemanticspaceswhileadaptingitssearchpatternsbasedonaccumulatedknowledge.Throughthisbalancedapproachoffocusedexploitationandstrategicexploration,theconstructoreffi-cientlynavigatesthechallengeofmatchinguserinputsinanextensiveunknownspacewhilemaintainingdiversityinitsattackattempts.5.3.ExperimentalSetupandEvaluationExperimentalSetup.OurexperimentalframeworkutilizedGPTCache’ssemanticcachinginfrastructure.Weconfig-uredthesemanticsimilaritythresholdsas0.9usingitsdefaultsimilarityevaluationmethodSearchDistanceEvalu-ation[50].Wetendtochooseadeliberatelyconservativethresholdsettingtoensurehigh-fidelitysemanticmatch-ingandtoimposestringentqualityrequirementsonourconstructor’soutput.Thishighthresholdhelpedeliminatefalsepositivesincachehits,enablingmoreprecisemea-surementofperformancedifferences.TheRAGdatabasewasconstructedbyuploadinglegalcorpustotheOpenAIorganizationplatform,wherewemeasuredandanalyzedretrievallatenciesundervariousqueryinputs.InputConstructorEvaluation.Ourstudyemployedalarge-scalelegalconsultationcorpusCrimeKgAssitant[1]consistingof200,000question-answerpairs,categorizedinto13distinctlegaldomains.Thedataset’scategoricaldis-tribution,trainingdatasizes,andinputlengthstatisticsaredetailedinTable5.Weextractedtheuserquerycomponentsfromthedatasetforinputconstructortraining.Tosimulatediversereal-worlduserinputs,weemployChatGPT-4togenerate30testqueriesandsplit30testdatafromthetrainingdataset,formingatestsetthatreflectsvarieduserexpressionpatterns.Empiricalresultsdemonstratethatourpromptconstruc-torcaneffectivelycapturesemanticspacesfromtrainingdata.Throughiterativeprobingofuserinputrequests,itachievessemanticextractionsuccessratesrangingfrom43%to100%,aspresentedinTable5.Thiseffectivenessingeneralizingacrossdisparatedatasetshighlightstherobustlearningcapabilitiesininputreconstruction.TABLE5:Systematicevaluationofattacksuccessrates(ASR).ConstructorlearnedfromCrimeKgAssitantdatasetswith13legaldomainsandtestedwithGPT-4generateddataCategoryCountLen.Avg.±Std.ASRMarriageandFamily3928138.11±344.2993.33%LaborDisputes3501138.79±329.5490.00%TrafficAccidents2264639.45±317.98100.00%DebtDisputes2192538.47±364.9790.00%CriminalDefense1831435.96±364.6493.33%ContractDisputes1376539.73±340.3096.67%PropertyDisputes1207136.65±337.62100.00%Infringement1059439.03±426.9143.33%CompanyLaw1001138.47±340.9070.00%MedicalDisputes728539.07±345.5573.33%DemolitionandResettlement702240.91±320.75100.00%AdministrativeLitigation277636.14±302.3993.10%ConstructionProjects161042.11±262.8263.33%6.DiscussionandDefenses6.1.DiscussionTrade-offsinCloud-DeployedLLMs.WhilelocalLLMdeploymentprovidesinherentprivacybenefits,cloudde-ploymentremainsinevitableduetothesubstantialcom-putationalrequirementsofmoderninferencesystemsthatexceededgedevicecapabilities.Thisfundamentaltensionbetweenprivacyandperformancehasledtovariousprivacy-preservingsolutions,includinghomomorphicencryption,TEEs,anddatamaskingforcloud-basedinference.How-ever,ourtimingside-channelattackdemonstratesthatthesecryptographicapproachesfailtoaddressprivacyleakagearisingbysystem-leveloptimizationslikeprefixcache-sharing.Ourresearchexposesacriticalvulnerabilitywhereper-formanceoptimizationsincloud-deployedLLMs,whilees-sentialforscalability,createexploitableprivacysidechan-nels.Thisfindingrevealsanimportanttrade-off:sharedcachingmechanismsthatenhancesystemefficiencysimul-taneouslyintroducesubtleyetsignificantprivacyrisks.TheimplicationsextendbeyondLLMsystems,contributingtothebroaderdiscourseonbalancingsecurityandperformanceincloudcomputingarchitecturesandemphasizingtheneedforcomprehensiveprivacy-preservingdesignsthatconsidercryptographicprotectionsandsystem-levelvulnerabilities.LimitationsoftheAttack.Onesignificantlimitationofourattackisthelackoffine-grainedinformationforaccuratelyreconstructingtheinput.Whileourinsightseffectivelycap-turesecretinformationinthedata,itdoesnotprovidethedetailedcontextrequiredforpreciserecovery.Toaddressthis,integratingtechniquessuchasembeddinginversionandtoken-lengthsidechannelscouldenhancetheattack’sef-fectivenessbyofferingadditionalgranularinformation.Ourmethodscouldserveasvalidationmechanisms,improvingthereliabilityoftheinputrecoveryprocess.Anothercriticallimitationisthatourattackcannotlinktheinferredinputstospecificusersorinputobjects,prevent-ingmeaningfuluseofthestolendatainreal-worldscenarios.Thislackofuserattributionsignificantlylimitstheattack’spracticalimplications.6.2.PotentialDefensesOurattackinvolvesmanipulatingpromptsequencestoprobetheKVCache,allowingadversariestodeterminecachehitsormissesbasedonthetimetakentogenerateresponses.Thissectiondelineatesstrategicdefensemecha-nismstomitigatesuchtimingattacks.User-LevelCacheIsolation.Implementingdistinctcachenamespacespreventscross-usercachesharing,effectivelycontainingcachestateswithinindividualsessions.Whilethisapproachstrengthenssecurity,ittradesoffsystemefficiency.MajorproviderslikeOpenAI’sAPI[89]andDeepSeek’sAPI[22]implementisolationforprefixcachingtoprotectuserprivacyandsecurity.RateLimitingtoMitigateFrequentSttacks.Byrestrict-ingrequestfrequency,ratelimitingimpedesrapidsuccessiveprobingnecessaryfortiminganalysis.Thisdefensenotonlypreventsbrute-forceattemptsbutalsomaintainsinfrastruc-turestability.WhileOpenAIemploysthisapproach[85],carefulcalibrationisneededtobalancesecuritywithlegit-imateuseraccess.ComplicateTimeAnalysis.Timingobfuscationapproachescaneffectivelypreventattackersfromexploitingresponsetimevariations.Similartechniqueshavebeenproveneffec-tiveagainstmodelextractionattacks,wheretimingpatternscanrevealmodelparametersthroughcorrelationswithacti-vationfunctions[8],networkdepth[30],andcomputationaloperations[27].Weproposetwokeyobfuscationstrategies:responsetimehomogenizationthrougheitherconstant-timeexecution[69]orrandomdelayinjection[9]anddisablingstreamingresponsestoeliminatemeasurabletimingpatternsOurdefensestrategyemphasizesthecriticalbalancebetweensecurity,performance,anduserexperience.Whileeachmechanismprovidesdistinctprotectionagainsttiming-basedattacks,theirimplementationrequirescarefulconsid-erationofoperationalrequirementsandthreatmodels.Acombinedapproach,tailoredtospecificdeploymentcon-texts,offersthemostrobustprotectionagainstourdemon-stratedside-channelvulnerabilities.7.RelatedWork7.1.Side-channelAttacksonAISystemsSide-channelattackscanexploitindirectinformationleakagefromAIsystems,suchastiming[27],[30],[39],powerconsumption[118],[127],orelectromagneticemissions[8],[45],[140],toinfersensitivemodelar-chitecturesandparameters.Additionally,cache-basedsidechannels[44],[122],[135],memoryaccesspatterns[46],[47],andresourcecontentioninformation[31],[80],[114]providefurtheravenuesforgleaningmodelinformation.Debenedettietal.[21]exploreprivacyside-channelattacksinmachinelearningsystems,highlightinghowsystem-levelcomponentscanbemanipulatedtoleakprivateinformationmoreeffectivelythanstandalonemodels.However,duetothecomplexityoflargemodelsystems,side-channelattacksagainstlargemodelsystemsremainrelativelyrare.Weissetal.[128]introduceanoveltoken-lengthside-channelvulnerabilityaffectingAIassistants,demonstratinghowencryptedresponsesfromAIChatbotscanbepartiallyreconstructedbyanalyzingthelengthoftransmittedtokensoverthenetwork.Incontrast,ourworkproposesanewtiming-basedside-channelattacktocaptureuserinputandanalyzecachebehaviorovertime,revealingthecache-sharingdynamicswithinLLMsystems.7.2.PromptTextLeakageAttacksAdversarialPrompts.Theartofpromptengineeringiscrucialandoftenregardedasproprietarybecauseitopti-mizesmodelperformanceforspecifictasks[126],enhancesinstruction-followingcapabilities[90],andalignsoutputswithhumanvalues[6],makingsystempromptsvaluableassets[125].Perezetal.[91]firstexplorepromptleakageinLLMsbyinjectingcraftedpromptsthatmisalignthemodel’sintendedgoals,allowingattackerstoextractsensitivein-formationembeddedintheprompts.Recentstudies[63],[141],[144]primarilyfocusondevelopingmoreeffectiveadversarialpromptstoexposethesystempromptsofLLMs.PromptsInversion.Anothertypeofattackinvolvesinfer-ringinputpromptsfromgeneratedcontent.Inputtextdataisoftenrepresentedasembeddingvectorsinnaturallanguageprocessing,especiallywiththeproliferationofLLMs.Previ-ouswork[105]hasdemonstratedthepossibilityofobtainingsensitiveinformationoforiginalinputsbyinvertingtheseembeddingvectors.Sincethen,numerousstudieshavefo-cusedonembeddinginversionattacksonlanguagemodels,Morrisetal.[79]recoversignificantpersonalinformationfromclinicaldatasets,Lietal.[59]generatecoherentandsimilarsentencestotheoriginalinput,andChenetal.[16]investigatemultilingualinversionattacks.Inadditiontoembeddingvectors,otherinformationcanalsobeusedtoreversetheinputcontent.Morrisetal.[78]suggestthatthenext-tokenprobabilitydistributioncontainsinformationabouttheprecedingtext,whichcanbeexploitedtoreconstructinputprompts,highlightingthesignificanceofresidualinformationinmodeloutputs.Similarly,imagesgeneratedbytext-to-imagediffusionmodels[67],[101]andtextsproducedbyLLMs[97],[138]canalsobeexploitedtoreverse-engineertextprompts.Theseattacktechniquesadverselyaffectthecommercialbenefitsofthepromptmar-ketplaceandinfringeonpromptengineers’propertyrights.7.3.MemorizationandPrivacyRisksinLLMsMemorizationoflanguagemodelscanrememberpartsofthetrainingdata,whichencompasseswebcrawlsofpersonalpages,socialmediamessages,andinternalemaildatabases,raisingconcernsaboutdatacopyrightandprivacybreaches.Pre-trainedandfine-tunedlanguagemodels[48],[57],[74],[75]alsosubjecttotheseissues.Carlinietal.[13]demonstratethatlargermodelstendtomemorizemoreinformation,highlightingthenecessityofmitigatingmemorizationasthemodelscalekeepsgrowing.Ifthetrainingdataisleaked,itcanresultintheunau-thorizedexposureofconfidentialinformation,raisingethicalconcernsregardingconsentanddataownership.Trainingdataextractionattacks[10],[14]canrecoversensitivetrain-ingexamplesbyqueryingtheLLMs.Additionally,member-shipinferenceattacks[13],[71],[72],[106]candeterminewhetherspecificdatawasincludedinthetrainingdataset,potentiallycompromisingthecopyrightsofthedataowner.Memorizationsignificantlythreatenspersonalprivacybypotentiallyretainingandrecallingsensitiveinformationfromtrainingdata.Lukasetal.[66]exploreprivacy-utilitytrade-offsofusingdefensessuchasPIIscrubbingandDiffer-entiallyPrivatetrainingwhenfine-tuninglanguagemodels.Kimetal.[55]enabledatasubjectstodeterminewhethertheirPIIisatriskofdisclosurethroughqueries.Staabetal.[108]indicatesthatLLMscanautomaticallyreasonauthorattributesfromunstructuredtext,greatlyreducingthecostassociatedwithprivacyviolation.References[1]GitHub-liuhuanyong/CrimeKgAssitant.https://github.com/liuhuanyong/CrimeKgAssitant.[Accessed14-11-2024].[2]OnlineToolsandUtilities:Generators.https://webutility.io/.[3]Anthropic.Promptcaching(beta).https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching,2024.[4]MicrosoftAzure.Tutorial:UseAzureCacheforRedisasaseman-ticcache.https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-semantic-cache,2024.[5]JinzeBai,ShuaiBai,YunfeiChu,ZeyuCui,KaiDang,XiaodongDeng,YangFan,WenbinGe,YuHan,FeiHuang,etal.Qwentechnicalreport.arXivpreprintarXiv:2309.16609,2023.[6]YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,StanislavFort,DeepGanguli,TomHenighan,etal.Trainingahelpfulandharmlessassistantwithreinforcementlearningfromhumanfeedback.arXivpreprintarXiv:2204.05862,2022.[7]FuBang.Gptcache:Anopen-sourcesemanticcacheforllmappli-cationsenablingfasteranswersandcostsavings.InProceedingsofthe3rdWorkshopforNaturalLanguageProcessingOpenSourceSoftware(NLP-OSS2023),pages212–218,2023.[8]LejlaBatina,ShivamBhasin,DirmantoJap,andStjepanPicek.{CSI}{NN}:Reverseengineeringofneuralnetworkarchitecturesthroughelectromagneticsidechannel.In28thUSENIXSecuritySymposium(USENIXSecurity19),pages515–532,2019.[9]JakubBreier,DirmantoJap,XiaoluHou,andShivamBhasin.Adesynchronization-basedcountermeasureagainstside-channelanal-ysisofneuralnetworks.InInternationalSymposiumonCyberSecu-rity,Cryptology,andMachineLearning,pages296–306.Springer,2023.[10]HannahBrown,KatherineLee,FatemehsadatMireshghallah,RezaShokri,andFlorianTram`er.Whatdoesitmeanforalanguagemodeltopreserveprivacy?InProceedingsofthe2022ACMconferenceonfairness,accountability,andtransparency,pages2280–2292,2022.[11]TomBBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal.Languagemodelsarefew-shotlearners.InAdvancesinNeuralInformationProcessingSystems,2020.[12]TuanBui,OanhTran,PhuongNguyen,BaoHo,LongNguyen,ThangBui,andThoQuan.Cross-dataknowledgegraphconstruc-tionforllm-enablededucationalquestion-answeringsystem:Acasestudyathcmut.InProceedingsofthe1stACMWorkshoponAI-PoweredQ&ASystemsforMultimedia,pages36–43,2024.[13]NicholasCarlini,DaphneIppolito,MatthewJagielski,KatherineLee,FlorianTramer,andChiyuanZhang.Quantifyingmemorizationacrossneurallanguagemodels.arXivpreprintarXiv:2202.07646,2022.[14]NicholasCarlini,FlorianTramer,EricWallace,MatthewJagielski,ArielHerbert-Voss,KatherineLee,AdamRoberts,TomBrown,DawnSong,UlfarErlingsson,etal.Extractingtrainingdatafromlargelanguagemodels.In30thUSENIXSecuritySymposium(USENIXSecurity21),pages2633–2650,2021.[15]AngelicaChen,DavidDohan,andDavidSo.Evoprompting:lan-guagemodelsforcode-levelneuralarchitecturesearch.AdvancesinNeuralInformationProcessingSystems,36,2024.[16]YiyiChen,HeatherLent,andJohannesBjerva.Textembeddinginversionsecurityformultilinguallanguagemodels.InProceedingsofthe62ndAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers),pages7808–7827,2024.[17]AakankshaChowdhery,SharanNarang,JacobDevlin,MikhailBosma,AdamRoberts,MaitreyaSubbiah,QuocVLe,andIlyaSutskever.Palm:Scalinglanguagemodelingwithpathways.arXivpreprintarXiv:2204.02311,2022.[18]KuanChaoChu,Yi-PeiChen,andHidekiNakayama.Abetterllmevaluatorfortextgeneration:Theimpactofpromptoutputsequencingandoptimization.arXivpreprintarXiv:2406.09972,2024.[19]JiaxiCui,ZongjianLi,YangYan,BohuaChen,andLiYuan.Chatlaw:Open-sourcelegallargelanguagemodelwithintegratedexternalknowledgebases.arXivpreprintarXiv:2306.16092,2023.[20]CadeDaniel,ChenShen,EricLiang,andRichardLiaw.Howcontinuousbatchingenables23xthroughputinllminferencewhilereducingp50latency,2023.[21]EdoardoDebenedetti,GiorgioSeveri,NicholasCarlini,Christo-pherAChoquette-Choo,MatthewJagielski,MiladNasr,EricWal-lace,andFlorianTram`er.Privacysidechannelsinmachinelearningsystems.In33rdUSENIXSecuritySymposium(USENIXSecurity24),pages6861–6848,2024.[22]DeepSeek.DeepSeekAPIDocs:DeepSeekAPIintroducesContextCachingonDisk,cuttingpricesbyanorderofmagnitude.https://api-docs.deepseek.com/news/news0802/.[23]DeepSeek.DeepSeekAPIintroducesContextCachingonDisk,cuttingpricesbyanorderofmagnitude.https://api-docs.deepseek.com/news/news0802/,2024.[24]TimDettmers,MikeLewis,YounesBelkada,andLukeZettlemoyer.Gpt3.int8():8-bitmatrixmultiplicationfortransformersatscale.AdvancesinNeuralInformationProcessingSystems,35:30318–30332,2022.[25]YiranDing,LiLynaZhang,ChengruidongZhang,YuanyuanXu,NingShang,JiahangXu,FanYang,andMaoYang.Longrope:Extendingllmcontextwindowbeyond2milliontokens.arXivpreprintarXiv:2402.13753,2024.[26]Jean-BaptisteD¨oderlein,MathieuAcher,DjamelEddineKhel-ladi,andBenoitCombemale.Pilotingcopilotandcodex:Hottemperature,coldprompts,orblackmagic?arXivpreprintarXiv:2210.14699,2022.[27]GaofengDong,PingWang,PingChen,RuizheGu,andHonggangHu.Floating-pointmultiplicationtimingattackondeepneuralnetwork.In2019IEEEInternationalConferenceonSmartInternetofThings(SmartIoT),pages155–161.IEEE,2019.[28]HarryDong,XinyuYang,ZhenyuZhang,ZhangyangWang,YuejieChi,andBeidiChen.Getmorewithless:Synthesizingrecurrencewithkvcachecompressionforefficientllminference.arXivpreprintarXiv:2402.09398,2024.[29]AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,AbhishekKadian,AhmadAl-Dahle,AieshaLetman,AkhilMathur,AlanSchelten,AmyYang,AngelaFan,etal.Thellama3herdofmodels.arXivpreprintarXiv:2407.21783,2024.[30]VasishtDuddu,DebasisSamanta,DVijayRao,andValentinaEBalas.Stealingneuralnetworksviatimingsidechannels.arXivpreprintarXiv:1812.11720,2018.[31]SankhaBaranDutta,HodaNaghibijouybari,ArjunGupta,NaelAbu-Ghazaleh,AndresMarquez,andKevinBarker.Spyinthegpu-box:Covertandsidechannelattacksonmulti-gpusystems.InProceedingsofthe50thAnnualInternationalSymposiumonComputerArchitecture,pages1–13,2023.[32]DomEccleston.Semanticcaching.https://www.unkey.com/blog/semantic-caching,2024.[33]ChenhaoFang,XiaohanLi,ZezhongFan,JianpengXu,KaushikiNag,EvrenKorpeoglu,SushantKumar,andKannanAchan.Llm-ensemble:Optimallargelanguagemodelensemblemethodfore-commerceproductattributevalueextraction.InProceedingsofthe47thInternationalACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval,pages2910–2914,2024.[34]EliasFrantar,SalehAshkboos,TorstenHoefler,andDanAlistarh.Gptq:Accuratepost-trainingquantizationforgenerativepre-trainedtransformers.arXivpreprintarXiv:2210.17323,2022.[35]TianyuGao,AdamFisch,andDanqiChen.Makingpre-trainedlanguagemodelsbetterfew-shotlearners.arXivpreprintarXiv:2012.15723,2020.[36]GenerateStory.FreeAIStoryGenerator.https://generatestory.io/.[37]WarisGill,MohamedElidrisi,PallaviKalapatapu,AliAnwar,andMuhammadAliGulzar.Privacy-awaresemanticcacheforlargelanguagemodels.arXivpreprintarXiv:2403.02694,2024.[38]InGim,GuojunChen,Seung-seobLee,NikhilSarda,AnuragKhan-delwal,andLinZhong.Promptcache:Modularattentionreuseforlow-latencyinference.ProceedingsofMachineLearningandSystems,6:325–338,2024.[39]ChengGongye,YunsiFei,andThomasWahl.Reverse-engineeringdeepneuralnetworksusingfloating-pointtimingside-channels.In202057thACM/IEEEDesignAutomationConference(DAC),pages1–6.IEEE,2020.[40]Google.GeminiAPI:GoogleAIforDevelopers.https://ai.google.dev/gemini-api/docs/caching?lang=python,2024.[41]YuxianGu,XuHan,ZhiyuanLiu,andMinlieHuang.Ppt:Pre-trainedprompttuningforfew-shotlearning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers),pages8410–8423,2022.[42]XinnanGuo,WentaoDeng,YongruiChen,YangLi,MengdiZhou,GuilinQi,TianxingWu,DongYang,LiubinWang,andYongPan.Comave:Contrastivepre-trainingwithmulti-scalemaskingforattributevalueextraction.InFindingsoftheAssociationforComputationalLinguistics:ACL2023,pages6007–6018,2023.[43]ChiHan,QifanWang,WenhanXiong,YuChen,HengJi,andSinongWang.Lm-infinite:Simpleon-the-flylengthgeneralizationforlargelanguagemodels.arXivpreprintarXiv:2308.16137,2023.[44]SanghyunHong,MichaelDavinroy,YiˇgitcanKaya,StuartNevansLocke,IanRackow,KevinKulda,DanaDachman-Soled,andTudorDumitras¸.Securityanalysisofdeepneuralnetworksoperatinginthepresenceofcacheside-channelattacks.arXivpreprintarXiv:1810.03487,2018.[45]PeterHorvath,LukaszChmielewski,LeoWeissbart,LejlaBatina,andYuvalYarom.Barracuda:Bringingelectromagneticsidechannelintoplaytostealtheweightsofneuralnetworksfromnvidiagpus.arXivpreprintarXiv:2312.07783,2023.[46]XingHu,LingLiang,ShuangchenLi,LeiDeng,PengfeiZuo,YuJi,XinfengXie,YufeiDing,ChangLiu,TimothySherwood,etal.Deepsniffer:Adnnmodelextractionframeworkbasedonlearningarchitecturalhints.InProceedingsoftheTwenty-FifthInternationalConferenceonArchitecturalSupportforProgrammingLanguagesandOperatingSystems,pages385–399,2020.[47]WeizheHua,ZhiruZhang,andGEdwardSuh.Reverseengineer-ingconvolutionalneuralnetworksthroughside-channelinformationleaks.InProceedingsofthe55thAnnualDesignAutomationConference,pages1–6,2018.[48]JieHuang,HanyinShao,andKevinChen-ChuanChang.Arelargepre-trainedlanguagemodelsleakingyourpersonalinformation?arXivpreprintarXiv:2205.12628,2022.[49]HuggingFace.LargeLanguageModelTextGenerationInference.https://github.com/huggingface/text-generation-inference.[50]ZillizInc.Howtobetterconfigureyourcache;GPTCache.https://gptcache.readthedocs.io/en/latest/configureit.html,2023.[51]InternLM.LMDeployisatoolkitforcompressing,deploying,andservingLLMs.https://github.com/InternLM/lmdeploy/tree/main.[52]JordanJuravsky,BradleyBrown,RyanEhrlich,DanielYFu,ChristopherR´e,andAzaliaMirhoseini.Hydragen:High-throughputllminferencewithsharedprefixes.arXivpreprintarXiv:2402.05099,2024.[53]RishiKalra,ZekunWu,AyeshaGulley,AirlieHilliard,XinGuan,AdrianoKoshiyama,andPhilipTreleaven.Hypa-rag:Ahybridparameteradaptiveretrieval-augmentedgenerationsystemforailegalandpolicyapplications.arXivpreprintarXiv:2409.09046,2024.[54]SantiagoFloresKanter.ImprovespeedandreducecostforgenerativeAIworkloadswithapersistentsemanticcacheinAmazonMemoryDB.https://aws.amazon.com/cn/blogs/database/improve-speed-and-reduce-cost-for-generative-ai-workloads-with-a-persistent-semantic-cache-in-amazon-memorydb/,2024.[55]SiwonKim,SangdooYun,HwaranLee,MartinGubri,SungrohYoon,andSeongJoonOh.Propile:Probingprivacyleakageinlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems,36,2024.[56]WoosukKwon,ZhuohanLi,SiyuanZhuang,YingSheng,LianminZheng,CodyHaoYu,JosephGonzalez,HaoZhang,andIonStoica.Efficientmemorymanagementforlargelanguagemodelservingwithpagedattention.InProceedingsofthe29thSymposiumonOperatingSystemsPrinciples,pages611–626,2023.[57]EricLehman,SarthakJain,KarlPichotta,YoavGoldberg,andByronCWallace.Doesbertpretrainedonclinicalnotesrevealsensitivedata?arXivpreprintarXiv:2104.07762,2021.[58]PatrickLewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin,NamanGoyal,HeinrichK¨uttler,MikeLewis,Wen-tauYih,TimRockt¨aschel,etal.Retrieval-augmentedgen-erationforknowledge-intensivenlptasks.AdvancesinNeuralInformationProcessingSystems,33:9459–9474,2020.[59]HaoranLi,MingshiXu,andYangqiuSong.Sentenceembeddingleaksmoreinformationthanyouexpect:Generativeembeddinginversionattacktorecoverthewholesentence.InFindingsoftheAssociationforComputationalLinguistics:ACL2023,pages14022–14040,2023.[60]JiaLi,GeLi,YongminLi,andZhiJin.Structuredchain-of-thoughtpromptingforcodegeneration.ACMTransactionsonSoftwareEngineeringandMethodology,2023.[61]JiaxingLi,ChiXu,FengWang,IsaacMvonRiedemann,CongZhang,andJiangchuanLiu.Scalm:Towardssemanticcachingforautomatedchatserviceswithlargelanguagemodels.arXivpreprintarXiv:2406.00025,2024.[62]YunxiangLi,ZihanLi,KaiZhang,RuilongDan,SteveJiang,andYouZhang.Chatdoctor:Amedicalchatmodelfine-tunedonalargelanguagemodelmeta-ai(llama)usingmedicaldomainknowledge.Cureus,15(6),2023.[63]ZiLiang,HaiboHu,QingqingYe,YaxinXiao,andHaoyangLi.Whyaremypromptsleaked?unravelingpromptextrac-tionthreatsincustomizedlargelanguagemodels.arXivpreprintarXiv:2408.02416,2024.[64]AnnaLiebandToshaliGoel.Studentinteractionwithnewtbot:Anllm-as-tutorchatbotforsecondaryphysicseducation.InExtendedAbstractsoftheCHIConferenceonHumanFactorsinComputingSystems,pages1–8,2024.[65]JiLin,JiamingTang,HaotianTang,ShangYang,Wei-MingChen,Wei-ChenWang,GuangxuanXiao,XingyuDang,ChuangGan,andSongHan.Awq:Activation-awareweightquantizationforon-devicellmcompressionandacceleration.ProceedingsofMachineLearningandSystems,6:87–100,2024.[66]NilsLukas,AhmedSalem,RobertSim,ShrutiTople,LukasWutschitz,andSantiagoZanella-B´eguelin.Analyzingleakageofpersonallyidentifiableinformationinlanguagemodels.In2023IEEESymposiumonSecurityandPrivacy(SP),pages346–363.IEEE,2023.[67]ShwetaMahajan,TanzilaRahman,KwangMooYi,andLeonidSigal.Promptinghardorhardlyprompting:Promptinversionfortext-to-imagediffusionmodels.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages6808–6817,2024.[68]ShwetaMahajan,TanzilaRahman,KwangMooYi,andLeonidSigal.Promptinghardorhardlyprompting:Promptinversionfortext-to-imagediffusionmodels.In2024IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),pages6808–6817,2024.[69]SauravMaji,UtsavBanerjee,andAnanthaPChandrakasan.Leakynets:Recoveringembeddedneuralnetworkmodelsandinputsthroughsimplepowerandtimingside-channels—attacksandde-fenses.IEEEInternetofThingsJournal,8(15):12079–12092,2021.[70]GgaliwangoMarvin,NakayizaHellen,DaudiJjingo,andJoyceNakatumba-Nabende.Promptengineeringinlargelanguagemod-els.InInternationalconferenceondataintelligenceandcognitiveinformatics,pages387–402.Springer,2023.[71]JustusMattern,FatemehsadatMireshghallah,ZhijingJin,BernhardSchoelkopf,MrinmayaSachan,andTaylorBerg-Kirkpatrick.Mem-bershipinferenceattacksagainstlanguagemodelsvianeighbour-hoodcomparison.InThe61stAnnualMeetingOfTheAssociationForComputationalLinguistics,2023.[72]MatthieuMeeus,ShubhamJain,MarekRei,andYves-AlexandredeMontjoye.Didtheneuronsreadyourbook?document-levelmembershipinferenceforlargelanguagemodels.In33rdUSENIXSecuritySymposium(USENIXSecurity24),pages2369–2385,2024.[73]SilviaMilano,JoshuaAMcGrane,andSabinaLeonelli.Largelanguagemodelschallengethefutureofhighereducation.NatureMachineIntelligence,5(4):333–334,2023.[74]FatemehsadatMireshghallah,ArchitUniyal,TianhaoWang,DavidEvans,andTaylorBerg-Kirkpatrick.Memorizationinnlpfine-tuningmethods.arXivpreprintarXiv:2205.12506,2022.[75]FatemehsadatMireshghallah,ArchitUniyal,TianhaoWang,DavidKEvans,andTaylorBerg-Kirkpatrick.Anempiricalanaly-sisofmemorizationinfine-tunedautoregressivelanguagemodels.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages1816–1826,2022.[76]RamaswamiMohandoss.Context-basedsemanticcachingforllmapplications.In2024IEEEConferenceonArtificialIntelligence(CAI),pages371–376.IEEE,2024.[77]MoonShot.UsingtheContextCachingFeatureoftheKimiAPI.https://platform.moonshot.cn/docs/guide/use-context-caching-feature-of-kimi-api,2024.[78]JohnXMorris,WentingZhao,JustinTChiu,VitalyShmatikov,andAlexanderMRush.Languagemodelinversion.arXivpreprintarXiv:2311.13647,2023.[79]JohnXavierMorris,VolodymyrKuleshov,VitalyShmatikov,andAlexanderMRush.Textembeddingsreveal(almost)asmuchastext.InThe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,2023.[80]HodaNaghibijouybari,AjayaNeupane,ZhiyunQian,andNaelAbu-Ghazaleh.Renderedinsecure:Gpusidechannelattacksarepractical.InProceedingsofthe2018ACMSIGSACconferenceoncomputerandcommunicationssecurity,pages2139–2153,2018.[81]Xuan-PhiNguyen,ShreyPandit,SenthilPurushwalkam,AustinXu,HailinChen,YifeiMing,ZixuanKe,SilvioSavarese,CaimingXong,andShafiqJoty.Sfr-rag:Towardscontextuallyfaithfulllms.arXivpreprintarXiv:2409.09916,2024.[82]NVIDIA.NVIDIATensorRT-LLM.https://docs.nvidia.com/tensorrt-llm/index.html.[83]NVIDIA.RaggedBatching;NVIDIATritonInferenceServer.https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/userguide/raggedbatching.html,2024.[Accessed13-11-2024].[84]OpenAI.Gpt-4turbointheopenaiapi.https://help.openai.com/en/articles/8555510-gpt-4-turbo-in-the-openai-api.[85]OpenAI.Openaideveloperplatform,Ratelimits.https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api.[86]OpenAI.Introducingchatgpt.https://openai.com/blog/chatgpt,2022.[87]OpenAI.IntroducingtheGPTStoreWe’relaunchingtheGPTStoretohelpyoufind.https://chat.openai.com/gpts,2024.[88]OpenAI.LearningtoReasonwithLLMsWeareintroducingOpenAIo1,anewlargelanguagemodeltrainedwithLLMs.https://openai.com/index/learning-to-reason-with-llms/,2024.[89]OpenAI.Promptcaching:Reducelatencyandcostwithpromptcaching.https://platform.openai.com/docs/guides/prompt-caching,2024.[90]LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWain-wright,PamelaMishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.Traininglanguagemodelstofollowin-structionswithhumanfeedback.Advancesinneuralinformationprocessingsystems,35:27730–27744,2022.[91]F´abioPerezandIanRibeiro.Ignorepreviousprompt:Attacktechniquesforlanguagemodels.arXivpreprintarXiv:2211.09527,2022.[92]ReinerPope,SholtoDouglas,AakankshaChowdhery,JacobDevlin,JamesBradbury,JonathanHeek,KefanXiao,ShivaniAgrawal,andJeffDean.Efficientlyscalingtransformerinference.ProceedingsofMachineLearningandSystems,5:606–624,2023.[93]Portkey.Cache(Simple&Semantic)-PortkeyDocs.https://portkey.ai/docs/product/ai-gateway/cache-simple-and-semantic,2024.[94]PranabSahoo,AyushKumarSingh,SriparnaSaha,VinijaJain,SamratMondal,andAmanChadha.Asystematicsurveyofpromptengineeringinlargelanguagemodels:Techniquesandapplications.arXivpreprintarXiv:2402.07927,2024.[95]MalikSallam.Chatgptutilityinhealthcareeducation,research,andpractice:systematicreviewonthepromisingperspectivesandvalidconcerns.InHealthcare,volume11,page887.MDPI,2023.[96]MelanieSclar,YejinChoi,YuliaTsvetkov,andAlaneSuhr.Quan-tifyinglanguagemodels’sensitivitytospuriousfeaturesinpromptdesignor:Howilearnedtostartworryingaboutpromptformatting.arXivpreprintarXiv:2310.11324,2023.[97]ZeyangShaandYangZhang.Promptstealingattacksagainstlargelanguagemodels.arXivpreprintarXiv:2402.12959,2024.[98]ArunShankar.ImplementingSemanticCaching:AStep-by-StepGuidetoFaster,Cost-EffectiveGenAIWorkflows.https://medium.com/google-cloud/implementing-semantic-caching-a-step-by-step-guide-to-faster-cost-effective-genai-workflows-ef85d8e72883,2024.[99]WenqiShao,MengzhaoChen,ZhaoyangZhang,PengXu,LiruiZhao,ZhiqianLi,KaipengZhang,PengGao,YuQiao,andPingLuo.Omniquant:Omnidirectionallycalibratedquantizationforlargelanguagemodels.arXivpreprintarXiv:2308.13137,2023.[100]ZhenweiShao,ZhouYu,MengWang,andJunYu.Promptinglargelanguagemodelswithanswerheuristicsforknowledge-basedvisualquestionanswering.InProceedingsoftheIEEE/CVFConferenceoncomputervisionandpatternrecognition,pages14974–14983,2023.[101]XinyueShen,YitingQu,MichaelBackes,andYangZhang.Promptstealingattacksagainst{Text-to-Image}generationmodels.In33rdUSENIXSecuritySymposium(USENIXSecurity24),pages5823–5840,2024.[102]JuanmingShi,QinglangGuo,YongLiao,YuxingWang,ShijiaChen,andShenglinLiang.Legal-lm:Knowledgegraphenhancedlargelanguagemodelsforlawconsulting.InInternationalConferenceonIntelligentComputing,pages175–186.Springer,2024.[103]KaranSinghal,ShekoofehAzizi,TaoTu,SSaraMahdavi,JasonWei,HyungWonChung,NathanScales,AjayTanwani,HeatherCole-Lewis,StephenPfohl,etal.Largelanguagemodelsencodeclinicalknowledge.Nature,620(7972):172–180,2023.[104]KaranSinghal,TaoTu,JurajGottweis,RorySayres,ElleryWul-czyn,LeHou,KevinClark,StephenPfohl,HeatherCole-Lewis,DarleneNeal,etal.Towardsexpert-levelmedicalquestionanswer-ingwithlargelanguagemodels.arXivpreprintarXiv:2305.09617,2023.[105]CongzhengSongandAnanthRaghunathan.Informationleakageinembeddingmodels.InProceedingsofthe2020ACMSIGSACconferenceoncomputerandcommunicationssecurity,pages377–390,2020.[106]CongzhengSongandVitalyShmatikov.Auditingdataprovenanceintext-generationmodels.InProceedingsofthe25thACMSIGKDDInternationalConferenceonKnowledgeDiscovery&DataMining,pages196–206,2019.[107]JaredSpataro.Introducingmicrosoft365copilot.https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/,2023.[108]RobinStaab,MarkVero,MislavBalunovi´c,andMartinVechev.Beyondmemorization:Violatingprivacyviainferencewithlargelanguagemodels.arXivpreprintarXiv:2310.07298,2023.[109]Sudarsan.OptimizeAzureOpenAIApplicationswithSemanticCaching.https://techcommunity.microsoft.com/blog/azurearchitectureblog/optimize-azure-openai-applications-with-semantic-caching/4106867,2024.[Accessed15-11-2024].[110]JingyunSun,ChengxiaoDai,ZhongzeLuo,YangboChang,andYangLi.Lawluo:Achineselawfirmco-runbyllmagents.arXivpreprintarXiv:2407.16252,2024.[111]Talarian.GPTforMicrosoftExcelorGoogleSheets.https://gptforwork.com/,2024.[112]Talarian.OpenAIGPTpromptgenerator.https://gptforwork.com/tools/prompt-generator,2024.[113]ChuanyuanTan,YueheChen,WenbiaoShao,andWenliangChen.Makeachoice!knowledgebasequestionansweringwithin-contextlearning.arXivpreprintarXiv:2305.13972,2023.[114]MingtianTan,JunpengWan,ZheZhou,andZhouLi.Invisibleprobe:Timingattackswithpciecongestionside-channel.In2021IEEESymposiumonSecurityandPrivacy(SP),pages322–338.IEEE,2021.[115]ChaofanTao,QianLiu,LongxuDou,NiklasMuennighoff,Zhong-weiWan,PingLuo,MinLin,andNgaiWong.Scalinglawswithvocabulary:Largermodelsdeservelargervocabularies.arXivpreprintarXiv:2407.13623,2024.[116]ZuoyiTechnology.Zuoshouyishengopenplatforms.https://open.zuoshouyisheng.com/,2024.[117]ArunJamesThirunavukarasu,DarrenShuJengTing,KabilanElan-govan,LauraGutierrez,TingFangTan,andDanielShuWeiTing.Largelanguagemodelsinmedicine.Naturemedicine,29(8):1930–1940,2023.[118]ShanquanTian,ShayanMoini,AdamWolnikowski,DanielHol-comb,RussellTessier,andJakubSzefer.Remotepowerattacksontheversatiletensoracceleratorinmulti-tenantfpgas.In2021IEEE29thAnnualInternationalSymposiumonField-ProgrammableCustomComputingMachines(FCCM),pages242–246.IEEE,2021.[119]HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,NikolayBashlykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal.Llama2:Openfoundationandfine-tunedchatmodels.arXivpreprintarXiv:2307.09288,2023.[120]TaoTu,ShekoofehAzizi,DannyDriess,MikeSchaekermann,MohamedAmin,Pi-ChuanChang,AndrewCarroll,CharlesLau,RyutaroTanno,IraKtena,etal.Towardsgeneralistbiomedicalai.NEJMAI,1(3):AIoa2300138,2024.[121]AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.Attentionisallyouneed.Advancesinneuralinformationprocessingsystems,30,2017.[122]HanWang,SyedMahbubHafiz,KartikPatwari,Chen-NeeChuah,ZubairShafiq,andHoumanHomayoun.Stealthyinferenceattackondnnviacache-basedside-channelattacks.In2022Design,Automation&TestinEuropeConference&Exhibition(DATE),pages1515–1520.IEEE,2022.[123]WenjinWang,YunhaoLi,YixinOu,andYinZhang.Layoutandtaskawareinstructionpromptforzero-shotdocumentimagequestionanswering.arXivpreprintarXiv:2306.00526,2023.[124]ZhiruoWang,JunAraki,ZhengbaoJiang,MdRizwanParvez,andGrahamNeubig.Learningtofiltercontextforretrieval-augmentedgeneration.arXivpreprintarXiv:2311.08377,2023.[125]TomWarren.Thesearemicrosoft’sbingaisecretrulesandwhyitsaysit’snamedsydney.TheVerge,14,2023.[126]JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,DennyZhou,etal.Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels.Advancesinneuralinformationprocessingsystems,35:24824–24837,2022.[127]LingxiaoWei,BoLuo,YuLi,YannanLiu,andQiangXu.Iknowwhatyousee:Powerside-channelattackonconvolutionalneuralnetworkaccelerators.InProceedingsofthe34thAnnualComputerSecurityApplicationsConference,pages393–406,2018.[128]RoyWeiss,DanielAyzenshteyn,GuyAmit,andYisroelMirsky.Whatwasyourprompt?aremotekeyloggingattackonaiassistants.arXivpreprintarXiv:2403.09751,2024.[129]RoyWeiss,DanielAyzenshteyn,andYisroelMirsky.Whatwasyourprompt?aremotekeyloggingattackonAIassistants.In33rdUSENIXSecuritySymposium(USENIXSecurity24),pages3367–3384,Philadelphia,PA,August2024.USENIXAssociation.[130]QingsongWen,JingLiang,CarlesSierra,RoseLuckin,RichardTong,ZitaoLiu,PengCui,andJiliangTang.Aiforeducation(ai4edu):Advancingpersonalizededucationwithllmandadaptivelearning.InProceedingsofthe30thACMSIGKDDConferenceonKnowledgeDiscoveryandDataMining,pages6743–6744,2024.[131]ShijieWu,OzanIrsoy,StevenLu,VadimDabravolski,MarkDredze,SebastianGehrmann,PrabhanjanKambadur,DavidRosenberg,andGideonMann.Bloomberggpt:Alargelanguagemodelforfinance.arXivpreprintarXiv:2303.17564,2023.[132]YangWu,ChenghaoWang,EceGumusel,andXiaozhongLiu.Knowledge-infusedlegalwisdom:Navigatingllmconsultationthroughthelensofdiagnosticsandpositive-unlabeledreinforcementlearning.arXivpreprintarXiv:2406.03600,2024.[133]PengXia,KangyuZhu,HaoranLi,HongtuZhu,YunLi,GangLi,LinjunZhang,andHuaxiuYao.Rule:Reliablemultimodalragforfactualityinmedicalvisionlanguagemodels.arXivpreprintarXiv:2407.05131,2024.[134]GuangxuanXiao,YuandongTian,BeidiChen,SongHan,andMikeLewis.Efficientstreaminglanguagemodelswithattentionsinks.arXivpreprintarXiv:2309.17453,2023.[135]MengjiaYan,ChristopherWFletcher,andJosepTorrellas.Cachetelepathy:Leveragingsharedresourceattackstolearn{DNN}ar-chitectures.In29thUSENIXSecuritySymposium(USENIXSecurity20),pages2003–2020,2020.[136]LiYang,QifanWang,JingangWang,XiaojunQuan,FuliFeng,YuChen,MadianKhabsa,SinongWang,ZenglinXu,andDongfangLiu.Mixpave:Mix-prompttuningforfew-shotproductattributevalueextraction.InFindingsoftheAssociationforComputationalLinguistics:ACL2023,pages9978–9991,2023.[137]XiYang,AokunChen,NimaPourNejatian,HooChangShin,KalebESmith,ChristopherParisien,ColinCompas,CherylMartin,MonaGFlores,YingZhang,etal.Gatortron:Alargeclinicallanguagemodeltounlockpatientinformationfromunstructuredelectronichealthrecords.arXivpreprintarXiv:2203.03540,2022.[138]YongYang,XuhongZhang,YiJiang,XiChen,HaoyuWang,Shoul-ingJi,andZonghuiWang.Prsa:Promptreversestealingattacksagainstlargelanguagemodels.arXivpreprintarXiv:2402.19200,2024.[139]LuYe,ZeTao,YongHuang,andYangLi.Chunkattention:Efficientself-attentionwithprefix-awarekvcacheandtwo-phasepartition.arXivpreprintarXiv:2402.15220,2024.[140]HonggangYu,HaochengMa,KaichenYang,YiqiangZhao,andYierJin.Deepem:Deepneuralnetworksmodelrecoverythroughemside-channelinformationleakage.In2020IEEEInternationalSymposiumonHardwareOrientedSecurityandTrust(HOST),pages209–218.IEEE,2020.[141]JiahaoYu,YuhangWu,DongShu,MingyuJin,andXinyuXing.Assessingpromptinjectionrisksin200+customgpts.arXivpreprintarXiv:2311.11538,2023.[142]YuxuanYue,ZhihangYuan,HaojieDuanmu,SifanZhou,JianlongWu,andLiqiangNie.Wkvquant:Quantizingweightandkey/valuecacheforlargelanguagemodelsgainsmore.arXivpreprintarXiv:2402.12065,2024.[143]AmirZandieh,InsuHan,VahabMirrokni,andAminKarbasi.Sub-gen:Tokengenerationinsublineartimeandmemory.arXivpreprintarXiv:2402.06082,2024.[144]YimingZhang,NicholasCarlini,andDaphneIppolito.Effectivepromptextractionfromlanguagemodels.InFirstConferenceonLanguageModeling,2024.[145]ZhenyuZhang,YingSheng,TianyiZhou,TianlongChen,LianminZheng,RuisiCai,ZhaoSong,YuandongTian,ChristopherR´e,ClarkBarrett,etal.H2o:Heavy-hitteroracleforefficientgenerativeinferenceoflargelanguagemodels.AdvancesinNeuralInformationProcessingSystems,36,2024.[146]ZhuoshengZhang,AstonZhang,MuLi,andAlexSmola.Automaticchainofthoughtpromptinginlargelanguagemodels.arXivpreprintarXiv:2210.03493,2022.[147]XufengZhao,MengdiLi,WenhaoLu,CorneliusWeber,JaeHeeLee,KunChu,andStefanWermter.Enhancingzero-shotchain-of-thoughtreasoninginlargelanguagemodelsthroughlogic.arXivpreprintarXiv:2309.13339,2023.[148]LianminZheng,LiangshengYin,ZhiqiangXie,JeffHuang,ChuyueSun,CodyHaoYu,ShiyiCao,ChristosKozyrakis,IonStoica,JosephEGonzalez,etal.Efficientlyprogramminglargelanguagemodelsusingsglang.arXivpreprintarXiv:2312.07104,2023.[149]BanghuaZhu,YingSheng,LianminZheng,ClarkBarrett,MichaelIJordan,andJiantaoJiao.Onoptimalcachingandmodelmultiplex-ingforlargemodelinference.arXivpreprintarXiv:2306.02003,2023.[150]HanlinZhu,BanghuaZhu,andJiantaoJiao.Efficientpromptcachingviaembeddingsimilarity,2024.[151]HenryPengZou,VinaySamuel,YueZhou,WeizhiZhang,LianchengFang,ZiheSong,PhilipSYu,andCorneliaCaragea.Implicitave:Anopen-sourcedatasetandmultimodalllmsbench-markforimplicitattributevalueextraction.arXivpreprintarXiv:2404.15592,2024.
