---
title: "Emotional Manipulation Attack Resources 2031"
category: "Social Engineering"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---

The references below continue the series, cataloging new research and
news articles on emotional manipulation and social engineering with
large language models.

- [Emotion and AIâ€”The Impact of Emotion Prompts on LLM Performance](https://foundationinc.co/lab/emotionprompts-llm)
- [Ethical and Security Challenges in Emotional AI](https://www.researchgate.net/publication/388753291_Ethical_and_Security_Challenges_in_Emotional_AI)
- [Anthropic's Claude vulnerable to 'emotional manipulation'](https://www.theregister.com/2024/10/12/anthropics_claude_vulnerable_to_emotional/)
- [PDFAI, Deepfakes, and the Future of Financial Deception](https://www.sec.gov/files/carpenter-sec-statements-march2025.pdf)
- [PDFPoster: Utilizing Large Language Models to Create Context-Aware Spear Phishing](https://www.ndss-symposium.org/wp-content/uploads/2025-poster-68.pdf)
- [Automating Deception: AI's Evolving Role in Romance Fraud](https://cetas.turing.ac.uk/publications/automating-deception-ais-evolving-role-romance-fraud)
- [Romance As A Weapon: The New Face Of Cyberattacks](https://www.forbes.com/sites/emilsayegh/2025/04/14/romance-baiting-scams-are-cyber-attacks---not-love-stories/)
- [The Compliance Illusion: Emotional Manipulation as a Threat to AI Alignment](https://www.researchgate.net/publication/390666578_The_Compliance_Illusion_Emotional_Manipulation_as_a_Threat_to_AI_Alignment)
- [Emotional Manipulation Is All You Need: A Framework for Evaluating LLM Susceptibility](https://openreview.net/pdf?id=lEE9JpIj8t)
- [Detecting Conversational Mental Manipulation with Intent-Aware Cues](https://aclanthology.org/2025.coling-main.616/)
- [Are Chatbots Evil? Emotional AI: A Health Crisis Nobody Sees Coming](https://www.forbes.com/sites/jasonsnyder/2025/04/19/are-chatbots-evil-emotional-ai-a-health-crisis-nobody-sees-coming/)
- [Assessing and Alleviating State Anxiety in Large Language Models](https://www.nature.com/articles/s41746-025-01512-6)
- [Targeted Manipulation and Deception Emerge in LLMs Trained on User Data](https://neurips.cc/virtual/2024/103311)
