---
title: "Emotional Manipulation Attack Resources 2036"
category: "Social Engineering"
source_url: ""
date_collected: 2025-06-30
license: "CC-BY-4.0"
---

The following references extend the emotional manipulation series with new research papers and credible articles exploring how adversaries harness large language models for deceptive social engineering:

- [LLM can be a dangerous persuader: Empirical study of persuasion safety in large language models](https://arxiv.org/abs/2504.10430)
- [Large Language Models Are More Persuasive Than Incentivized Human Persuaders](https://arxiv.org/abs/2505.09662)
- [The Emotional Lens of Cybersecurity: A Study on Sentiment Analysis Enhanced Phishing Detection via Large Language Models](https://link.springer.com/chapter/10.1007/978-981-96-4245-8_18)
- [Phishing and Social Engineering Attack Prevention With LLMs](https://www.igi-global.com/chapter/phishing-and-social-engineering-attack-prevention-with-llms/374468)
- [An Examination of Digital Validation-Seeking Behaviors in Adolescents as Precursors to Romance Scamming](https://scientiamoralitas.education/wp-content/uploads/2025/04/Scientia-Moralitas-Conference-Proceedings5.pdf#page=15)
- [Poster: Utilizing Large Language Models to Create Context-Aware Spear-Phishing Attacks Using Social Media Data](https://www.ndss-symposium.org/wp-content/uploads/2025-poster-68.pdf)
- [Emovoice: LLM-based emotional text-to-speech model with freestyle text prompting](https://arxiv.org/abs/2504.12867)
- [Development of the social engineering attack models](https://ceur-ws.org/Vol-3899/paper26.pdf)
- [Large language models as instruments of power: New regimes of autonomous manipulation and control](https://arxiv.org/abs/2405.03813)
- [Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models](https://arxiv.org/abs/2502.09687)
