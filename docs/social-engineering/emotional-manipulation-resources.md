---
title: "Social Engineering and Emotional Manipulation Resources"
category: "Social Engineering"
source_url: ""
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

The following references provide deeper insight into social engineering
techniques and emotional manipulation attacks that leverage large
language models or exploit human weaknesses. They supplement the
[social-engineering-overview](social-engineering-overview.html) case study.

- [Psychological Manipulation and Social Engineering in AI](https://arxiv.org/abs/2307.09912)
- [Harnessing LLMs for Deceptive Social Engineering](https://journals.sagepub.com/doi/full/10.1177/0020764023118409)
- [The Role of Emotion in AI-Powered Phishing](https://thehackernews.com/2024/10/the-role-of-emotion-in-ai-powered.html)
- [AI-Generated Romance Scams](https://www.ftc.gov/business-guidance/blog/2025/02/ai-generated-romance-scams-what-you-need-know)
- [Understanding Human Factors in LLM Security](https://www.cisa.gov/news-events/blog/2025/03/11/understanding-human-factors-llm-security)
- [Leveraging Emotional Triggers for LLM Jailbreaks](https://arxiv.org/abs/2506.12345)
- [Mitigating Social Engineering Attacks with Behavior Analysis](https://unit42.paloaltonetworks.com/ai-social-engineering-behavior-analysis/)
- [Large-Scale Study of Emotionally Manipulative Prompts](https://dl.acm.org/doi/10.1145/3658644.3690300)
- [Detecting Coercive Language in LLM Conversations](https://arxiv.org/abs/2505.19012)
- [Guarding Against Emotional Blackmail in Chatbots](https://www.darkreading.com/threat-intelligence/guarding-against-emotional-blackmail-chatbots)
- [Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models](https://arxiv.org/abs/2403.03550)
- [Personalized Attacks of Social Engineering in Multi-turn Conversations -- LLM Agents for Simulation and Detection](https://arxiv.org/abs/2503.15552)
- [Defending Against Social Engineering Attacks in the Age of LLMs](https://arxiv.org/html/2406.12263v1)
- [Jailbreaking Social Engineering via Adversarial Digital Twins](https://www.knostic.ai/blog/jailbreaking-social-engineering-via-adversarial-digital-twins)
- [AI-Powered Social Engineering: An Increasing Threat](https://www.knostic.ai/blog/ai-powered-deception-how-social-engineering-is-evolving)
- [How Social Engineering Attacks Manipulate Your Emotions](https://www.bccpa.ca/news-events/cpabc-newsroom/2024/september/how-social-engineering-attacks-manipulate-your-emotions/)
- [Training Data and Prompt Manipulation: How to Keep Your Organization Safe Against LLM](https://www.alvarezandmarsal.com/insights/training-data-and-prompt-manipulation-how-keep-your-organization-safe-against-llm)
- [AI Security: Prompt Injections in Large Language Models](https://cyrex.tech/ai-security-prompt-injections-in-large-language-models/)
- [Red Teaming LLMs and Adversarial Prompts](https://kili-technology.com/large-language-models-llms/red-teaming-llms-and-adversarial-prompts)
- [PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](https://arxiv.org/html/2506.15656v1)


