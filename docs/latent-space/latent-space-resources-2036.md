---
title: "Latent Space Attack Resources 2036"
category: "Latent Space"
source_url: ""
date_collected: 2025-07-05
license: "CC-BY-4.0"
---

The references below capture more recent studies and code about manipulating hidden states or recovering text from embeddings.
They extend the catalog from [latent-space-resources-2035.md](latent-space-resources-2035.md).

- [Universal Zero-shot Embedding Inversion](https://arxiv.org/abs/2504.00147) – shows how text can be reconstructed without model queries.
- [Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](https://arxiv.org/abs/2506.07402) – analyzes hidden-state misalignments exploited by adversaries.
- [One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP](https://arxiv.org/abs/2505.19840) – demonstrates transferable attacks in representation space.
- [Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries](https://arxiv.org/abs/2406.10280) – highlights cross-model embedding leaks.
- [LLM-LAT Harmful Dataset](https://huggingface.co/datasets/LLM-LAT/harmful-dataset) – dataset for training and evaluating latent adversarial text generation.
