---
title: "Latent Space Attack Resources 2028"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below capture additional research focused on manipulating or defending hidden representations in large language models. They extend [latent-space-resources-2027.md](latent-space-resources-2027.md).

- [RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?](https://arxiv.org/abs/2506.14261)
- [AdversariaL attacK sAfety aLIgnment (ALKALI): Safeguarding LLMs through GRACE](https://arxiv.org/abs/2506.08885)
- [LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](https://arxiv.org/abs/2505.10838)
- [Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI](https://arxiv.org/abs/2504.13201)
- [Alignment Quality Index: Beyond Refusals as an Intrinsic Alignment Diagnostic via Latent Geometry](https://arxiv.org/abs/2506.13901)
