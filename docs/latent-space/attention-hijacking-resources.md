---
title: "Attention Hijacking Resources"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below focus on manipulating a transformer's **attention** mechanisms to subvert or hijack LLM behavior.

- [Universal Jailbreak Suffixes Are Strong Attention Hijackers](https://arxiv.org/abs/2506.12880)
- [Attention Hijackers: Detect and Disentangle Attention Hijacking in LVLMs](https://arxiv.org/abs/2503.08216)
- [ShadowCoT: Cognitive Hijacking for Stealthy Reasoning Backdoors in LLMs](https://arxiv.org/abs/2504.05605)
- [Pseudo-Conversation Injection for LLM Goal Hijacking](https://arxiv.org/abs/2410.23678)
- [Attention Hijacking in Trojan Transformers](https://arxiv.org/abs/2208.04946)
