---
title: "Additional Resources on LLM Attacks 2035"
category: "Overview"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---
The references below highlight research published after the 2034 snapshot. They focus on supply-chain threats and emerging backdoor techniques.

- [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://www.semanticscholar.org/paper/42abbbbf6581c5ad37d6378aed3194690c9ba81e)
- [How well does LLM generate security tests?](https://www.semanticscholar.org/paper/0ace4a1d304649d6b48f12104855bcda1fa76d54)
- [ASPIRER: Bypassing System Prompts With Permutation-based Backdoors in LLMs](https://www.semanticscholar.org/paper/9e7c869577cbab463576f7a63d4575ad073e4fa1)
- [Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems](https://www.semanticscholar.org/paper/85fe670df8b056520eb747277d70769f9a532816)
- [Understanding Stakeholders' Perceptions and Needs Across the LLM Supply Chain](https://www.semanticscholar.org/paper/0725917ff4498c8916ce78234e1feb65ca8ca4bf)
- [LLM Supply Chain Provenance: A Blockchain-based Approach](https://www.semanticscholar.org/paper/23b031e5b84a114ad5b27ea92a3e0689b92fd590)
- [Unpacking Trust Dynamics in the LLM Supply Chain: An Empirical Exploration to Foster Trustworthy LLM Production & Use](https://www.semanticscholar.org/paper/34b10289a1d76f668dbccc6ef63c2f024558e3aa)
