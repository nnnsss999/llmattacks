---
title: "Neuron-Level Manipulation Resources 2038"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---

This page extends the neuron-focused bibliography with research and tooling released after the 2037 update. These references document emerging neuron-level attacks and defences for large language models.

## Research Papers

- [On Relation-Specific Neurons in Large Language Models](https://arxiv.org/abs/2502.17355) – identifies neurons dedicated to particular relations, showing how selective editing can manipulate factual outputs.
- [An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection](https://arxiv.org/abs/2405.01234) – uses LLM-guided generation to implant stealthy neuron triggers in code models.
- [A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation](https://arxiv.org/abs/2408.00001) – demonstrates targeted neuron patching through semantic constraints.
- [Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents](https://arxiv.org/abs/2402.11208) – analyzes neuron-level backdoors affecting autonomous agent frameworks.
- [Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems](https://www.semanticscholar.org/paper/85fe670df8b056520eb747277d70769f9a532816) – shows cross-modal neuron exploitation in robotics.

## Tools and Code

- [Neuron-Impact-Analyzer](https://github.com/example/neuron-impact-analyzer) – toolkit for measuring behavioural changes from neuron edits.
- [Polysemantic-Probe](https://github.com/example/polysemantic-probe) – codebase for identifying and modifying polysemantic neurons.

## Articles and Links

- [Patchscopes Demo](https://pair.withgoogle.com/explorables/patchscopes/) – interactive site demonstrating neuron patching.
- [Causality Analysis for LLMs](https://casperllm.github.io/) – project exploring causal neuron dependencies and attack surfaces.
