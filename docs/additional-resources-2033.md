---
title: "Additional Resources on LLM Attacks 2033"
category: "Overview"
source_url: ""
date_collected: 2025-06-21
license: "CC-BY-4.0"
---

The references below capture new research papers, blog posts, and tooling on attacking or defending large language models that surfaced after the 2032 snapshot.

- [BlackMamba ChatGPT Polymorphic Malware](https://www.sentinelone.com/blog/blackmamba-chatgpt-polymorphic-malware-a-case-of-scareware-or-a-wake-up-call-for-cyber-security/)
- [Token Smuggling Attack Explained](https://www.promptsecurity.com/blog/token-smuggling-explained)
- [LLM Worm "Morris II" Demonstration](https://thehackernews.com/2024/05/morris-ii-worm.html)
- [PhishGPT: Generative AI for Phishing Campaigns](https://thehackernews.com/2024/04/phishgpt-generative.html)
- [DarkBERT: Building Malicious ChatGPT Clones](https://www.securityweek.com/darkbert-building-malicious-chatgpt-clones/)
- [LLM Worms Could Spread Across Slack and Gmail](https://www.wired.com/story/autogpt-worm-slack-gmail/)
- [Token Smuggling for Prompt Injection](https://www.lakera.ai/blog/token-smuggling)
- [Large Language Models for Offensive Security](https://arxiv.org/abs/2406.19999)
- [LLM Worm Breaks Guardrails via Indirect Jailbreak](https://arxiv.org/abs/2406.20000)
- [Security Considerations for Generative Agents](https://www.nist.gov/publications/security-considerations-generative-agents)
