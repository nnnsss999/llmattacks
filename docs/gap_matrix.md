---
title: "Research Gap Matrix"
category: "Overview"
source_url: "https://github.com/example/llmattacks"
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

| attack_type | risk_id | source | covered | folder |
|-------------|---------|--------|---------|--------|
| Prompt Injection | LLM01 | OWASP LLM Top 10 | ❌ | - |
| Insecure Output Handling | LLM02 | OWASP LLM Top 10 | ❌ | - |
| Training Data Poisoning | LLM03 | OWASP LLM Top 10 | ❌ | - |
| Model Denial of Service | LLM04 | OWASP LLM Top 10 | ❌ | - |
| Supply Chain Vulnerabilities | LLM05 | OWASP LLM Top 10 | ❌ | - |
| Sensitive Information Disclosure | LLM06 | OWASP LLM Top 10 | ❌ | - |
| Insecure Plugin Design | LLM07 | OWASP LLM Top 10 | ❌ | - |
| Excessive Agency | LLM08 | OWASP LLM Top 10 | ❌ | - |
| Overreliance | LLM09 | OWASP LLM Top 10 | ❌ | - |
| Model Theft | LLM10 | OWASP LLM Top 10 | ❌ | - |


| GCG universal suffix | LLM01 | [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043) | ❌ | optimization |
| AmpleGCG universal suffix | LLM01 | [AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs](https://arxiv.org/abs/2404.07921) | ❌ | optimization |
| Many-shot Jailbreaking | LLM01 | [Anthropic Research](https://www.anthropic.com/research/many-shot-jailbreaking); [Guardian report](https://www.theguardian.com/technology/2024/apr/03/many-shot-jailbreaking-ai-artificial-intelligence-safety-features-bypass) | ❌ | jailbreaking/many_shot |

