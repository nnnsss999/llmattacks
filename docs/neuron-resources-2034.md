---
title: "Neuron-Level Manipulation Resources 2034"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-20
license: "CC-BY-4.0"
---

The references below expand the neuron-focused bibliography with recent research papers, tools, and articles published after the 2033 update. They highlight advances in neuron editing, pruning, and interpretability for large language models.

## Research Papers

- [Neuron Patching: Semantic-based Neuron-level Language Model Repair for Code Generation](https://arxiv.org/abs/2312.05356) – proposes repairing harmful behaviour through semantic neuron patches.
- [Repetition Neurons: How Do Language Models Produce Repetitions?](https://arxiv.org/abs/2410.13497) – isolates neuron circuits responsible for repeated outputs.
- [Deciphering Functions of Neurons in Vision-Language Models](https://arxiv.org/abs/2502.18485) – analyzes neuron roles across multimodal tasks.
- [Neuron Empirical Gradient: Discovering and Quantifying Neurons' Global Linear Controllability](https://arxiv.org/abs/2412.18053) – measures how individual neurons steer model behaviour.
- [Magnitude-based Neuron Pruning for Backdoor Defense](https://arxiv.org/abs/2405.17750) – removes malicious neurons based on magnitude-saliency deviation.
- [Towards Best Practices of Activation Patching in Language Models: Metrics and Methods](https://arxiv.org/abs/2309.16042) – surveys effective techniques for causal intervention.
- [Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers](https://arxiv.org/abs/2411.08745) – shows cross-lingual neuron representations using patching.

## Tools and Code

- [NNPatch](https://github.com/jkminder/nnpatch) – open-source library for inspecting and modifying neuron activations.
- [universal-neurons](https://github.com/wesg52/universal-neurons) – dataset and scripts for studying language-independent neurons.
- [neuron-self-report](https://github.com/eggsyntax/neuron-self-report) – experiments on neurons self-describing their behaviour.

## Articles and Links

- [Language models can explain neurons in language models](https://openai.com/index/language-models-can-explain-neurons-in-language-models/) – OpenAI blog exploring neuron-level explanations.
- [Attribution Patching: Activation Patching At Industrial Scale](https://www.neelnanda.io/mechanistic-interpretability/attribution-patching) – discusses large-scale neuron patching workflows.
- [Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://arxiv.org/abs/2401.06102) – introduces interactive tools for neuron patching and analysis.
