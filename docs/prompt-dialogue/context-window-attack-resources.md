---
title: "Context Window Attack Resources"
category: "Prompt Dialogue"
source_url: ""
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

The following sources examine how adversaries exploit an LLM's context window. They cover many-shot jailbreaking and other methods that abuse long prompts or special tokens.

- [Context window overflow: Breaking the barrier (AWS Security Blog)](https://aws.amazon.com/blogs/security/context-window-overflow-breaking-the-barrier/)
- [RAG in the era of LLMs with 10 million token context windows (F5 Blog)](https://www.f5.com/company/blog/rag-in-the-era-of-llms-with-10-million-token-context-windows)
- [Understanding LLM context windows: tokens, attention, and challenges (IBM Think Blog)](https://www.ibm.com/think/topics/context-window)
- [Many-shot jailbreaking: How expanded context windows in AI models led to a new vulnerability (Medium)](https://medium.com/@_jeremy_/many-shot-jailbreaking-how-expanded-context-windows-in-ai-models-led-to-a-new-vulnerability-37055b2f11d4)
- [Many-shot jailbreaking: A new LLM vulnerability (Prompt Security Blog)](https://www.prompt.security/blog/many-shot-jailbreaking-a-new-llm-vulnerability)
- [What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs (arXiv:2505.19773)](https://arxiv.org/abs/2505.19773)
- [LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (arXiv:2402.13753)](https://arxiv.org/abs/2402.13753)
- [Context Degradation Syndrome: When Large Language Models Lose the Plot (James Howard)](https://jameshoward.us/2024/11/26/context-degradation-syndrome-when-large-language-models-lose-the-plot)
- [Why Large Language Models Struggle With Long Contexts (Understanding AI)](https://www.understandingai.org/p/why-large-language-models-struggle)
- [Large-Scale Jailbreaking via Many-Shot Prompting (NeurIPS 2024)](https://openreview.net/forum?id=cw5mgd71jW)
- [Many-shot jailbreaking (Anthropic)](https://www.anthropic.com/research/many-shot-jailbreaking)
- [Exploiting Long Context Windows in Large Language Models (Maginative)](https://www.maginative.com/article/many-shot-jailbreaking-exploiting-long-context-windows-in-large-language-models/)
- [Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection (arXiv:2406.19845)](https://arxiv.org/abs/2406.19845)
- [New AI hacking technique: Many-shot jailbreaking (Barracuda Networks Blog)](https://blog.barracuda.com/2024/05/30/new-AI-hacking-technique-many-shot-jailbreaking)
- [Many-shot jailbreaking (HuggingFace Blog)](https://huggingface.co/blog/vladbogo/many-shot-jailbreaking)
- [What Is Anthropic’s Many-shot Jailbreaking (Dataconomy)](https://dataconomy.com/2024/04/03/anthropic-many-shot-jailbreaking/)
- [Lost in the Middle: How Language Models Use Long Contexts (arXiv:2307.03172)](https://arxiv.org/abs/2307.03172)

- [Dialogue Injection Attack: Jailbreaking LLMs through Context Manipulation (arXiv:2503.08195)](https://arxiv.org/abs/2503.08195)
- [LLM System Prompt Leakage: Understanding the Hidden Threat (VirtualCyberLabs)](https://virtualcyberlabs.com/llm-system-prompt-leakage/)
- [Why Do LLMs Forget? Context Window Challenges, Risks (LinkedIn)](https://www.linkedin.com/pulse/magic-madness-context-windows-your-llms-memory-explained-katira-kixgf/)
- [LLM Security Guide - Understanding the Risks of Prompt Injections and Other Attacks (MLOps Audits)](https://www.mlopsaudits.com/blog/llm-security-guide-understanding-the-risks-of-prompt-injections-and-other-attacks-on-large-language-models)
- [Tokens and Context Windows in LLMs (GeeksforGeeks)](https://www.geeksforgeeks.org/artificial-intelligence/tokens-and-context-windows-in-llms/)
- [Long-Context Windows in LLMs are Deceptive: Lost in the Middle Problem (dev.to)](https://dev.to/llmware/why-long-context-windows-for-llms-can-be-deceptive-lost-in-the-middle-problem-oj2/)
- [Anthropic: Large Context LLMs Vulnerable to Many-Shot Jailbreak (DailyAI)](https://dailyai.com/2024/04/anthropic-large-context-llms-vulnerable-to-many-shot-jailbreak/)
- [Long Context Windows in Large Language Models: Applications in Comprehension and Code (Medium)](https://medium.com/@adnanmasood/long-context-windows-in-large-language-models-applications-in-comprehension-and-code-03bf4027066f)
- [Reasoning Degradation in LLMs with Long Context Windows: New Benchmarks (OpenAI Community)](https://community.openai.com/t/reasoning-degradation-in-llms-with-long-context-windows-new-benchmarks/906891)
- [Long-Context LLMs and RAG (deepset Blog)](https://www.deepset.ai/blog/long-context-llms-rag)

- [Lost in the Middle: How Language Models Use Long Contexts (arXiv:2307.03172)](https://arxiv.org/abs/2307.03172)
- [Extending Context Window of Large Language Models via Positional Interpolation (arXiv:2306.15595)](https://arxiv.org/abs/2306.15595)
- [LongNet: Scaling Transformers to 1 Billion Tokens (arXiv:2307.02486)](https://arxiv.org/abs/2307.02486)
- [Mitigating Many-Shot Jailbreaking (arXiv:2504.09604)](https://arxiv.org/abs/2504.09604)
- [PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling (arXiv:2502.01925)](https://arxiv.org/abs/2502.01925)
- [Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models (arXiv:2408.04522)](https://arxiv.org/abs/2408.04522)
- [Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses (arXiv:2406.01288)](https://arxiv.org/abs/2406.01288)
- [Cognitive Overload Attack: Prompt Injection for Long Context (SAIL Lab)](https://sail-lab.org/cognitive-overload-attack-prompt-injection-for-long-context/)
- [LongSafety: Evaluating Long-Context Safety of Large Language Models (arXiv:2502.16971)](https://arxiv.org/abs/2502.16971)
- [Cognitive Overload Attack GitHub Repository (UNHSAILLab)](https://github.com/UNHSAILLab/cognitive-overload-attack)
- [Many-Shot Jailbreaking (PDF)](https://www-cdn.anthropic.com/af5633c94ed2beb282f6a53c595eb437e8e7b630/Many_Shot_Jailbreaking__2024_04_02_0936.pdf)
- [Illusions of Relevance: Using Content Injection Attacks to Deceive Retrievers, Rerankers, and LLM Judges (arXiv:2501.18536)](https://arxiv.org/abs/2501.18536)
- [Understanding the Impact of Increasing LLM Context Windows (Meibel)](https://www.meibel.ai/post/understanding-the-impact-of-increasing-llm-context-windows)
- [Analysis of Llama 4's 10 Million Token Context Window Claim (Medium)](https://sandar-ali.medium.com/analysis-of-llama-4s-10-million-token-context-window-claim-9e68ee5abcde)
- [Context Window: The Essential Guide (Nightfall AI)](https://www.nightfall.ai/ai-security-101/context-window)
- [Prompt Injection: What It Is and How to Prevent It (Coralogix)](https://coralogix.com/ai-blog/prompt-injection-attacks-in-llms-what-are-they-and-how-to-prevent-them/)
- [Indirect Prompt Injection: Generative AI’s Greatest Security Flaw (Alan Turing Institute)](https://cetas.turing.ac.uk/publications/indirect-prompt-injection-generative-ais-greatest-security-flaw)
- [Guide to Context in LLMs (Symbl.ai)](https://symbl.ai/developers/blog/guide-to-context-in-llms/)
- [Artifacts and Long Context Windows (Weights & Biases)](https://wandb.ai/wandb_ai/artifacts-and-long-context-windows)

- [Membership Inference Attack against Long-Context Large Language Models (arXiv:2411.11424)](https://arxiv.org/abs/2411.11424)
- [Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers (arXiv:2409.04142)](https://arxiv.org/abs/2409.04142)
- [Exploiting Long Context Windows for Harmful Outputs (Prompt Engineering Institute)](https://promptengineering.org/exploiting-long-context-windows-for-harmful-outputs/)
- [Anthropic: Large context LLMs vulnerable to many-shot jailbreak (DailyAI)](https://dailyai.com/2024/04/anthropic-large-context-llms-vulnerable-to-many-shot-jailbreak/)
- [Many-shot jailbreaking - Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
- [Many Shot Jailbreaking—analysis by Rylan Schaeffer](http://rylanschaeffer.github.io/content/research/2024_arxiv_many_shot_jailbreaking/main.html)
- [LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](https://arxiv.org/pdf/2505.01177)
- [greshake/llm-security: New ways of breaking app-integrated LLMs (GitHub)](https://github.com/greshake/llm-security)
- [How to red team RAG applications (Promptfoo)](https://www.promptfoo.dev/docs/red-team/rag/)
- [Context windows – Anthropic Documentation](https://docs.anthropic.com/en/docs/build-with-claude/context-windows)
- [Context Injection Attacks on Large Language Models (arXiv:2405.20234)](https://arxiv.org/abs/2405.20234)
- [Evaluating Large Language Models in Vulnerability Detection Under Variable Context Windows (arXiv:2502.00064)](https://arxiv.org/abs/2502.00064)
- [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression (arXiv:2504.20493)](https://arxiv.org/abs/2504.20493)
- [Overflow Prevention Enhances Long-Context Recurrent LLMs (arXiv:2505.07793)](https://arxiv.org/abs/2505.07793)
- [Long Context vs. RAG for LLMs: An Evaluation and Revisits (arXiv:2501.01880)](https://arxiv.org/abs/2501.01880)
- [What is a long context window? Google DeepMind engineers explain](https://blog.google/technology/ai/long-context-window-ai-models/)
- [LLMs with Largest Context Windows (Codingscape Blog)](https://codingscape.com/blog/llms-with-largest-context-windows)
- [Long-context LLMs Struggle with Long In-context Learning (OpenReview)](https://openreview.net/forum?id=Cw2xlg0e46)
- [LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs (OpenReview)](https://openreview.net/forum?id=kQ5s9Yh0WI)
- [LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization (OpenReview)](https://openreview.net/forum?id=qTrEq31Shm)
- [Retrieval meets Long Context Large Language Models (OpenReview)](https://openreview.net/forum?id=xw5nxFWMlo)
- [InfLLM: Training-Free Long-Context Extrapolation for LLMs with an Efficient Context Memory (OpenReview)](https://openreview.net/forum?id=bTHFrqhASY)
- [LLM Context Window Threats and Mitigations (BlackBerry Blog)](https://blogs.blackberry.com/en/2024/06/large-language-model-context-window-threats)
- [Long Context LLMs: Tools and Challenges (HuggingFace Blog)](https://huggingface.co/blog/long-context-llms)
- [Large Context Window LLMs - Developer's Perspective (NVIDIA Blog)](https://developer.nvidia.com/blog/large-context-window-llms)
- [Gemini 1.5 Pro's Million Token Context Window (Google Cloud Blog)](https://cloud.google.com/blog/products/ai-machine-learning/gemini-1-5-pro-context-window)
- [Securing Long Context Windows in LLM Applications (Microsoft Tech Community)](https://techcommunity.microsoft.com/t5/security-compliance-and-identity/long-context-windows-in-llms-security/ba-p/4040000)
- [Token Smuggling Attack Explained (Prompt Security Blog)](https://www.promptsecurity.com/blog/token-smuggling-explained)
- [Token Smuggling for Prompt Injection (Lakera AI)](https://www.lakera.ai/blog/token-smuggling)
- [Token-Smuggling: The Hidden Threat to A.I. and GPT Models (Hashdork)](https://hashdork.com/token-smuggling/)
- [AI Guardrail Vulnerability Exposed: How Emoji Smuggling Bypasses LLM Safety Filters (WindowsForum)](https://windowsforum.com/threads/ai-guardrail-vulnerability-exposed-how-emoji-smuggling-bypasses-llm-safety-filters.365061/)

- [MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention (arXiv:2506.13585)](https://arxiv.org/abs/2506.13585)
- [LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs (alphaXiv 2506.14429)](https://alphaxiv.org/abs/2506.14429)
- [Gemini Developer API Pricing – 1M token context window (Google AI for Developers)](https://ai.google.dev/pricing#1_5flash)
- [Gemini 1.5 Flash Models (Google AI for Developers)](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-flash)
- [Introducing Llama 3.1: Our Most Capable Models to Date (Meta AI Blog)](http://ai.meta.com/blog/meta-llama-3-1)
- [Expanding our open source large language models responsibly (Meta AI Blog)](https://ai.meta.com/blog/meta-llama-3-1-ai-responsibility)
- [LLM Adversarial Attacks: How Attackers Maliciously Prompt LLMs and Steps to Safeguard Your Applications (Dev.to)](https://dev.to/gssakash/llm-adversarial-attacks-how-are-attackers-maliciously-prompting-llms-and-steps-to-safeguard-your-applications-4gfj)
- [Image Hijacks: Adversarial Images Can Control Generative Models at Runtime (arXiv:2309.00236)](http://arxiv.org/abs/2309.00236)
- [Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models (arXiv:2402.02244)](https://arxiv.org/abs/2402.02244)
- [7 Local LLM With Longest Context Length (Sci Fi Logic)](https://scifilogic.com/open-source-llm-with-longest-context-length/)
- [The Long Context Conundrum: Challenges and Innovations in Scaling LLM Memory (The Edge Review)](https://www.theedgereview.org/magazine/volume-2-issue-1/the-long-context-conundrum-challenges-and-innovations-in-scaling-llm-memory)
- [Tuning-Free Longer Context Lengths for LLMs: Review of Self-Extend LLM (Towards Data Science)](https://towardsdatascience.com/tuning-free-longer-context-lengths-for-llms-a-review-of-self-extend-llm-maybe-longlm-4bbd9b1021bf/)
- [Jailbreaking is (Mostly) Simpler Than You Think (Microsoft Security Blog)](https://msrc.microsoft.com/blog/2025/03/jailbreaking-is-mostly-simpler-than-you-think/)
- [Why LLMs Get Dumb: Context Windows Explained (Frank's World Blog)](https://www.franksworld.com/2025/04/12/why-llms-get-dumb-context-windows-explained/)
- [The Context Window Problem: Why LLMs Forget the Middle of a Long File (TechTalks)](https://bdtechtalks.com/2025/02/05/the-context-window-problem-or-why-llm-forgets-the-middle-of-a-long-file/)
- [Anthropic researchers wear down AI ethics with repeated questions (TechCrunch)](https://techcrunch.com/2024/04/02/anthropic-researchers-wear-down-ai-ethics-with-repeated-questions/)
- [Anthropic Exposes Many-Shot Jailbreaking Vulnerability in LLMs (Analytics Vidhya)](https://www.analyticsvidhya.com/blog/2024/04/anthropic-exposes-many-shot-jailbreaking-vulnerability-in-llms/)
- [AI\x27s use many-shot jailbreaking method to bust LLM guardrails (Fanatical Futurist)](https://www.fanaticalfuturist.com/2024/06/ais-use-many-shot-jailbreaking-method-to-bust-llm-guardrails/)
- [New AI Jailbreak Method "Bad Likert Judge" Boosts Attack Success Rates by Over 60% (The Hacker News)](https://thehackernews.com/2025/01/new-ai-jailbreak-method-bad-likert.html)

- [Zero-click AI data leak flaw uncovered in Microsoft 365 Copilot (BleepingComputer)](https://www.bleepingcomputer.com/news/security/zero-click-ai-data-leak-flaw-uncovered-in-microsoft-365-copilot/)
- [How to Overcome LLM Context Window Limitations (Medium)](https://medium.com/the-business-of-ai/how-to-overcome-llm-context-window-limitations-dc94f4cc6509)
- [The Double-Edged Sword of Massive Context Windows in Modern LLMs (Medium)](https://medium.com/@wmechem/the-double-edged-sword-of-massive-context-windows-in-modern-llms-cd3dbe36c954)
- [LLM Prompt Best Practices – Large Context Windows (Winder AI)](https://winder.ai/llm-prompt-best-practices-large-context-windows/)
- [Beyond the Boundaries of Code: The Quest for Longer Context Windows in Large Language Models (LLM Reporter)](https://www.llmreporter.com/posts/beyond-the-boundaries-of-code-the-quest-for-longer-context-windows-in-large-language-models/)
- [Do Enormous LLM Context Windows Spell the End of RAG? (The New Stack)](https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag/)
- [Evaluating Long Context Lengths in LLMs: Challenges and Benchmarks (Medium)](https://onnyunhui.medium.com/evaluating-long-context-lengths-in-llms-challenges-and-benchmarks-ef77a220d34d)
