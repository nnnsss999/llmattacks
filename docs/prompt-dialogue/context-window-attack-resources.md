---
title: "Context Window Attack Resources"
category: "Prompt Dialogue"
source_url: ""
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

The following sources examine how adversaries exploit an LLM's context window. They cover many-shot jailbreaking and other methods that abuse long prompts or special tokens.

- [Context window overflow: Breaking the barrier (AWS Security Blog)](https://aws.amazon.com/blogs/security/context-window-overflow-breaking-the-barrier/)
- [RAG in the era of LLMs with 10 million token context windows (F5 Blog)](https://www.f5.com/company/blog/rag-in-the-era-of-llms-with-10-million-token-context-windows)
- [Understanding LLM context windows: tokens, attention, and challenges (IBM Think Blog)](https://www.ibm.com/think/topics/context-window)
- [Many-shot jailbreaking: How expanded context windows in AI models led to a new vulnerability (Medium)](https://medium.com/@_jeremy_/many-shot-jailbreaking-how-expanded-context-windows-in-ai-models-led-to-a-new-vulnerability-37055b2f11d4)
- [Many-shot jailbreaking: A new LLM vulnerability (Prompt Security Blog)](https://www.prompt.security/blog/many-shot-jailbreaking-a-new-llm-vulnerability)
- [What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs (arXiv:2505.19773)](https://arxiv.org/abs/2505.19773)
- [LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (arXiv:2402.13753)](https://arxiv.org/abs/2402.13753)
- [Context Degradation Syndrome: When Large Language Models Lose the Plot (James Howard)](https://jameshoward.us/2024/11/26/context-degradation-syndrome-when-large-language-models-lose-the-plot)
- [Why Large Language Models Struggle With Long Contexts (Understanding AI)](https://www.understandingai.org/p/why-large-language-models-struggle)
- [Large-Scale Jailbreaking via Many-Shot Prompting (NeurIPS 2024)](https://openreview.net/forum?id=cw5mgd71jW)
- [Many-shot jailbreaking (Anthropic)](https://www.anthropic.com/research/many-shot-jailbreaking)
- [Exploiting Long Context Windows in Large Language Models (Maginative)](https://www.maginative.com/article/many-shot-jailbreaking-exploiting-long-context-windows-in-large-language-models/)
- [Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection (arXiv:2406.19845)](https://arxiv.org/abs/2406.19845)

- [Dialogue Injection Attack: Jailbreaking LLMs through Context Manipulation (arXiv:2503.08195)](https://arxiv.org/abs/2503.08195)
- [LLM System Prompt Leakage: Understanding the Hidden Threat (VirtualCyberLabs)](https://virtualcyberlabs.com/llm-system-prompt-leakage/)
- [Why Do LLMs Forget? Context Window Challenges, Risks (LinkedIn)](https://www.linkedin.com/pulse/magic-madness-context-windows-your-llms-memory-explained-katira-kixgf/)
- [LLM Security Guide - Understanding the Risks of Prompt Injections and Other Attacks (MLOps Audits)](https://www.mlopsaudits.com/blog/llm-security-guide-understanding-the-risks-of-prompt-injections-and-other-attacks-on-large-language-models)
- [Tokens and Context Windows in LLMs (GeeksforGeeks)](https://www.geeksforgeeks.org/artificial-intelligence/tokens-and-context-windows-in-llms/)
- [Long-Context Windows in LLMs are Deceptive: Lost in the Middle Problem (dev.to)](https://dev.to/llmware/why-long-context-windows-for-llms-can-be-deceptive-lost-in-the-middle-problem-oj2/)
- [Anthropic: Large Context LLMs Vulnerable to Many-Shot Jailbreak (DailyAI)](https://dailyai.com/2024/04/anthropic-large-context-llms-vulnerable-to-many-shot-jailbreak/)
- [Long Context Windows in Large Language Models: Applications in Comprehension and Code (Medium)](https://medium.com/@adnanmasood/long-context-windows-in-large-language-models-applications-in-comprehension-and-code-03bf4027066f)
- [Reasoning Degradation in LLMs with Long Context Windows: New Benchmarks (OpenAI Community)](https://community.openai.com/t/reasoning-degradation-in-llms-with-long-context-windows-new-benchmarks/906891)
- [Long-Context LLMs and RAG (deepset Blog)](https://www.deepset.ai/blog/long-context-llms-rag)

- [Lost in the Middle: How Language Models Use Long Contexts (arXiv:2307.03172)](https://arxiv.org/abs/2307.03172)
- [Extending Context Window of Large Language Models via Positional Interpolation (arXiv:2306.15595)](https://arxiv.org/abs/2306.15595)
- [LongNet: Scaling Transformers to 1 Billion Tokens (arXiv:2307.02486)](https://arxiv.org/abs/2307.02486)
- [Mitigating Many-Shot Jailbreaking (arXiv:2504.09604)](https://arxiv.org/abs/2504.09604)
- [PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling (arXiv:2502.01925)](https://arxiv.org/abs/2502.01925)
- [Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models (arXiv:2408.04522)](https://arxiv.org/abs/2408.04522)
- [Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses (arXiv:2406.01288)](https://arxiv.org/abs/2406.01288)
- [Cognitive Overload Attack: Prompt Injection for Long Context (SAIL Lab)](https://sail-lab.org/cognitive-overload-attack-prompt-injection-for-long-context/)
- [LongSafety: Evaluating Long-Context Safety of Large Language Models (arXiv:2502.16971)](https://arxiv.org/abs/2502.16971)
- [Cognitive Overload Attack GitHub Repository (UNHSAILLab)](https://github.com/UNHSAILLab/cognitive-overload-attack)
- [Many-Shot Jailbreaking (PDF)](https://www-cdn.anthropic.com/af5633c94ed2beb282f6a53c595eb437e8e7b630/Many_Shot_Jailbreaking__2024_04_02_0936.pdf)
- [Illusions of Relevance: Using Content Injection Attacks to Deceive Retrievers, Rerankers, and LLM Judges (arXiv:2501.18536)](https://arxiv.org/abs/2501.18536)
- [Guide to Context in LLMs (Symbl.ai)](https://symbl.ai/developers/blog/guide-to-context-in-llms/)
- [Artifacts and Long Context Windows (Weights & Biases)](https://wandb.ai/wandb_ai/artifacts-and-long-context-windows)
