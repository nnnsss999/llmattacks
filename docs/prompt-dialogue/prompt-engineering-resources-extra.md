---
title: "Prompt Engineering Attack Resources Extra"
category: "Prompt Dialogue"
source_url: ""
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

The following references expand the catalog with additional credible writings and tools focused on prompt engineering attacks.

- [CyberSecEval 3 – Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models](https://ai.meta.com/research/publications/cyberseceval-3-advancing-the-evaluation-of-cybersecurity-risks-and-capabilities-in-large-language-models/)
- [Prompt Guard: Meta's Injection and Jailbreak Filter](https://ai.meta.com/blog/meta-llama-3-1-ai-responsibility/)
- [Llama Agentic System Reference Implementation](https://github.com/meta-llama/llama-agentic-system)
- [OpenAI Guide on Mitigating Prompt Injection](https://platform.openai.com/docs/guides/prompt-engineering/prompt-injection)
- [OpenAI Model Spec – Chain of Command Guidance](https://cdn.openai.com/spec/model-spec-2024-05-08.html)

These sources highlight advanced evaluation frameworks, mitigation tools, and best practice guidance that help defend against prompt engineering threats.
