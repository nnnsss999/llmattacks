---
title: "Prompt Engineering Attack Resources 2029"
category: "Prompt Dialogue"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The resources below expand on prompt engineering-based attacks and mitigation approaches. They complement [prompt-engineering-resources-2028.md](prompt-engineering-resources-2028.md).

- [DRIFT: Dynamic Rule-Based Defense with Injection Isolation for Securing LLM Agents](https://arxiv.org/abs/2506.12104)
- [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org/abs/2506.10020)
- [Sentinel: SOTA Model to Protect Against Prompt Injections](https://arxiv.org/abs/2506.05446)
- [Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering](https://arxiv.org/abs/2506.06384)
- [BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage](https://arxiv.org/abs/2506.02479)
- [ReGA: Representation-Guided Abstraction for Model-based Safeguarding of LLMs](https://arxiv.org/abs/2506.01770)
- [Enhancing Diffusion-based Unrestricted Adversarial Attacks via Adversary Preferences Alignment](https://arxiv.org/abs/2506.01511)
- [Jailbreak Distillation: Renewable Safety Benchmarking](https://arxiv.org/abs/2505.22037)
- [Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](https://arxiv.org/abs/2505.22852)
- [A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming](https://arxiv.org/abs/2505.24252)
