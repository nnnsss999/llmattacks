---
title: "Prompt Engineering Attack Resources 2031"
category: "Prompt Dialogue"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The resources below extend the catalog with new research papers and open-source tools focused on prompt injection and jailbreak techniques. They build upon [prompt-engineering-resources-2030.md](prompt-engineering-resources-2030.md).

- [Maatphor: Automated Variant Analysis for Prompt Injection Attacks](https://arxiv.org/abs/2312.11513)
- [Prompt Injection attack against LLM-integrated Applications](https://arxiv.org/abs/2306.05499)
- [Open-Prompt-Injection Toolkit for Attacks and Defenses](https://github.com/liu00222/Open-Prompt-Injection)
- [deepset Prompt Injection Dataset on Hugging Face](https://huggingface.co/datasets/deepset/prompt-injections)
- [Evaluating Prompt Injection Datasets](https://hiddenlayer.com/prompt-injection-datasets)
- [LLM Security Prompt Injection Project](https://github.com/sinanw/llm-security-prompt-injection)

These links highlight emerging methods for generating, detecting, and mitigating prompt-based attacks across real-world LLM deployments.
