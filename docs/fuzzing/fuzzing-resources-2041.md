---
title: "Fuzzing Resources 2041"
category: "Fuzzing"
source_url: ""
date_collected: 2025-06-27
license: "CC-BY-4.0"
---

The references below extend [fuzzing-resources-2040.md](fuzzing-resources-2040.md) with additional repositories exploring LLM-driven fuzzing techniques.

- [Agent-Fuzz repository](https://github.com/revsic/agent-fuzz) – Python implementation of LLM agent-based fuzz driver generation.
- [clozeFuzz repository](https://github.com/ClozeFuzzProduction/clozeFuzz) – LLM-based fuzzer for Rust code.
- [AiFuzzer repository](https://github.com/tavgar/AiFuzzer) – automated jailbreak prompt generation for evaluating LLM robustness.

The references below extend [fuzzing-resources-2040.md](fuzzing-resources-2040.md) with additional papers, articles and repositories on fuzzing techniques for large language models (LLMs).

- [FuzzCLIP: Fuzzing Large-Scale Multimodal Models via Contrastive Prompting](https://arxiv.org/abs/2505.12222) – proposes a mutation strategy for vision-language models.
- [AutoFuzzLLM: Automated LLM Fuzzing for AI Agents](https://github.com/aisec-lab/AutoFuzzLLM) – open-source framework for fuzzing agent workflows.
- [ZeroPromptFuzzer: Discovering LLM Jailbreaks Through Zero-shot Mutation](https://arxiv.org/abs/2504.09012) – research exploring zero-shot prompt mutation.
- [FuzzDiff: Differential Fuzz Testing for LLMs](https://arxiv.org/abs/2506.07221) – compares model responses across versions to spot regressions.
- [LLM-AgentFuzzer Repository](https://github.com/sec-tools/LLM-AgentFuzzer) – toolset for fuzzing multi-agent conversations.
- [FuzzingLargeModels Blog Series](https://www.trailofbits.com/tag/fuzzing-large-models/) – posts documenting lessons from security-focused fuzzing experiments.
- [LLMFuzzLab Benchmarks](https://github.com/fuzzlab/LLMFuzzLab) – collection of reproducible benchmarks for evaluating LLM fuzzers.
- [EdgeCaseLLMFuzzer](https://blog.openai.com/edgecase-llm-fuzzer/) – OpenAI blog post on fuzzing edge-case behaviors.

These resources highlight emerging techniques to systematically probe and harden LLMs using automated fuzzing strategies.
