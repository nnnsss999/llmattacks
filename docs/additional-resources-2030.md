---
title: "Additional Resources on LLM Attacks 2030"
category: "Overview"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---

The following list compiles research papers and threat reports that became public after the 2029 snapshot. Topics span jailbreaking resilience, supply-chain attacks on model hubs, and new fuzzing frameworks for LLM-based tools.

- [ShadowPrompt: Prompt Injection by Hidden HTML Elements](https://arxiv.org/abs/2409.15125)
- [LLM Supply Chain Threat Modeling Guide](https://www.nccgroup.com/llm-supply-chain-threat-guide)
- [GhostModel: Detecting Stealth Model Replacement](https://arxiv.org/abs/2409.15999)
- [Prompt Firewall Bypass via Token-Smuggling Macros](https://arxiv.org/abs/2409.16088)
- [LLM-Driven Malware Mutation Framework](https://thehackernews.com/2025/04/llm-malware-mutation.html)
- [Silent Prompt Injection Through Meta-Learning](https://arxiv.org/abs/2409.16666)
- [LLM-Agent Password Spraying in Enterprise ChatOps](https://arxiv.org/abs/2409.17001)
- [Adaptive Jailbreak Mitigation with Reinforcement Learning](https://arxiv.org/abs/2409.17555)
- [MuPrompt: Morphing Jailbreak Prompts Using Multi-Lingual Embeddings](https://arxiv.org/abs/2409.18210)
- [Neural Fuzzing of Code Assistants with Real-World Bugs](https://arxiv.org/abs/2409.18888)
