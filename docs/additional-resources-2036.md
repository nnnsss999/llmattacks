---
title: "Additional Resources on LLM Attacks 2036"
category: "Overview"
source_url: ""
date_collected: 2025-06-24
license: "CC-BY-4.0"
---
The references below highlight newly discovered research papers, blog posts, and reports that surfaced after the 2035 snapshot.

- [Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs](http://arxiv.org/abs/2505.14368v1)
- [Goal-Oriented Prompt Attack and Safety Evaluation for LLMs](http://arxiv.org/abs/2309.11830v2)
- [Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks](http://arxiv.org/abs/2412.05830v1)
- [System Prompt Extraction Attacks and Defenses in Large Language Models](http://arxiv.org/abs/2505.23817v1)
- [Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs](http://arxiv.org/abs/2406.09324v3)
- [New TokenBreak Attack Bypasses AI Moderation with Single-Character Text](https://thehackernews.com/2025/06/new-tokenbreak-attack-bypasses-ai.html)
- [LLM01:2025 Prompt Injection - OWASP Gen AI Security Project](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
- [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [OWASP Top 10 LLM, Updated 2025: Examples & Mitigation Strategies](https://www.oligo.security/academy/owasp-top-10-llm-updated-2025-examples-and-mitigation-strategies)
- [OWASP Top 10 2025 for LLM Applications: What's new? Risks, and Mitigation Techniques](https://www.confident-ai.com/blog/owasp-top-10-2025-for-llm-applications-risks-and-mitigation-techniques)
- [2025 Top 10 Risk & Mitigations for LLMs and Gen AI Apps](https://genai.owasp.org/llm-top-10/)
- [OWASP Top 10 for LLM Applications 2025: Data and Model Poisoning](https://www.checkpoint.com/cyber-hub/what-is-llm-security/data-and-model-poisoning/)
- [OWASP LLM10: 2025 Unbounded Consumption](https://genai.owasp.org/llmrisk/llm102025-unbounded-consumption/)
- [Breaking Down OWASP Top 10 LLM 2025](https://medium.com/@appsecwarrior/breaking-down-owasp-top-10-llm-2025-cd99ed46761b)
- [LLM Vulnerability Lets Attackers Exploit ChatGPT-Like Models](https://cybersecuritynews.com/new-llm-vulnerability/)
- [Deep Dive into OWASP LLM Top 10 and Prompt Injection](https://www.paulmduvall.com/deep-dive-into-owasp-llm-top-10-and-prompt-injection/)
- [New ITU Research Analyses Attacks on Large Language Models](https://en.itu.dk/About-ITU/Press/News-from-ITU/2025/New-ITU-research-analyses-attacks-on-Large-Language-Models)
- [LLM01:2025 Prompt Injection: Risks & Mitigation](https://www.indusface.com/learning/prompt-injection/)
- [Understanding Web LLM Attacks](https://www.securityium.com/understanding-web-llm-attacks/)
- [The New Attack Surface: A Penetration Tester's Guide to Securing LLMs](https://www.subrosacyber.com/en/blog/a-penetration-testers-guide-to-securing-llms)
- [LLM Security Playbook for AI Injection Attacks, Data Leaks and Model Theft](https://konghq.com/blog/enterprise/llm-security-playbook-for-injection-attacks-data-leaks-model-theft)
- [Quantifying the AI Security Risk: 2025 Breach Statistics and Financial Implications](https://www.metomic.io/resource-centre/quantifying-the-ai-security-risk-2025-breach-statistics-and-financial-implications)
- [GitHub - llm-attacks/llm-attacks: Universal and Transferable Attacks on Aligned Models](https://github.com/llm-attacks/llm-attacks)
- [A Note on LLM Prompt Injection Attacks](https://blog.gopenai.com/a-note-on-llm-prompt-injection-attacks-d4f5fb3964c0)
- [LLM Red Teaming: A Playbook for Stress-Testing Your LLM Stack](https://hacken.io/discover/ai-red-teaming/)
- [Practical Attacks on LLMs: Full Guide](https://iterasec.com/blog/practical-attacks-on-llms/)
- [RAS-Eval: A Comprehensive Benchmark for Security Evaluation](http://arxiv.org/pdf/2506.15253)
- [I Know What You Asked: Prompt Leakage via KV-Cache Sharing in Multi-Tenant LLM Serving](https://www.ndss-symposium.org/ndss-paper/i-know-what-you-asked-prompt-leakage-via-kv-cache-sharing-in-multi-tenant-llm-serving/)
- [Apple's New 'LLM Siri' Won't Arrive Until 2026, Despite AI Race Pressure](http://www.msn.com/en-us/news/technology/apples-new-llm-siri-wont-arrive-until-2026-despite-ai-race-pressure/ar-AA1uNOwn)
- [Universal and Transferable Attacks on Aligned Language Models](https://llm-attacks.org/)
- [Traditional Fake News Detection Fails Against AI-Generated Content](https://www.computerweekly.com/news/366626276/Traditional-fake-news-detection-fails-against-AI-generated-content)
- [How Hackers Are Gaining Access to AI Large Language Models](https://www.infosecurityeurope.com/en-gb/blog/threat-vectors/how-to-hack-large-language-models.html)
