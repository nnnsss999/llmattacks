---
title: "Mechanism-Centric Data Poisoning for LLMs"
category: "Training"
source_url: "https://arxiv.org/html/2502.14182v1"
date_collected: 2025-06-18
license: "Fair Use"
---

This arXiv study surveys methods for corrupting training data used by large language models. It covers clean-label and dirty-label attacks, poisoning retrieval corpora, and the challenges of detecting tampered examples at scale.
