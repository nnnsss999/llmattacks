---
title: "Visual Jailbreaking Resources 2037"
category: "Multimodal"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

This page extends [visual-jailbreaking-resources-2036.md](visual-jailbreaking-resources-2036.md) with more references on image-driven jailbreak attacks and defences. The papers and articles below highlight ongoing research into multimodal exploits.

- [Visual Adversarial Examples Jailbreak Aligned Large Language Models](https://dl.acm.org/doi/10.1609/aaai.v38i19.30150) – AAAI paper detailing how crafted images bypass alignment mechanisms.
- [JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models](https://ieeexplore.ieee.org/document/11020711) – IEEE Xplore article examining jailbreak behaviours using visualization tools.
- [Bohrium DP-Tech mirror of Visual Adversarial Examples Jailbreak Aligned LLMs](https://bohrium.dp.tech/paper/arxiv/2306.13213) – alternative host for the original arXiv paper.
