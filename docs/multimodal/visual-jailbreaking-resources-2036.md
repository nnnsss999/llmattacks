---
title: "Visual Jailbreaking Resources 2036"
category: "Multimodal"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below extend [visual-jailbreaking-resources-2035.md](visual-jailbreaking-resources-2035.md) with additional research on visual and multimodal jailbreak techniques published after mid-2035.

- [VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration](https://arxiv.org/abs/2505.20362) – proposes a benchmark for calibrating LVLM defences. [GitHub](https://github.com/jiahuigeng/VSCBench)
- [Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs](https://arxiv.org/abs/2505.11842) – dataset and tooling for measuring video-based jailbreak success. [Homepage](https://liuxuannan.github.io/Video-SafetyBench.github.io/)
- [Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model](https://arxiv.org/abs/2505.06538) – explores robustness gaps and mitigation strategies. [GitHub](https://github.com/xinyuelou/Think-in-Safety)
- [SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models](https://arxiv.org/abs/2504.08813) – documents alignment failures in LVLM reasoning chains. [GitHub](https://github.com/fangjf1/OpenSafeMLRM)
- [TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis](https://arxiv.org/abs/2505.08804)
- [Inception: Jailbreak the Memory Mechanism of Text-to-Image Generation Systems](https://arxiv.org/abs/2504.20376)
- [Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models](https://arxiv.org/abs/2504.11106)
- [Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking](https://arxiv.org/abs/2504.05838)
- [Unified Prompt Attack Against Text-to-Image Generation Models](https://arxiv.org/abs/2502.16423)
- [T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation](https://arxiv.org/abs/2501.12612)
- [CogMorph: Cognitive Morphing Attacks for Text-to-Image Models](https://arxiv.org/abs/2501.11815)
- [FameBias: Embedding Manipulation Bias Attack in Text-to-Image Models](https://arxiv.org/abs/2412.18302)
