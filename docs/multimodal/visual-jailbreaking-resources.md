---
title: "Visual Jailbreaking Resources"
category: "Multimodal"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The following papers and repositories provide additional detail on multimodal and visual jailbreaking attacks. These references expand on the techniques mentioned in the catalog and illustrate how images or other media can subvert content filters in modern MLLMs.

- [Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character](https://arxiv.org/abs/2405.20773)
- [Jailbreaking Attack against Multimodal Large Language Model](https://arxiv.org/abs/2402.02309)
- [White-box Multimodal Jailbreaks Against Large Vision-Language Models](https://openreview.net/forum?id=SMOUQtEaAf)
- [Align is not Enough: Multimodal Universal Jailbreak Attack against Multimodal Large Language Models](https://arxiv.org/html/2506.01307v1)
- [Vision-fused Jailbreak: A Multi-modal Collaborative Jailbreak Attack](https://practical-dl.github.io/2024/short_paper/13/CameraReady/13.pdf)
- [Visual Role-Play Jailbreak â€“ LLM Security Database](https://www.promptfoo.dev/lm-security-db/vuln/undefined-55c7b700)
- [Awesome-Multimodal-Jailbreak Repository](https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak)
- [Awesome-LVLM-Attack Repository](https://github.com/liudaizong/Awesome-LVLM-Attack)
- [Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models](https://openreview.net/forum?id=plmBsXHxgR)
