---
title: "Visual Jailbreaking Resources 2031"
category: "Multimodal"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below extend [visual-jailbreaking-resources-2028.md](visual-jailbreaking-resources-2028.md) with papers and articles published after the 2028 snapshot. They highlight ongoing work exploring image-based and multimodal jailbreak vectors against large language models.

- [JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks](https://www.semanticscholar.org/paper/f019c9661b253ddb611e930348e20ddcd350a952)
- [Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast](https://www.semanticscholar.org/paper/b0ada492ba48e85016cbbfd95ec7180fb7e79648)
- [Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey](https://www.semanticscholar.org/paper/233c605cc547d69299fcf4737aee51e0dfeb4652)
- [UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models](https://www.semanticscholar.org/paper/62474020cdd6d106fa0d32c10335bc91e4d713c5)
- [Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection](https://www.semanticscholar.org/paper/763cf8a095ef039c99cdcfc654132169443c56ee)
- [VPI-Bench: Visual Prompt Injection Attacks for Computer-Use Agents](https://www.semanticscholar.org/paper/038bedad2baed0fe87f69b3deeb98559a63c4d45)
- [Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors](https://www.semanticscholar.org/paper/f41109b24c24ecccf26cda9ceacad9167d197028)
- [Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs](https://www.semanticscholar.org/paper/06435fa07e7e2063fb898c2ef017857c4c6bea65)
- [Adversarial Robustness for Visual Grounding of Multimodal Large Language Models](https://www.semanticscholar.org/paper/51ed81d2a394ae395eb22285a7c57c03ae34f558)
- [Exploring Visual Vulnerabilities via Multi-Loss Adversarial Search for Jailbreaking Vision-Language Models](https://www.semanticscholar.org/paper/6d242c538893f35e35855190db96103a2b22d521)
- [Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models](https://www.semanticscholar.org/paper/2c030ad4be327dc3447e23ad68c303714c55cf14)
- [JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large Language and Vision-Language Models](https://www.semanticscholar.org/paper/027ac1dad95fa9f42c5e9d00a4de31214f437604)
- [Misusing Tools in Large Language Models With Visual Adversarial Examples](https://www.semanticscholar.org/paper/ac5b4df0e398ca48388330ac5c795b6fe708793c)

