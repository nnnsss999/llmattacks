---
title: "Visual Jailbreaking Resources 2034"
category: "Multimodal"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The following papers showcase recent research on multimodal and vision-based jailbreak attacks and defenses published after the 2033 snapshot. They explore new methods for constructing or mitigating image-driven prompts.

- [T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models](https://arxiv.org/abs/2504.15512)
- [Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks](https://arxiv.org/abs/2504.01308)
- [REVAL: A Comprehension Evaluation on Reliability and Values of Large Vision-Language Models](https://arxiv.org/abs/2503.16566)
- [Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense](https://arxiv.org/abs/2503.11619)
- [TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models](https://arxiv.org/abs/2503.10872)
- [FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts](https://arxiv.org/abs/2502.21059)
- [Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers Exhibit Greater Sensitivity to Harmful Content](https://arxiv.org/abs/2502.20952)
- [Distraction is All You Need for Multimodal Large Language Model Jailbreaking](https://arxiv.org/abs/2502.10794)
- [Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models](https://arxiv.org/abs/2502.01576)
- [Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org/abs/2501.13772)
