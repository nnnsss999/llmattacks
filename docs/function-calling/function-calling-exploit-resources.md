---
title: "Function Calling Exploit Resources"
category: "Insecure Output"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

These links highlight research on compromising LLMs via malicious or coerced function calls.

- [The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models](https://arxiv.org/html/2407.17915v3)
- [jailbreakfunction GitHub Repository](https://github.com/wooozihui/jailbreakfunction)
- [Securing Function Calls in LLMs: Unveiling and Mitigating Jailbreak Vulnerabilities](https://www.marktechpost.com/2024/08/08/securing-function-calls-in-llms-unveiling-and-mitigating-jailbreak-vulnerabilities/)
- [The Dark Side of Function Calling in Large Language Models](https://medium.com/@has.dhia/the-dark-side-of-function-calling-in-large-language-models-ca089b994aa4)
- [Web LLM Attacks | Web Security Academy](https://portswigger.net/web-security/llm-attacks)
