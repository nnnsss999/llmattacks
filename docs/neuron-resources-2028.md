---
title: "Neuron-Level Manipulation Resources 2028"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below extend the catalog with new research on editing and analyzing individual neurons in large language models. They supplement [neuron-resources-2027.md](neuron-resources-2027.md).

## Research Papers

- [Neuron to Graph: Interpreting Language Model Neurons at Scale](https://arxiv.org/abs/2305.19911) – automatically translates neuron activations into interpretable graphs.
- [Universal Neurons in GPT2 Language Models](https://arxiv.org/abs/2401.12181) – identifies neurons consistent across random seeds.
- [Repetition Neurons: How Do Language Models Produce Repetitions?](https://arxiv.org/abs/2410.13497) – isolates neurons responsible for repeated output loops.
- [On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons](https://arxiv.org/abs/2404.02431) – reveals language-specific neurons and demonstrates how to control them.
- [Compositional Explanations of Neurons](https://arxiv.org/abs/2006.14032) – outlines a procedure to craft logical concepts for neurons, enabling targeted adversarial inputs.
- [Precise Localization of Memories: A Fine-grained Neuron-level Knowledge Editing Technique for LLMs](https://arxiv.org/abs/2503.01090) – proposes methods to precisely locate and edit memory neurons.
- [Exploring the Neural Landscape: Visual Analytics of Neuron Activation](https://www.sciencedirect.com/science/article/pii/S1524070324000262) – introduces interactive tools to analyze neuron activations.
- [Human-like Object Concept Representations Emerge Naturally in Transformers](https://www.nature.com/articles/s42256-025-01049-z) – uses cognitive methods to analyze concept neurons.

## Tools and Code

- [zepingyu0512/awesome-LLM-neuron](https://github.com/zepingyu0512/awesome-LLM-neuron) – curated repository collecting neuron-level analyses and editing resources.
