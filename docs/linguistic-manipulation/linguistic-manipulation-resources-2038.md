---
title: "Linguistic Manipulation Resources 2038"
category: "Linguistic Manipulation"
source_url: ""
date_collected: 2025-06-28
license: "CC-BY-4.0"
---

The references below catalog recent research papers and articles on advanced paraphrase-based or cross-lingual jailbreak techniques published after the 2037 snapshot.

- [How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States](https://aclanthology.org/2024.findings-emnlp.139/) – analyzes safety failures using hidden state inspection.
- [Diversity Helps Jailbreak Large Language Models](https://openreview.net/forum?id=yI60yhMQ7L) – shows that linguistic variety increases jailbreak success rates.
- [NEMESIS \ Jailbreaking LLMs with Chain of Thoughts Approach](https://openreview.net/forum?id=5kMwiMnUip) – exploits chain-of-thought prompts to bypass safeguards.
- [A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos](https://arxiv.org/abs/2502.15806) – iterative paraphrases escalate reasoning attacks.
- [h4rm3l: A Language for Composable Jailbreak Attack Synthesis](https://iclr.cc/virtual/2025/poster/27663) – proposes a formal language to combine linguistic attack primitives.
- [ICLR 2025: Understanding Adversarial LLM Jailbreaks and Their Mitigation](https://textify.ai/iclr-2025-understanding-adversarial-llm-jailbreaks-and-their-mitigation/) – summary of novel jailbreak tricks and defences.
- [Protecting LLMs from Jailbreaks](https://cacm.acm.org/news/protecting-llms-from-jailbreaks/) – article in CACM reviewing current mitigations.
- [Cato Networks Discovers New LLM Jailbreak Technique](https://securitymea.com/2025/03/27/cato-networks-discovers-new-llm-jailbreak-technique/) – reports on cross-language evasion observed in the wild.
- [OWASP Gen AI Incident & Exploit Round-up, Jan-Feb 2025](https://genai.owasp.org/2025/03/06/owasp-gen-ai-incident-exploit-round-up-jan-feb-2025/) – documents early jailbreak incidents and countermeasures.
- [Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis](https://arxiv.org/abs/2410.13237) – quantifies confusion-based jailbreak pathways across languages.
