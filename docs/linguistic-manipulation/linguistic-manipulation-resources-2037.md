---
title: "Linguistic Manipulation Resources 2037"
category: "Linguistic Manipulation"
source_url: ""
date_collected: 2025-06-27
license: "CC-BY-4.0"
---

The references below cover recent research and articles on paraphrase-based and cross-lingual jailbreak strategies published after the 2036 snapshot.

- [LLMs have a multilingual jailbreak problem – how you can stay safe](https://www.sdxcentral.com/analysis/llms-have-a-multilingual-jailbreak-problem-how-you-can-stay-safe/) – article discussing cross-language threats and mitigation advice.
- [Homoglyph-Based Attacks: Circumventing LLM Detectors](https://ndc-security.com/agenda/homoglyph-based-attacks-circumventing-llm-detectors-08hy/0oxqj7xqhx5) – conference talk on using look-alike characters to hide malicious prompts.
- [Cognitive Overload: Jailbreaking Large Language Models with Overloaded Prompts](https://arxiv.org/abs/2311.09827) – shows how extremely long or complex requests degrade safeguards.
- [Cognitive Overload Attack: Prompt Injection for Long Context](https://sail-lab.org/cognitive-overload-attack-prompt-injection-for-long-context/) – demonstrates overwhelming models with verbose text.
- [LLM Guardrail / Jailbreak Detection Evasion](https://arxiv.org/abs/2504.11168) – explores methods to bypass text-based jailbreak detectors.
- [Attacking LLM Watermarks by Exploiting Their Strengths](https://arxiv.org/abs/2402.16187) – manipulates output style to defeat watermark protections.
- [B4: A Black-Box Scrubbing Attack on LLM Watermarks](https://aclanthology.org/2025.naacl-long.460/) – algorithmically removes watermark tokens from generated text.
- [Large Language Model Watermark Stealing With Mixed Integer Programming](https://paperswithcode.com/paper/large-language-model-watermark-stealing-with) – demonstrates watermark extraction via optimization.
- [Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs](https://aclanthology.org/2024.trustnlp-1.18/) – crafts mixed-language prompts that transfer across models.
