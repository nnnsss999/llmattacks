---
title: "Linguistic Manipulation Resources 2031"
category: "Linguistic Manipulation"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below capture additional research on multilingual and paraphrase-based jailbreak methods released after the 2030 snapshot.

- [A Multilingual Exploration of Jailbreak Attacks in Large Language Models](https://openreview.net/forum?id=NaFtZu3c5f)
- [Jailbreak Attacks on Large Language Models and Possible Defenses](https://ieeexplore.ieee.org/abstract/document/10732418)
- [Distract Large Language Models for Automatic Jailbreak Attack](https://arxiv.org/abs/2403.08424)
- [Enhancing LLM Character-Level Manipulation via Divide and Conquer](https://arxiv.org/abs/2502.08180)
- [Jailbreak Open-Sourced Large Language Models via Enforced Decoding](http://faculty.ist.psu.edu/wu/papers/jailbreak-LLM.pdf)
- [Making Them Ask and Answer: Jailbreaking Large Language Models](https://www.usenix.org/system/files/usenixsecurity24-liu-tong.pdf)
- [Understanding Jailbreak Attacks in Large Language Models: A New Taxonomy](https://quantumzeitgeist.com/understanding-jailbreak-attacks-in-large-language-models/)
- [Tongue-Tied: Breaking LLMs Safety Through New Language Learning](https://aclanthology.org/2025.calcs-1.5.pdf)
- [Towards Understanding the Fragility of Multilingual LLMs against Fine-Grained Jailbreaks](https://aclanthology.org/2025.findings-naacl.126.pdf)
- [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Attacks](https://arxiv.org/abs/2505.04806)
- [One Model Transfer to All: On Robust Jailbreak Prompts Generation](https://openreview.net/forum?id=sULAwlAWc1)
- [AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio LLMs](https://arxiv.org/abs/2505.14103)
