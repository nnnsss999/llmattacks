---
title: "Linguistic Manipulation Resources 2027"
category: "Linguistic Manipulation"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below extend the catalog with additional papers and articles on multilingual and paraphrase-based jailbreak methods published after the initial snapshot.

- [Don't Say No: Jailbreaking LLM by Suppressing Refusal](https://arxiv.org/abs/2404.16369)
- [Mission Impossible: A Statistical Perspective on Jailbreaking LLMs](http://arxiv.org/abs/2408.01420)
- [Hacc-Man: An Arcade Game for Jailbreaking LLMs](https://doi.org/10.1145/3656156.3665432)
- [COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability](http://arxiv.org/abs/2402.08679)
- [Jailbreaking LLM-Controlled Robots](http://arxiv.org/abs/2410.13691)
- [Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation](https://arxiv.org/abs/2405.13068)

