---
title: "Linguistic Manipulation Resources 2029"
category: "Linguistic Manipulation"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The references below provide additional research and articles on linguistic manipulation and crossâ€‘lingual jailbreak techniques published after the 2028 snapshot.

- [Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study](https://arxiv.org/abs/2305.13860)
- [Text Embedding Inversion Attacks on Multilingual Language Models](https://arxiv.org/abs/2401.12192)
- [LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization](https://arxiv.org/pdf/2505.16008)
- [Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks](https://arxiv.org/abs/2408.11749)
- [Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character](https://arxiv.org/abs/2405.20773)
- [Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models](https://aclanthology.org/2024.findings-emnlp.803)
- [GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts](https://arxiv.org/abs/2309.10253)
- [From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking](https://arxiv.org/pdf/2406.14859)
- [Linguistic Manipulation and Jailbreak Prompts Discovery](https://www.semanticscholar.org/paper/2c4d2d889a1f0ff9598de829a001df11a95d3294)
- [WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response](https://aclanthology.org/2025.findings-naacl.269)
