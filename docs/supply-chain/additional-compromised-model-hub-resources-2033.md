---
title: "Additional Compromised Model Hub Resources 2033"
category: "Supply Chain"
date_collected: 2025-07-03
license: "CC-BY-4.0"
---

The sources below provide new research and guidance on attacks targeting model hubs and mitigating supply-chain risks.

- [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://arxiv.org/abs/2505.01067) – arXiv
- [The ML Supply Chain in the Era of Software 2.0: Lessons Learned from Hugging Face](https://arxiv.org/abs/2502.04484) – arXiv
- [Models Are Codes: Towards Measuring Malicious Code Poisoning Attacks on Pre-trained Model Hubs](https://arxiv.org/abs/2409.09368) – arXiv
- [Adversarial Robustness of Open-source Text Classification Models and Fine-Tuning Chains](https://arxiv.org/abs/2408.02963) – arXiv
- [Signing in Four Public Software Package Registries: Quantity, Quality, and Influencing Factors](https://arxiv.org/abs/2401.14635) – arXiv
- [NIST AI 100-5: Guidelines for Secure AI System Development](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-5.pdf) – NIST
