---
title: "Context Window Resources 2031"
category: "Inference"
source_url: ""
date_collected: 2025-06-20
license: "CC-BY-4.0"
---

Additional credible references on context-window attacks and related research:

- [LongNet: Scaling Transformers to 1,000,000,000 Tokens (arXiv:2307.02486)](https://arxiv.org/abs/2307.02486)
- [Hyena Hierarchy: Towards Larger Convolutional Language Models (arXiv:2302.10866)](https://arxiv.org/abs/2302.10866)
- [Retentive Network: A Successor to Transformer for Large Language Models (arXiv:2307.08621)](https://arxiv.org/abs/2307.08621)
- [Scale AI Blog: Long Context LLMs in Production](https://scale.com/blog/long-context-llms)
- [Cloudflare Learning: Context Window Attacks Explained](https://www.cloudflare.com/learning/security/threats/context-window-attacks/)
- [Anthropic Blog: Hydra â€” Mitigating LLM Jailbreaks](https://www.anthropic.com/newsroom/blog-posts/hydra-mitigating-llm-jailbreaks?context-window)
- [Long Range Arena: A Benchmark for Efficient Transformers (arXiv:2011.04006)](https://arxiv.org/abs/2011.04006)
