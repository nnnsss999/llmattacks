---
title: "Malware Generation Using Jailbroken LLMs"
category: "Inference"
source_url: "https://thehackernews.com/2023/07/wormgpt-hackers-gpt.html"
date_collected: 2025-06-18
license: "Fair Use"
---

Threat actors increasingly rely on specialized language models that lack safety constraints to generate malicious code and phishing content. Underground tools such as **WormGPT** and **FraudGPT** build on open-source checkpoints to produce convincing emails, macros and even complete malware payloads. Researchers warn that iterative prompting lets attackers craft polymorphic code that can evade signature-based detection.

Referenced articles detail how cybercriminal forums advertise these models as a replacement for ChatGPT's restricted interface. They demonstrate the ability to assemble remote access trojans and social engineering lures with minimal effort.
