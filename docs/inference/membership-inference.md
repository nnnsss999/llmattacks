---
title: "Membership Inference Attacks on Large-Scale Models: A Survey"
category: "Inference"
source_url: "https://arxiv.org/abs/2503.19338"
date_collected: 2025-06-18
license: "Fair Use"
---

The 2025 survey of membership inference attacks on large language models reviews how adversaries can determine if a specific text was used to train a model. Attackers analyze outputs or internal gradients to measure confidence changes, enabling privacy leaks even from public APIs. The paper also covers defenses like differential privacy and suggests better fine-tuning hygiene.
