---
title: "Context Window Resources 2028"
category: "Inference"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The following articles and papers expand on known context-window attacks and related vulnerabilities in long-context language models.

- [Do Enormous LLM Context Windows Spell the End of RAG? (The New Stack)](https://thenewstack.io/do-enormous-llm-context-windows-spell-the-end-of-rag/)
- [Scaling to Millions of Tokens with Efficient Long-Context LLM Training (NVIDIA Technical Blog)](https://developer.nvidia.com/blog/scaling-to-millions-of-tokens-with-efficient-long-context-llm-training/)
- [LLM Context Windows: Why They Matter and 5 Solutions for Context Limits (Kolena Blog)](https://www.kolena.com/blog/llm-context-windows)
- [LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (arXiv:2402.13753)](https://arxiv.org/abs/2402.13753)
- [Reasoning Degradation in LLMs with Long Context Windows (OpenAI Community)](https://community.openai.com/t/reasoning-degradation-in-llms-with-long-context-windows-new-benchmarks/551368)
