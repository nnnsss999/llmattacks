---
title: "Neuron-Level Manipulation Resources 2039"
category: "Latent Space"
source_url: ""
date_collected: 2025-06-24
license: "CC-BY-4.0"
---

This update extends the neuron-level bibliography with research and tooling published after the 2038 update. The references track emerging methods for editing and defending neurons in large language models.

## Research Papers

- [Does Large Language Model Contain Task-Specific Neurons?](https://aclanthology.org/2024.emnlp-main.403/) – analyses specialized neurons associated with downstream tasks.
- [Learnable Privacy Neurons Localization in Language Models](https://arxiv.org/abs/2405.10989) – proposes a method to detect and modify privacy neurons.
- [Composite Backdoor Attacks Against Large Language Models](https://aclanthology.org/2024.findings-naacl.94/) – demonstrates multi-trigger backdoors at the neuron level.
- [Multi-Turn Hidden Backdoor in Large Language Model-powered Chatbot](https://doi.org/10.1145/3634737.3656289?utm_source=chatgpt.com) – implants hidden triggers that persist across conversations.
- [BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks and Defenses on Large Language Models](https://github.com/bboylyg/BackdoorLLM) – curated dataset and tools for evaluating neuron-level backdoors.
- [Cross-Lingual Knowledge Editing in Large Language Models](https://aclanthology.org/2024.acl-long.627/) – explores targeted neuron edits across languages.
- [How to Use and Interpret Activation Patching](https://arxiv.org/abs/2404.15255) – provides guidance on large-scale neuron patching.
- [Advanced Interpretability Techniques for Tracing LLM Activations](https://dejan.ai/blog/advanced-interpretability-techniques-for-tracing-llm-activations/) – article detailing practical analysis of neuron activations.

## Tools and Code

- [BackdoorLLM Benchmark](https://github.com/bboylyg/BackdoorLLM) – open-source benchmark for testing neuron-level backdoors.
- [Composite Backdoor Attacks (CBA)](https://github.com/MiracleHH/CBA) – code for inserting composite backdoors in LLMs.
- [Awesome LLM Understanding Mechanism](https://github.com/zepingyu0512/awesome-llm-understanding-mechanism) – repository collecting papers and code on neuron analysis.
