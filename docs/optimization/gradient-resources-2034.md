---
title: "Gradient Attack Resources 2034"
category: "Optimization"
source_url: ""
date_collected: 2025-06-26
license: "CC-BY-4.0"
---

The references below catalog additional gradient-based jailbreak attacks and defenses published after the 2033 list.

- [Fast Projected Gradient Jailbreak | LLM Security Database](https://www.promptfoo.dev/lm-security-db/vuln/fast-projected-gradient-jailbreak-ef10d346) – quick projected-gradient iterations generate adversarial suffixes that evade safety filters.
- [Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models](https://arxiv.org/abs/2503.06269) – introduces **subspace rerouting** to guide gradient updates along interpretable directions.
- [Gradient Subspace Tracking Poster (Adaptive Foundation Models 2024)](https://adaptive-foundation-models.org/posters/Gradient_Subspace_Tracking_AFM_2024_Poster.pdf) – demonstrates tracking gradient subspaces for effective jailbreak optimization.
- [Robust LLM Defenses: Unpacking Gradient Analysis for Enhanced Jailbreak Detection](https://medium.com/aim-intelligence/robust-llm-defenses-unpacking-gradient-analysis-for-enhanced-jailbreak-detection-2b9319bd3609) – blog exploring gradient-inspection techniques to harden models.
- [How to Protect LLMs from Jailbreaking Attacks](https://www.boozallen.com/insights/ai-research/how-to-protect-llms-from-jailbreaking-attacks.html) – overview highlighting Greedy Coordinate Gradient attacks and mitigation strategies.
- [Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States](https://arxiv.org/abs/2503.09066) – analyzes gradient directions that reveal adversarial behaviors.
- [Temporally Sparse Attack for Fooling Large Language Models in Time Series Forecasting](https://openreview.net/forum?id=wEvAJFYXXN) – temporally sparse gradient attacks targeting forecasting models.

