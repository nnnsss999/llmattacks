---
title: "Gradient-based Adversarial Attacks Against Text Transformers"
category: "Optimization"
source_url: "https://blogs.night-wolf.io/gradient-based-adversarial-attacks-against-text-transformers"
date_collected: 2025-06-18
license: "Fair Use"
---
This technical blog post introduces a general-purpose gradient-based attack targeting transformer language models. Instead of searching for a single adversarial example, the authors optimize over a continuous matrix to learn a distribution of perturbations. Sampling from this distribution yields high-success jailbreak prompts in both white-box and black-box settings, rivaling state-of-the-art attacks with only hard-label feedback.
