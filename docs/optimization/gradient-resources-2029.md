---
title: "Gradient Attack Resources 2029"
category: "Optimization"
source_url: ""
date_collected: 2025-06-19
license: "CC-BY-4.0"
---

The papers below extend the gradient-based jailbreak collection with new research appearing after the 2028 snapshot.

- [Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models](https://arxiv.org/abs/2411.07559) – introduces a query-efficient multi-modal attack that optimizes gradients while minimizing memory footprint.
- [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2504.20570) – shows how gradients reveal private training data during LoRA fine-tuning.
- [FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model](https://arxiv.org/abs/2506.05640) – proposes gradient-sanitization defenses against leakage in federated settings.
- [SHE-LoRA: Selective Homomorphic Encryption for Federated Tuning with Heterogeneous LoRA](https://arxiv.org/abs/2505.21051) – uses encrypted gradient updates to protect distributed LoRA fine-tuning.
- [Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage](https://arxiv.org/abs/2505.20026) – describes a stronger inversion attack recovering text from leaked gradients.
