<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/images/arrow_left.svg"/><link rel="preload" as="image" href="/images/pdf_icon_blue.svg"/><link rel="stylesheet" href="/_next/static/css/623ec4d945fb0950.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1777a0996b88c8c1.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1dad14d11404e245.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7e1ff74241679440.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/8dc164557bded312.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-700efc7a3fe218fa.js"/><script src="/_next/static/chunks/4bd1b696-674b1201a1d63716.js" async=""></script><script src="/_next/static/chunks/1684-f2e76e08982cc2da.js" async=""></script><script src="/_next/static/chunks/main-app-895d0017b454980b.js" async=""></script><script src="/_next/static/chunks/e37a0b60-86dcf540460bd9a6.js" async=""></script><script src="/_next/static/chunks/7ce798d6-3eb8122476a3f2e5.js" async=""></script><script src="/_next/static/chunks/6874-8f3d6c72a87c2225.js" async=""></script><script src="/_next/static/chunks/3697-c0092b2c69fd8d8c.js" async=""></script><script src="/_next/static/chunks/590-a7095dbf68fad767.js" async=""></script><script src="/_next/static/chunks/4540-1380528b77b77034.js" async=""></script><script src="/_next/static/chunks/8780-219cd1efe9e9c581.js" async=""></script><script src="/_next/static/chunks/5226-3f9b6d1f505acbb7.js" async=""></script><script src="/_next/static/chunks/8533-b514bce0a35f7ac6.js" async=""></script><script src="/_next/static/chunks/9433-a9a98e8d4788630c.js" async=""></script><script src="/_next/static/chunks/app/layout-16592c7bbd62e480.js" async=""></script><script src="/_next/static/chunks/6325-93a1b42c84bba41c.js" async=""></script><script src="/_next/static/chunks/7153-99554ef3ddb80cbe.js" async=""></script><script src="/_next/static/chunks/2308-5ba70fcab32074d1.js" async=""></script><script src="/_next/static/chunks/424-bf9f8c3b9c338050.js" async=""></script><script src="/_next/static/chunks/2064-620cbcc98eda7280.js" async=""></script><script src="/_next/static/chunks/4281-defa8559eb9a8986.js" async=""></script><script src="/_next/static/chunks/9911-76bc1f1d480a89fe.js" async=""></script><script src="/_next/static/chunks/2882-66622e31b0f52a02.js" async=""></script><script src="/_next/static/chunks/4745-960031cc83ae4c6c.js" async=""></script><script src="/_next/static/chunks/5262-9b0df618c3a5e5de.js" async=""></script><script src="/_next/static/chunks/4438-1e3980f50c842bfd.js" async=""></script><script src="/_next/static/chunks/app/forum/page-259d5f29b9409771.js" async=""></script><script src="/_next/static/chunks/app/error-e8e38cde74148468.js" async=""></script><script src="/_next/static/chunks/app/global-error-437204fce1f23329.js" async=""></script><link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js" as="script"/><link rel="preload" href="https://challenges.cloudflare.com/turnstile/v0/api.js" as="script"/><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-GTB25PBMVL" as="script"/><meta name="next-size-adjust" content=""/><link rel="icon" href="/favicon.ico"/><link rel="manifest" href="/manifest.json"/><title>AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs | OpenReview</title><meta name="description" content="\begin{center} \textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\end{center}
As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\citep{zou2023universal} proposes a discrete tokens optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.
Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. 
More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\% ASR on the latest GPT-3.5.
To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend."/><meta name="citation_title" content="AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs"/><meta name="citation_author" content="Zeyi Liao"/><meta name="citation_author" content="Huan Sun"/><meta name="citation_online_date" content="2024/08/26"/><meta name="citation_pdf_url" content="https://openreview.net/pdf?id=UfqzXg95I5"/><meta name="citation_abstract" content="\begin{center} \textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\end{center}
As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\citep{zou2023universal} proposes a discrete tokens optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.
Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. 
More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\% ASR on the latest GPT-3.5.
To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend."/><meta name="citation_conference_title" content="First Conference on Language Modeling"/><meta property="og:title" content="AmpleGCG: Learning a Universal and Transferable Generative Model of..."/><meta property="og:description" content="\begin{center} \textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\end{center}
As large language models (LLMs) become increasingly prevalent and integrated into..."/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="AmpleGCG: Learning a Universal and Transferable Generative Model of..."/><meta name="twitter:description" content="\begin{center} \textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\end{center}
As large language models (LLMs) become increasingly prevalent and integrated into..."/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_086c6e"><div id="__next"><nav class="navbar navbar-inverse" role="navigation"><div class="container"><div class="navbar-header"><button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a></div><div id="navbar" class="navbar-collapse collapse"><form class="navbar-form navbar-left profile-search" role="search"><div class="form-group has-feedback"><input type="text" class="form-control" placeholder="Search OpenReview..." autoComplete="off" autoCorrect="off" name="term" value=""/><span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span></div><input type="hidden" name="group" value="all"/><input type="hidden" name="content" value="all"/><input type="hidden" name="source" value="all"/></form><ul class="nav navbar-nav navbar-right"><li id="user-menu"><a href="/login">Login</a></li></ul></div></div></nav><div id="flash-message-container" class="alert alert-danger fixed-overlay" role="alert" style="display:none"><div class="container"><div class="row"><div class="col-xs-12"><div class="alert-content"><button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button></div></div></div></div></div><script>(self.__next_s=self.__next_s||[]).push(["https://challenges.cloudflare.com/turnstile/v0/api.js",{}])</script><div id="or-banner" class="banner"><div class="container"><div class="row"><div class="col-xs-12"><a title="Venue Homepage" href="/group?id=colmweb.org/COLM/2024/Conference"><img class="icon" src="/images/arrow_left.svg" alt="back arrow"/>Go to <strong>COLM 2024 Conference</strong> <!-- -->homepage</a></div></div></div></div><div class="container"><div class="row"><main id="content"><div class="Forum_forum__wS8Fw"><div class="forum-container"><div class="forum-note"><div class="forum-title mt-2 mb-2"><h2 class="citation_title">AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs</h2><div class="forum-content-link"><a class="citation_pdf_url" href="/pdf?id=UfqzXg95I5" title="Download PDF" target="_blank" rel="noreferrer"><img src="/images/pdf_icon_blue.svg" alt="Download PDF"/></a></div></div><div class="forum-authors mb-2"><h3><span><a title="~Zeyi_Liao1" data-toggle="tooltip" data-placement="top" href="/profile?id=~Zeyi_Liao1">Zeyi Liao</a>, <a title="~Huan_Sun1" data-toggle="tooltip" data-placement="top" href="/profile?id=~Huan_Sun1">Huan Sun</a> <!-- --> </span></h3></div><div class="clearfix mb-1"><div class="forum-meta"><span class="date item"><span class="glyphicon glyphicon-calendar " aria-hidden="true"></span>Published: 10 Jul 2024, Last Modified: 26 Aug 2024</span><span class="item"><span class="glyphicon glyphicon-folder-open " aria-hidden="true"></span>COLM</span><span class="readers item" data-toggle="tooltip" data-placement="top" title="Visible to &lt;br/&gt;everyone&lt;br/&gt;since 26 Aug 2024"><span class="glyphicon glyphicon-eye-open " aria-hidden="true"></span>Everyone</span><span class="item"><span class="glyphicon glyphicon-duplicate " aria-hidden="true"></span><a href="/revisions?id=UfqzXg95I5">Revisions</a></span><span class="item"><span class="glyphicon glyphicon-bookmark " aria-hidden="true"></span><a href="#" data-target="#bibtex-modal" data-toggle="modal" data-bibtex="%40inproceedings%7B%0Aliao2024amplegcg%2C%0Atitle%3D%7BAmple%7BGCG%7D%3A%20Learning%20a%20Universal%20and%20Transferable%20Generative%20Model%20of%20Adversarial%20Suffixes%20for%20Jailbreaking%20Both%20Open%20and%20Closed%20%7BLLM%7Ds%7D%2C%0Aauthor%3D%7BZeyi%20Liao%20and%20Huan%20Sun%7D%2C%0Abooktitle%3D%7BFirst%20Conference%20on%20Language%20Modeling%7D%2C%0Ayear%3D%7B2024%7D%2C%0Aurl%3D%7Bhttps%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DUfqzXg95I5%7D%0A%7D">BibTeX</a></span><span class="item"><span class="glyphicon glyphicon-copyright-mark " aria-hidden="true"></span><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" title="Licensed under Creative Commons Attribution 4.0 International" data-toggle="tooltip" data-placement="top">CC BY 4.0</a></span></div><div class="invitation-buttons"></div></div><div class="note-content"><div><strong class="note-content-field disable-tex-rendering">Research Area<!-- -->:</strong> <span class="note-content-value">Safety</span></div><div><strong class="note-content-field disable-tex-rendering">Keywords<!-- -->:</strong> <span class="note-content-value">Large Language Models, Jailbreak Attack, Adversarial Attack</span></div><div><strong class="note-content-field disable-tex-rendering">TL;DR<!-- -->:</strong> <span class="note-content-value">We propose a universal adversarial suffix generator to generate many customized suffixes for any harmful queries in seconds and achieve near 100% ASR on aligned LLMs. it could also transfers to different LLMs and bypass perplexity detector.</span></div><div><strong class="note-content-field disable-tex-rendering">Abstract<!-- -->:</strong> <span class="note-content-value">\begin{center} \textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\end{center}
As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\citep{zou2023universal} proposes a discrete tokens optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.
Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. 
More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\% ASR on the latest GPT-3.5.
To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend.</span></div><div><strong class="note-content-field disable-tex-rendering">Supplementary Material<!-- -->:</strong> <span class="note-content-value"><a href="/attachment?id=UfqzXg95I5&amp;name=supplementary_material" class="attachment-download-link" title="Download Supplementary Material" target="_blank"><span class="glyphicon glyphicon-download-alt " aria-hidden="true"></span> <!-- -->zip</a></span></div><div><strong class="note-content-field disable-tex-rendering">Code Of Ethics<!-- -->:</strong> <span class="note-content-value">I acknowledge that I and all co-authors of this work have read and commit to adhering to the COLM Code of Ethics on https://colmweb.org/CoE.html</span></div><div><strong class="note-content-field disable-tex-rendering">Author Guide<!-- -->:</strong> <span class="note-content-value">I certify that this submission complies with the submission instructions as described on https://colmweb.org/AuthorGuide.html</span></div><div><strong class="note-content-field disable-tex-rendering">Flagged For Ethics Review<!-- -->:</strong> <span class="note-content-value">true</span></div><div><strong class="note-content-field disable-tex-rendering">Ethics Comments<!-- -->:</strong> <span class="note-content-value">The techniques can be used to extract responses from the LLM that can cause societal harm in the form of offensive language, encouraging unsafe behavior, etc. The authors have acknowledged these concerns.

The creation and dissemination of a tool capable of efficiently generating adversarial attacks on LLMs could be considered ethically questionable, as it may aid malicious actors.</span></div><div><strong class="note-content-field disable-tex-rendering">Submission Number<!-- -->:</strong> <span class="note-content-value">527</span></div></div></div><div class="row forum-replies-container layout-default"><div class="col-xs-12"><div id="forum-replies"><div class="spinner-container spinner-inline"><div class="spinner undefined"><div class="rect1"></div><div class="rect2"></div><div class="rect3"></div><div class="rect4"></div><div class="rect5"></div></div><span>Loading</span></div></div></div></div></div></div></main></div></div><footer class="sitemap"><div class="container"><div class="row hidden-xs"><div class="col-sm-4"><ul class="list-unstyled"><li><a href="/about">About OpenReview</a></li><li><a href="/group?id=OpenReview.net/Support">Hosting a Venue</a></li><li><a href="/venues">All Venues</a></li></ul></div><div class="col-sm-4"><ul class="list-unstyled"><li><a href="/contact">Contact</a></li><li><a>Feedback</a></li><li><a href="/sponsors">Sponsors</a></li><li><a class="join-the-team" href="https://codeforscience.org/jobs?job=OpenReview-Developer" target="_blank" rel="noopener noreferrer"><strong>Join the Team</strong></a></li></ul></div><div class="col-sm-4"><ul class="list-unstyled"><li><a href="https://docs.openreview.net/getting-started/frequently-asked-questions">Frequently Asked Questions</a></li><li><a href="/legal/terms">Terms of Use</a></li><li><a href="/legal/privacy">Privacy Policy</a></li></ul></div></div><div class="row visible-xs-block"><div class="col-xs-6"><ul class="list-unstyled"><li><a href="/about">About OpenReview</a></li><li><a href="/group?id=OpenReview.net/Support">Hosting a Venue</a></li><li><a href="/venues">All Venues</a></li><li><a href="/sponsors">Sponsors</a></li><li><a class="join-the-team" href="https://codeforscience.org/jobs?job=OpenReview-Developer" target="_blank" rel="noopener noreferrer"><strong>Join the Team</strong></a></li></ul></div><div class="col-xs-6"><ul class="list-unstyled"><li><a href="https://docs.openreview.net/getting-started/frequently-asked-questions">Frequently Asked Questions</a></li><li><a href="/contact">Contact</a></li><li><a>Feedback</a></li><li><a href="/legal/terms">Terms of Use</a></li><li><a href="/legal/privacy">Privacy Policy</a></li></ul></div></div></div></footer><footer class="sponsor"><div class="container"><div class="row"><div class="col-sm-10 col-sm-offset-1"><p class="text-center"><a href="/about" target="_blank">OpenReview</a> <!-- -->is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the<!-- --> <a href="/sponsors" target="_blank">OpenReview Sponsors</a>. © <!-- -->2025<!-- --> OpenReview</p></div></div></div></footer></div><script src="/_next/static/chunks/webpack-700efc7a3fe218fa.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[64818,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"3740\",\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"8780\",\"static/chunks/8780-219cd1efe9e9c581.js\",\"5226\",\"static/chunks/5226-3f9b6d1f505acbb7.js\",\"8533\",\"static/chunks/8533-b514bce0a35f7ac6.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"7177\",\"static/chunks/app/layout-16592c7bbd62e480.js\"],\"default\"]\n3:I[6874,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"2308\",\"static/chunks/2308-5ba70fcab32074d1.js\",\"424\",\"static/chunks/424-bf9f8c3b9c338050.js\",\"2064\",\"static/chunks/2064-620cbcc98eda7280.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"2882\",\"static/chunks/2882-66622e31b0f52a02.js\",\"4745\",\"static/chunks/4745-960031cc83ae4c6c.js\",\"5262\",\"static/chunks/5262-9b0df618c3a5e5de.js\",\"4438\",\"static/chunks/4438-1e3980f50c842bfd.js\",\"5300\",\"static/chunks/app/forum/page-259d5f29b9409771.js\"],\"\"]\n4:I[41316,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"3740\",\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"8780\",\"static/chunks/8780-219cd1efe9e9c581.js\",\"5226\",\"static/chunks/5226-3f9b6d1f505acbb7.js\",\"8533\",\"static/chunks/8533-b514bce0a35f7ac6.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"7177\",\"static/chunks/app/layout-16592c7bbd62e480.js\"],\"default\"]\n6:I[46967,[\""])</script><script>self.__next_f.push([1,"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"3740\",\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"8780\",\"static/chunks/8780-219cd1efe9e9c581.js\",\"5226\",\"static/chunks/5226-3f9b6d1f505acbb7.js\",\"8533\",\"static/chunks/8533-b514bce0a35f7ac6.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"7177\",\"static/chunks/app/layout-16592c7bbd62e480.js\"],\"default\"]\n7:I[87555,[],\"\"]\n8:I[31702,[\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"8039\",\"static/chunks/app/error-e8e38cde74148468.js\"],\"default\"]\n9:I[31295,[],\"\"]\na:I[64757,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"2308\",\"static/chunks/2308-5ba70fcab32074d1.js\",\"424\",\"static/chunks/424-bf9f8c3b9c338050.js\",\"2064\",\"static/chunks/2064-620cbcc98eda7280.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"2882\",\"static/chunks/2882-66622e31b0f52a02.js\",\"4745\",\"static/chunks/4745-960031cc83ae4c6c.js\",\"5262\",\"static/chunks/5262-9b0df618c3a5e5de.js\",\"4438\",\"static/chunks/4438-1e3980f50c842bfd.js\",\"5300\",\"static/chunks/app/forum/page-259d5f29b9409771.js\"],\"default\"]\nb:I[69243,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.j"])</script><script>self.__next_f.push([1,"s\",\"3740\",\"static/chunks/7ce798d6-3eb8122476a3f2e5.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"8780\",\"static/chunks/8780-219cd1efe9e9c581.js\",\"5226\",\"static/chunks/5226-3f9b6d1f505acbb7.js\",\"8533\",\"static/chunks/8533-b514bce0a35f7ac6.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"7177\",\"static/chunks/app/layout-16592c7bbd62e480.js\"],\"\"]\nd:I[59665,[],\"OutletBoundary\"]\n10:I[59665,[],\"ViewportBoundary\"]\n12:I[59665,[],\"MetadataBoundary\"]\n14:I[89340,[\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"4219\",\"static/chunks/app/global-error-437204fce1f23329.js\"],\"default\"]\n:HL[\"/_next/static/media/08f4947ad4536ee1-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/c4250770ab8708b6-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/623ec4d945fb0950.css\",\"style\"]\n:HL[\"/_next/static/css/1777a0996b88c8c1.css\",\"style\"]\n:HL[\"/_next/static/css/1dad14d11404e245.css\",\"style\"]\n:HL[\"/_next/static/css/7e1ff74241679440.css\",\"style\"]\n:HL[\"/_next/static/css/8dc164557bded312.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"v1.14.1\",\"p\":\"\",\"c\":[\"\",\"forum?id=UfqzXg95I5\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"forum\",{\"children\":[\"__PAGE__?{\\\"id\\\":\\\"UfqzXg95I5\\\"}\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/623ec4d945fb0950.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1777a0996b88c8c1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1dad14d11404e245.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7e1ff74241679440.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",null,{\"rel\":\"manifest\",\"href\":\"/manifest.json\"}]]}],[\"$\",\"$L2\",null,{\"children\":[\"$\",\"body\",null,{\"className\":\"__className_086c6e\",\"children\":[\"$\",\"div\",null,{\"id\":\"__next\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"navbar navbar-inverse\",\"role\":\"navigation\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"div\",null,{\"className\":\"navbar-header\",\"children\":[[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"navbar-toggle collapsed\",\"data-toggle\":\"collapse\",\"data-target\":\"#navbar\",\"aria-expanded\":\"false\",\"aria-controls\":\"navbar\",\"children\":[[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Toggle navigation\"}],[\"$\",\"span\",null,{\"className\":\"icon-bar\"}],[\"$\",\"span\",null,{\"className\":\"icon-bar\"}],[\"$\",\"span\",null,{\"className\":\"icon-bar\"}]]}],[\"$\",\"$L3\",null,{\"href\":\"/\",\"className\":\"navbar-brand home push-link\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"OpenReview\"}],\".net\"]}]]}],[\"$\",\"div\",null,{\"id\":\"navbar\",\"className\":\"navbar-collapse collapse\",\"children\":[[\"$\",\"$L4\",null,{}],\"$L5\"]}]]}]}],[\"$\",\"div\",null,{\"id\":\"flash-message-container\",\"className\":\"alert alert-danger fixed-overlay\",\"role\":\"alert\",\"style\":{\"display\":\"none\"},\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[\"$\",\"div\",null,{\"className\":\"row\",\"children\":[\"$\",\"div\",null,{\"className\":\"col-xs-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"alert-content\",\"children\":[\"$\",\"button\",null,{\"type\":\"button\",\"className\":\"close\",\"aria-label\":\"Close\",\"children\":[\"$\",\"span\",null,{\"aria-hidden\":\"true\",\"children\":\"×\"}]}]}]}]}]}]}],[\"$\",\"$L6\",null,{}],[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$8\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"$La\",null,{\"statusCode\":404,\"message\":\"Please check that the URL is spelled correctly and try again.\"}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]}]}],[[\"$\",\"$Lb\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-GTB25PBMVL\"}],[\"$\",\"$Lb\",null,{\"id\":\"ga-script\",\"dangerouslySetInnerHTML\":{\"__html\":\"window.dataLayer = window.dataLayer || [];\\nfunction gtag() { dataLayer.push(arguments); }\\ngtag('js', new Date());\\ngtag('config', 'G-GTB25PBMVL', {\\npage_location: location.origin + location.pathname + location.search,\\n});\"}}]]]}]]}],{\"children\":[\"forum\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",\"$undefined\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8dc164557bded312.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",\"$Lf\",null]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"tFZWtXG761lbHMsi4wCSL\",{\"children\":[[\"$\",\"$L10\",null,{\"children\":\"$L11\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$L12\",null,{\"children\":\"$L13\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$14\",[]],\"s\":false,\"S\":false}\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"ul\",null,{\"className\":\"nav navbar-nav navbar-right\",\"children\":[\"$\",\"li\",null,{\"id\":\"user-menu\",\"children\":[\"$\",\"$L3\",null,{\"href\":\"/login\",\"children\":\"Login\"}]}]}]\n11:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"15:I[39677,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"2308\",\"static/chunks/2308-5ba70fcab32074d1.js\",\"424\",\"static/chunks/424-bf9f8c3b9c338050.js\",\"2064\",\"static/chunks/2064-620cbcc98eda7280.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"2882\",\"static/chunks/2882-66622e31b0f52a02.js\",\"4745\",\"static/chunks/4745-960031cc83ae4c6c.js\",\"5262\",\"static/chunks/5262-9b0df618c3a5e5de.js\",\"4438\",\"static/chunks/4438-1e3980f50c842bfd.js\",\"5300\",\"static/chunks/app/forum/page-259d5f29b9409771.js\"],\"default\"]\n16:I[73775,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"2308\",\"static/chunks/2308-5ba70fcab32074d1.js\",\"424\",\"static/chunks/424-bf9f8c3b9c338050.js\",\"2064\",\"static/chunks/2064-620cbcc98eda7280.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"2882\",\"static/chunks/2882-66622e31b0f52a02.js\",\"4745\",\"static/chunks/4745-960031cc83ae4c6c.js\",\"5262\",\"static/chunks/5262-9b0df618c3a5e5de.js\",\"4438\",\"static/chunks/4438-1e3980f50c842bfd.js\",\"5300\",\"static/chunks/app/forum/page-259d5f29b9409771.js\"],\"default\"]\n18:I[32587,[\"4935\",\"static/chunks/e37a0b60-86dcf540460bd9a6.js\",\"6874\",\"static/chunks/6874-8f3d6c72a87c2225.js\",\"3697\",\"static/chunks/3697-c0092b2c69fd8d8c.js\",\"590\",\"static/chunks/590-a7095dbf68fad767.js\",\"6325\",\"static/chunks/6325-93a1b42c84bba41c.js"])</script><script>self.__next_f.push([1,"\",\"4540\",\"static/chunks/4540-1380528b77b77034.js\",\"7153\",\"static/chunks/7153-99554ef3ddb80cbe.js\",\"2308\",\"static/chunks/2308-5ba70fcab32074d1.js\",\"424\",\"static/chunks/424-bf9f8c3b9c338050.js\",\"2064\",\"static/chunks/2064-620cbcc98eda7280.js\",\"9433\",\"static/chunks/9433-a9a98e8d4788630c.js\",\"4281\",\"static/chunks/4281-defa8559eb9a8986.js\",\"9911\",\"static/chunks/9911-76bc1f1d480a89fe.js\",\"2882\",\"static/chunks/2882-66622e31b0f52a02.js\",\"4745\",\"static/chunks/4745-960031cc83ae4c6c.js\",\"5262\",\"static/chunks/5262-9b0df618c3a5e5de.js\",\"4438\",\"static/chunks/4438-1e3980f50c842bfd.js\",\"5300\",\"static/chunks/app/forum/page-259d5f29b9409771.js\"],\"default\"]\n17:T669,\\begin{center} \\textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\\end{center}\nAs large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\\citep{zou2023universal} proposes a discrete tokens optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.\nMoreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. \nMore interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\\% ASR on the latest GPT-3.5.\nTo summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes th"])</script><script>self.__next_f.push([1,"at is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend."])</script><script>self.__next_f.push([1,"c:[[\"$\",\"$L15\",null,{\"banner\":[\"$\",\"div\",null,{\"id\":\"or-banner\",\"className\":\"banner\",\"style\":null,\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[\"$\",\"div\",null,{\"className\":\"row\",\"children\":[\"$\",\"div\",null,{\"className\":\"col-xs-12\",\"children\":[\"$\",\"$L3\",null,{\"href\":\"/group?id=colmweb.org/COLM/2024/Conference\",\"title\":\"Venue Homepage\",\"children\":[[\"$\",\"img\",null,{\"className\":\"icon\",\"src\":\"/images/arrow_left.svg\",\"alt\":\"back arrow\"}],\"Go to \",[\"$\",\"strong\",null,{\"children\":\"COLM 2024 Conference\"}],\" \",\"homepage\"]}]}]}]}]}]}],\"$undefined\",[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[\"$\",\"div\",null,{\"className\":\"row\",\"children\":[\"$\",\"main\",null,{\"id\":\"content\",\"children\":[\"$\",\"div\",null,{\"className\":\"Forum_forum__wS8Fw\",\"children\":[\"$\",\"$L16\",null,{\"forumNote\":{\"content\":{\"title\":{\"value\":\"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\"},\"authors\":{\"value\":[\"Zeyi Liao\",\"Huan Sun\"]},\"authorids\":{\"value\":[\"~Zeyi_Liao1\",\"~Huan_Sun1\"]},\"research_area\":{\"value\":[\"Safety\"]},\"keywords\":{\"value\":\"Large Language Models, Jailbreak Attack, Adversarial Attack\"},\"TLDR\":{\"value\":\"We propose a universal adversarial suffix generator to generate many customized suffixes for any harmful queries in seconds and achieve near 100% ASR on aligned LLMs. it could also transfers to different LLMs and bypass perplexity detector.\"},\"abstract\":{\"value\":\"$17\"},\"code_of_ethics\":{\"value\":[\"I acknowledge that I and all co-authors of this work have read and commit to adhering to the COLM Code of Ethics on https://colmweb.org/CoE.html\"]},\"author_guide\":{\"value\":[\"I certify that this submission complies with the submission instructions as described on https://colmweb.org/AuthorGuide.html\"]},\"supplementary_material\":{\"value\":\"/attachment/68774d39c0c9ecd4fead9def8cc25d1458150a77.zip\"},\"venue\":{\"value\":\"COLM\"},\"venueid\":{\"value\":\"colmweb.org/COLM/2024/Conference\"},\"pdf\":{\"value\":\"/pdf/e48267cdfef6dab8f8c574c95f0cbb60dd10db28.pdf\"},\"flagged_for_ethics_review\":{\"value\":true},\"ethics_comments\":{\"value\":\"The techniques can be used to extract responses from the LLM that can cause societal harm in the form of offensive language, encouraging unsafe behavior, etc. The authors have acknowledged these concerns.\\n\\nThe creation and dissemination of a tool capable of efficiently generating adversarial attacks on LLMs could be considered ethically questionable, as it may aid malicious actors.\\n\\n\"},\"_bibtex\":{\"value\":\"@inproceedings{\\nliao2024amplegcg,\\ntitle={Ample{GCG}: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed {LLM}s},\\nauthor={Zeyi Liao and Huan Sun},\\nbooktitle={First Conference on Language Modeling},\\nyear={2024},\\nurl={https://openreview.net/forum?id=UfqzXg95I5}\\n}\"},\"paperhash\":{\"value\":\"liao|amplegcg_learning_a_universal_and_transferable_generative_model_of_adversarial_suffixes_for_jailbreaking_both_open_and_closed_llms\"}},\"id\":\"UfqzXg95I5\",\"forum\":\"UfqzXg95I5\",\"license\":\"CC BY 4.0\",\"signatures\":[\"colmweb.org/COLM/2024/Conference/Submission527/Authors\"],\"readers\":[\"everyone\"],\"writers\":[\"colmweb.org/COLM/2024/Conference\",\"colmweb.org/COLM/2024/Conference/Submission527/Authors\"],\"number\":527,\"invitations\":[\"colmweb.org/COLM/2024/Conference/-/Submission\",\"colmweb.org/COLM/2024/Conference/-/Post_Submission\",\"colmweb.org/COLM/2024/Conference/Submission527/-/Revision\",\"colmweb.org/COLM/2024/Conference/-/Ethics_Review_Flag\",\"colmweb.org/COLM/2024/Conference/-/Edit\",\"colmweb.org/COLM/2024/Conference/Submission527/-/Camera_Ready\"],\"domain\":\"colmweb.org/COLM/2024/Conference\",\"tcdate\":1711069853625,\"cdate\":1711069853625,\"tmdate\":1724633533278,\"mdate\":1724633533278,\"pdate\":1720608911625,\"odate\":1724633533264,\"version\":2,\"details\":{\"writable\":false,\"presentation\":[{\"name\":\"title\",\"order\":1,\"type\":\"string\"},{\"name\":\"authors\",\"order\":3},{\"name\":\"authorids\",\"order\":4},{\"name\":\"research_area\",\"order\":4,\"type\":\"string[]\",\"input\":\"checkbox\",\"value\":[\"Safety\"],\"description\":[null]},{\"name\":\"keywords\",\"order\":5,\"type\":\"string\"},{\"name\":\"TLDR\",\"order\":6,\"type\":\"string\",\"fieldName\":\"TL;DR\"},{\"name\":\"abstract\",\"order\":7,\"type\":\"string\",\"input\":\"textarea\",\"markdown\":true},{\"name\":\"pdf\",\"order\":8,\"type\":\"file\"},{\"name\":\"supplementary_material\",\"order\":9,\"type\":\"file\"},{\"name\":\"code_of_ethics\",\"order\":10,\"type\":\"string[]\",\"input\":\"checkbox\",\"value\":[\"I acknowledge that I and all co-authors of this work have read and commit to adhering to the COLM Code of Ethics on https://colmweb.org/CoE.html\"],\"description\":[null]},{\"name\":\"author_guide\",\"order\":11,\"type\":\"string[]\",\"input\":\"checkbox\",\"value\":[\"I certify that this submission complies with the submission instructions as described on https://colmweb.org/AuthorGuide.html\"],\"description\":[null]},{\"name\":\"venue\",\"hidden\":true},{\"name\":\"venueid\",\"hidden\":true},{\"name\":\"_bibtex\",\"type\":\"string\",\"input\":\"textarea\"},{\"name\":\"flagged_for_ethics_review\",\"type\":\"boolean\",\"input\":\"radio\",\"value\":true,\"description\":null},{\"name\":\"ethics_comments\",\"type\":\"string\",\"input\":\"textarea\",\"markdown\":true}]},\"apiVersion\":2},\"selectedNoteId\":\"$undefined\",\"selectedInvitationId\":\"$undefined\",\"prefilledValues\":{},\"query\":{\"id\":\"UfqzXg95I5\"}}]}]}]}]}],[[\"$\",\"footer\",null,{\"className\":\"sitemap\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[[\"$\",\"div\",null,{\"className\":\"row hidden-xs\",\"children\":[[\"$\",\"div\",null,{\"className\":\"col-sm-4\",\"children\":[\"$\",\"ul\",null,{\"className\":\"list-unstyled\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/about\",\"children\":\"About OpenReview\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/group?id=OpenReview.net/Support\",\"children\":\"Hosting a Venue\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/venues\",\"children\":\"All Venues\"}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"col-sm-4\",\"children\":[\"$\",\"ul\",null,{\"className\":\"list-unstyled\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/contact\",\"children\":\"Contact\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L18\",null,{}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/sponsors\",\"children\":\"Sponsors\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"className\":\"join-the-team\",\"href\":\"https://codeforscience.org/jobs?job=OpenReview-Developer\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Join the Team\"}]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"col-sm-4\",\"children\":[\"$\",\"ul\",null,{\"className\":\"list-unstyled\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://docs.openreview.net/getting-started/frequently-asked-questions\",\"children\":\"Frequently Asked Questions\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/legal/terms\",\"children\":\"Terms of Use\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/legal/privacy\",\"children\":\"Privacy Policy\"}]}]]}]}]]}],[\"$\",\"div\",null,{\"className\":\"row visible-xs-block\",\"children\":[[\"$\",\"div\",null,{\"className\":\"col-xs-6\",\"children\":[\"$\",\"ul\",null,{\"className\":\"list-unstyled\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/about\",\"children\":\"About OpenReview\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/group?id=OpenReview.net/Support\",\"children\":\"Hosting a Venue\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/venues\",\"children\":\"All Venues\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/sponsors\",\"children\":\"Sponsors\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"className\":\"join-the-team\",\"href\":\"https://codeforscience.org/jobs?job=OpenReview-Developer\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Join the Team\"}]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"col-xs-6\",\"children\":[\"$\",\"ul\",null,{\"className\":\"list-unstyled\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://docs.openreview.net/getting-started/frequently-asked-questions\",\"children\":\"Frequently Asked Questions\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/contact\",\"children\":\"Contact\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L18\",null,{\"modalId\":\"feedback-modal-mobile\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/legal/terms\",\"children\":\"Terms of Use\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L3\",null,{\"href\":\"/legal/privacy\",\"children\":\"Privacy Policy\"}]}]]}]}]]}]]}]}],[\"$\",\"footer\",null,{\"className\":\"sponsor\",\"children\":[\"$\",\"div\",null,{\"className\":\"container\",\"children\":[\"$\",\"div\",null,{\"className\":\"row\",\"children\":[\"$\",\"div\",null,{\"className\":\"col-sm-10 col-sm-offset-1\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/about\",\"target\":\"_blank\",\"children\":\"OpenReview\"}],\" \",\"is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the\",\" \",[\"$\",\"a\",null,{\"href\":\"/sponsors\",\"target\":\"_blank\",\"children\":\"OpenReview Sponsors\"}],\". © \",2025,\" OpenReview\"]}]}]}]}]}]]]\n"])</script><script>self.__next_f.push([1,"f:null\n19:T669,\\begin{center} \\textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\\end{center}\nAs large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\\citep{zou2023universal} proposes a discrete tokens optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.\nMoreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. \nMore interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\\% ASR on the latest GPT-3.5.\nTo summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend.1a:T669,\\begin{center} \\textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\\end{center}\nAs large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\\citep{zou2023universal} proposes a discrete tokens optimizatio"])</script><script>self.__next_f.push([1,"n algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.\nMoreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. \nMore interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\\% ASR on the latest GPT-3.5.\nTo summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. Impressively, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend.13:[[\"$\",\"title\",\"0\",{\"children\":\"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs | OpenReview\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$19\"}],[\"$\",\"meta\",\"2\",{\"name\":\"citation_title\",\"content\":\"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\"}],[\"$\",\"meta\",\"3\",{\"name\":\"citation_author\",\"content\":\"Zeyi Liao\"}],[\"$\",\"meta\",\"4\",{\"name\":\"citation_author\",\"content\":\"Huan Sun\"}],[\"$\",\"meta\",\"5\",{\"name\":\"citation_online_date\",\"content\":\"2024/08/26\"}],[\"$\",\"meta\",\"6\",{\"name\":\"citation_pdf_url\",\"content\":\"https://openreview.net/pdf?id=UfqzXg95I5\"}],[\"$\",\"meta\",\"7\",{\"name\":\"citation_abstract\",\"content\":\"$1a\"}],[\"$"])</script><script>self.__next_f.push([1,"\",\"meta\",\"8\",{\"name\":\"citation_conference_title\",\"content\":\"First Conference on Language Modeling\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:title\",\"content\":\"AmpleGCG: Learning a Universal and Transferable Generative Model of...\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:description\",\"content\":\"\\\\begin{center} \\\\textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\\\\end{center}\\nAs large language models (LLMs) become increasingly prevalent and integrated into...\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"AmpleGCG: Learning a Universal and Transferable Generative Model of...\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"\\\\begin{center} \\\\textcolor{red}{Warning: This paper contains potentially offensive and harmful text.}\\\\end{center}\\nAs large language models (LLMs) become increasingly prevalent and integrated into...\"}]]\n"])</script></body></html>
