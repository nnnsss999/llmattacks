---
title: "Evolutionary Algorithm Jailbreak Resources"
category: "Optimization"
source_url: ""
date_collected: 2025-06-18
license: "CC-BY-4.0"
---

The references below catalog evolutionary and genetic algorithm approaches for jailbreaking large language models (LLMs). These resources demonstrate how evolutionary search can generate adversarial prompts that evade alignment controls.

- [Open Sesame: Universal Black Box Jailbreaking with Genetic Algorithms](https://arxiv.org/abs/2309.01446) – proposes an iterative genetic algorithm that evolves prompts to maximize harmful responses across models.
- [LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models](https://arxiv.org/abs/2501.00055) – integrates evolutionary search with gradient feedback to craft universal jailbreaks.
- [Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts](https://arxiv.org/abs/2406.05321) – evolves paraphrased prompts that achieve higher success rates while retaining semantics.
- [AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models](https://arxiv.org/abs/2310.04451) – combines mutation operations with gradient guidance to create stealthy jailbreaks.
- [LLM_EA](https://github.com/xiaofangxd/LLM_EA) – open-source implementation of evolutionary algorithms for automated LLM jailbreaks.
- [A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models](https://aclanthology.org/2024.findings-acl.443/) – survey analyzing jailbreak strategies including evolutionary search methods.

