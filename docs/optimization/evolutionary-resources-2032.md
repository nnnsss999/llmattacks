---
title: "Evolutionary Algorithm Resources 2032"
category: "Optimization"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---

The references below expand the catalog with further coverage of evolutionary and genetic algorithm approaches for jailbreaking large language models (LLMs) and related defenses.

- [GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts](https://arxiv.org/abs/2309.10253) – introduces a fuzzing framework that mutates seed prompts similar to genetic algorithms to systematically discover jailbreaks.
- [MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots](https://arxiv.org/abs/2307.08715) – evolves prompts that transfer across different LLM chatbots.
- [Improved Techniques for Optimization-Based Jailbreaking on Large Language Models](https://arxiv.org/abs/2405.21018) – refines gradient and evolutionary search strategies for automated attacks.
- [AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens](https://arxiv.org/abs/2406.03805) – analyzes evolutionary-style prompt mutation across dependency chains.
- [Learn to Disguise: Avoid Refusal Responses in LLM’s Defense via a Multi-Agent Attacker-Disguiser Game](https://arxiv.org/abs/2404.02532) – applies multi-agent optimization that iteratively disguises prompts.
- [Maatphor: Automated Variant Analysis for Prompt Injection Attacks](https://arxiv.org/abs/2312.11513) – performs large-scale mutation analysis of jailbreak prompts.
- [Cross-Modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models](https://arxiv.org/abs/2407.21659) – proposes detection techniques targeting evolved multimodal jailbreaks.
- [Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation](https://arxiv.org/abs/2310.06987) – demonstrates iterative attacks that adapt prompts through search.
- [LAGO: Few-shot Cross-Lingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization](https://arxiv.org/abs/2505.16008) – explores optimization-based jailbreaks with graph search.
- [Exploring the Impact of LLM Assisted Malware Variants on Anti-Virus Detection](https://doi.org/10.1109/dsc63325.2024.00027) – evaluates the security implications of evolutionary malware generated with LLM help.
- [From LLMs to MLLMs: Exploring Multi-modal Jailbreak Attacks via the Contribution of Visual Features](https://arxiv.org/abs/2406.14859) – shows how evolutionary search can adapt multimodal prompts.
- [An LLM-Empowered Adaptive Evolutionary Algorithm for Multi-Component Deep Learning Systems](https://doi.org/10.1609/aaai.v39i19.34303) – discusses evolutionary optimization with LLM guidance, relevant for advanced jailbreak tactics.
