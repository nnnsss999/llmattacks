---
title: "Evolutionary Algorithm Resources 2032"
category: "Optimization"
source_url: ""
date_collected: 2025-06-23
license: "CC-BY-4.0"
---

The references below add recent work on evolutionary and reinforcement-learning approaches for jailbreaking large language models (LLMs).

- [When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search](https://www.semanticscholar.org/paper/ff9854d4323e75252fec985d411f3b058eb718bf) – integrates deep reinforcement learning with evolutionary search to optimize jailbreaks.
- [PathSeeker: Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach](https://www.semanticscholar.org/paper/26c1431f46f90b29b4ee8522ebce92de68068cbb) – uses RL and evolutionary heuristics to uncover new attack vectors.
- [Jailbreak Distillation: Renewable Safety Benchmarking](https://www.semanticscholar.org/paper/57d7977bb8ae533de61a317d907d8fa505ed1af3) – proposes an iterative distillation method to maintain an evolving set of jailbreak prompts.
- [Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models](https://www.semanticscholar.org/paper/6e35a9a0a5dd54caee0b0cce7271599280dc1ce8) – explores prompt evolution guided by semantic feedback.
- [Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses](https://www.semanticscholar.org/paper/868eb1e4fe90ec7c9f375d2e4b15b183c08e8f59) – surveys advances in evolutionary jailbreak techniques and countermeasures.
- [JailbreakLens: Interpreting Jailbreak Mechanisms in the Lens of Representation and Circuit](https://www.semanticscholar.org/paper/48feacb8b9567e9a03eea85656e6233d19ea4a14) – applies evolutionary methods to visualize adversarial prompt circuits.
- [A Hitchhiker's Guide to Jailbreaking ChatGPT via Prompt Engineering](https://www.semanticscholar.org/paper/da9e8b168817b4101fc166a11b2db74d7cafcbd9) – covers practical attacks including evolutionary prompt mutation.
- [JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large Language and Vision-Language Models](https://www.semanticscholar.org/paper/027ac1dad95fa9f42c5e9d00a4de31214f437604) – comprehensive survey summarizing evolutionary and genetic algorithm strategies.
The references below expand the catalog with further coverage of evolutionary and genetic algorithm approaches for jailbreaking large language models (LLMs) and related defenses.

- [GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts](https://arxiv.org/abs/2309.10253) – introduces a fuzzing framework that mutates seed prompts similar to genetic algorithms to systematically discover jailbreaks.
- [MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots](https://arxiv.org/abs/2307.08715) – evolves prompts that transfer across different LLM chatbots.
- [Improved Techniques for Optimization-Based Jailbreaking on Large Language Models](https://arxiv.org/abs/2405.21018) – refines gradient and evolutionary search strategies for automated attacks.
- [AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens](https://arxiv.org/abs/2406.03805) – analyzes evolutionary-style prompt mutation across dependency chains.
- [Learn to Disguise: Avoid Refusal Responses in LLM’s Defense via a Multi-Agent Attacker-Disguiser Game](https://arxiv.org/abs/2404.02532) – applies multi-agent optimization that iteratively disguises prompts.
- [Maatphor: Automated Variant Analysis for Prompt Injection Attacks](https://arxiv.org/abs/2312.11513) – performs large-scale mutation analysis of jailbreak prompts.
- [Cross-Modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models](https://arxiv.org/abs/2407.21659) – proposes detection techniques targeting evolved multimodal jailbreaks.
- [Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation](https://arxiv.org/abs/2310.06987) – demonstrates iterative attacks that adapt prompts through search.
- [LAGO: Few-shot Cross-Lingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization](https://arxiv.org/abs/2505.16008) – explores optimization-based jailbreaks with graph search.
- [Exploring the Impact of LLM Assisted Malware Variants on Anti-Virus Detection](https://doi.org/10.1109/dsc63325.2024.00027) – evaluates the security implications of evolutionary malware generated with LLM help.
- [From LLMs to MLLMs: Exploring Multi-modal Jailbreak Attacks via the Contribution of Visual Features](https://arxiv.org/abs/2406.14859) – shows how evolutionary search can adapt multimodal prompts.
- [An LLM-Empowered Adaptive Evolutionary Algorithm for Multi-Component Deep Learning Systems](https://doi.org/10.1609/aaai.v39i19.34303) – discusses evolutionary optimization with LLM guidance, relevant for advanced jailbreak tactics.
