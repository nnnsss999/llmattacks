---
title: "Evolutionary Algorithm Resources 2033"
category: "Optimization"
source_url: ""
date_collected: 2025-06-24
license: "CC-BY-4.0"
---

The references below add to the catalog of genetic and evolutionary algorithm approaches for jailbreaking large language models (LLMs). These works highlight community efforts, research projects and public vulnerability databases published after the 2025 snapshot.

- [Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities](https://www.microsoft.com/en-us/research/publication/iterative-self-tuning-llms-for-enhanced-jailbreaking-capabilities/) – Microsoft researchers explore evolutionary feedback loops to automatically refine jailbreak prompts.
- [HackEvolve](https://devpost.com/software/hackevolve) – Devpost project demonstrating an evolutionary coding agent that evolves jailbreak prompts over hundreds of generations.
- [15 LLM Jailbreaks That Shook AI Safety](https://medium.com/@nirdiamant21/15-llm-jailbreaks-that-shook-ai-safety-981d2796d5c6) – article describing notable jailbreak techniques, including those that use genetic algorithms to craft prompts.
- [Awesome-Jailbreak-on-LLMs](https://github.com/yueliu1999/Awesome-Jailbreak-on-LLMs) – GitHub repository curating state-of-the-art jailbreak methods, with dedicated sections on evolutionary prompt search.
- [Evolutionary LLM Jailbreak | LLM Security Database](https://www.promptfoo.dev/lm-security-db/vuln/undefined-d8228765) – database entry summarizing evolutionary algorithm vulnerabilities and mitigation tips.

These resources demonstrate the ongoing evolution of automated jailbreak techniques and associated defenses.
