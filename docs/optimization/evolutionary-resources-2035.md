---
title: "Evolutionary Algorithm Resources 2035"
category: "Optimization"
source_url: ""
date_collected: 2025-06-26
license: "CC-BY-4.0"
---

The references below consolidate additional research and community materials on evolutionary and genetic algorithm approaches for jailbreaking large language models (LLMs). These items expand on prior catalogs, highlighting recent surveys, open-source code, and multi-modal attacks.

- [Open Sesame: Universal Black Box Jailbreaking with Genetic Algorithms](https://arxiv.org/abs/2309.01446) – iteratively evolves prompts to maximize harmful responses across models.
- [AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens](https://arxiv.org/abs/2406.03805) – analyzes GA-based prompt mutation chains and proposes defenses.
- [LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models](https://arxiv.org/abs/2501.00055) – demonstrates gradient-guided evolutionary search for transferable jailbreaks.
- [BlackDAN: A Black-Box Multi-Objective Approach for Effective and Stealthy LLM Jailbreaks](https://arxiv.org/abs/2410.09804) – employs multi-objective genetic algorithms for robust attacks.
- [GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance](https://www.semanticscholar.org/paper/65e33981255b65215e9ceffc433cb4c7ad050d79) – adapts evolutionary strategies to exploit specialized LLMs.
- [MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots](https://arxiv.org/abs/2307.08715) – uses evolutionary search to reverse engineer model defenses.
- [GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts](https://arxiv.org/abs/2309.10253) – applies genetic mutations to fuzz prompts and uncover vulnerabilities.
- [Jailbreak Attacks and Defenses Against Large Language Models: A Survey](https://arxiv.org/abs/2407.04295) – comprehensive survey including evolutionary attack frameworks.
- [Adaptive Strategy Evolution for Generating Tailored Jailbreaks](https://openreview.net/forum?id=xF5st2HtYP) – proposes self-adapting genetic strategies for customized prompts.
- [PromptBreeder Evolves & Adapts Prompts For A Given Domain](https://cobusgreyling.medium.com/promptbreeder-evolves-adapts-prompts-for-a-given-domain-7d7bf75b5555) – demonstrates domain-specific prompt evolution using genetic algorithms.

The references below add more coverage of evolutionary algorithm approaches for jailbreaking large language models (LLMs).

- [Paper - RED QUEEN : Safeguarding LLMs against Concealed Multi-Turn Jailbreaking](https://www.youtube.com/watch?v=5y-xPiqrToo) – overview of a multi-turn jailbreak method and corresponding mitigation strategy.
- [AI Jailbreaking Demo: How Prompt Engineering Bypasses LLM Security Measures](https://www.youtube.com/watch?v=F_KychntktU) – demonstration of iterative prompt evolution to evade safeguards.
- [The Secrets of Jailbreaking LLMs // Ron Heichman // MLOps Podcast #252 clip](https://www.youtube.com/watch?v=RgL3NwOE64M) – discussion of automated jailbreak frameworks including genetic approaches.
- [Jailbreaking Large Language Models: Techniques, Examples, Prevention Methods](https://www.lakera.ai/blog/jailbreaking-large-language-models-guide) – blog covering state-of-the-art attacks and defenses such as evolutionary search.
- [How to Automatically Jailbreak OpenAI's o1 (Case Studies)](https://artificialintelligencemadesimple.substack.com/p/how-to-automatically-jailbreak-openais) – case studies of automated jailbreaks using evolutionary optimization.
