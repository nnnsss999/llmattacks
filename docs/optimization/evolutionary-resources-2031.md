---
title: "Evolutionary Algorithm Resources 2031"
category: "Optimization"
source_url: ""
date_collected: 2025-06-22
license: "CC-BY-4.0"
---

The resources below extend the catalog with additional coverage of evolutionary and genetic algorithm attacks against large language models (LLMs).

- [How to Jailbreak LLMs One Step at a Time: Top Techniques and Strategies](https://www.confident-ai.com/blog/how-to-jailbreak-llms-one-step-at-a-time) – overview of practical jailbreak tactics, including automated prompt evolution.
- [Jailbreaking Large Language Models: If You Torture the Model Long Enough, It Will Confess!](https://medium.com/the-generator/jailbreaking-large-language-models-if-you-torture-the-model-long-enough-it-will-confess-55e910ee2c3c) – discusses evolving adversarial token streams with a fitness-based approach.
- [How to Automatically Jailbreak OpenAI's o1 (Case Studies)](https://artificialintelligencemadesimple.substack.com/p/how-to-automatically-jailbreak-openais) – describes evolutionary techniques for generating jailbreak prompts.
- [Literature Review: LLM-Virus – Evolutionary Jailbreak Attack on Large Language Models](https://www.themoonlight.io/en/review/llm-virus-evolutionary-jailbreak-attack-on-large-language-models) – independent analysis of the LLM-Virus framework.
- [How to Protect LLMs from Jailbreaking Attacks](https://www.boozallen.com/insights/ai-research/how-to-protect-llms-from-jailbreaking-attacks.html) – highlights defenses against emerging evolutionary jailbreak methods.
- [Evolutionary Computation in the Era of Large Language Models: Survey and Roadmap](https://arxiv.org/abs/2401.10034) – survey connecting evolutionary computation and LLM-based optimization, including jailbreak use cases.
- [Evolving Code with a Large Language Model](https://arxiv.org/abs/2401.07102) – demonstrates LLM-guided evolutionary algorithms that can adapt to jailbreak tasks.
