---
title: "Evolutionary Algorithm Resources 2038"
category: "Optimization"
source_url: ""
date_collected: 2025-06-29
license: "CC-BY-4.0"
---

The references below provide further research and community projects on evolutionary and genetic algorithm techniques for jailbreaking large language models (LLMs). These resources extend the catalog beyond the 2037 snapshot.

- [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – introduces RA-LLM, a framework that checks alignment and mitigates evolving attacks.
- [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – describes random perturbation and aggregation to detect genetic prompt variants.
- [Self-Guard: Empower the LLM to Safeguard Itself](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – two-stage approach where the model evaluates prompts and reinforces its own defenses.
- [Jailbreaker in Jail: Moving Target Defense for Large Language Models](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – proposes dynamic model switching to counter iterative jailbreak attempts.
- [Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – explores in-context strategies for evolving jailbreaks and defenses.
- [Shield and Spear: Jailbreaking Aligned LLMs with Generative Prompting](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – shows how generative attackers can iteratively refine adversarial prompts.
- [Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – demonstrates deceptive prompt evolution that bypasses content filters.
- [Baseline Defenses for Adversarial Attacks Against Aligned Language Models](https://docs.kanaries.net/topics/ChatGPT/llm-jailbreak-papers) – summarizes early defensive baselines evaluated against genetic attacks.
- [Genetic Prompt Compiler](https://github.com/Antonin-Deniau/genetic_prompt_compiler) – open-source project optimizing prompts with a genetic algorithm.
- [Genetic-Algo-Prompt-Engineering](https://github.com/AlejandroSalamancaRuiz/Genetic-Algo-Prompt-Engineering) – experiments using GAs to discover effective prompt sequences.
- [Genetic_Algorithm_Prompt_Engineering](https://github.com/clalanliu/Genetic_Algorithm_Prompt_Engineering) – repository exploring GA-based prompt search.
- [gallm](https://github.com/leloss/gallm) – LLM-guided genetic algorithm framework for automated prompt engineering.
- [Darwin](https://github.com/PeytonCleveland/Darwin) – implements evolutionary prompt evolution based on Evol-Instruct.
- [PromptPilot](https://github.com/doganarif/promptpilot) – CLI tool for tracking prompt evolution and optimization across models.
- [Instruction-Fusion](https://github.com/XpastaX/Instruction-Fusion) – hybrid approach combining multiple evolutionary strategies for prompt refinement.
- [LLM-Prompt-Evolution](https://github.com/Binary67/LLM-Prompt-Evolution) – demonstrates iterative prompt mutation guided by LLM feedback.
- [semantic-evolution-lab-](https://github.com/Ethermind/semantic-evolution-lab-) – experimental repository on symbolic prompt structures and semantic drift.
