---
title: "AutoDAN: Interpretable Gradient-Based Adversarial Attacks"
category: "Optimization"
source_url: "https://arxiv.org/abs/2310.15140"
date_collected: 2025-06-18
license: "Fair Use"
---
The paper **AutoDAN** introduces an interpretable gradient-based framework for generating jailbreak prompts against large language models. By optimizing perturbations guided by model gradients, AutoDAN produces minimally modified prompts that evade safety filters while preserving semantics. The approach is evaluated in white-box settings and lays groundwork for later automated jailbreak strategies.
