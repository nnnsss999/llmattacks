---
title: "Evolutionary Algorithm Resources 2036"
category: "Optimization"
source_url: ""
date_collected: 2025-06-27
license: "CC-BY-4.0"
---

The references below spotlight additional research articles and reports on evolutionary and genetic algorithm attacks targeting large language models (LLMs). These sources surfaced after the 2035 snapshot and document ongoing adversarial techniques and countermeasures.

- [WormGPT Returns: How AI Jailbreaks Are Fueling Next-Gen Cyberattacks](https://undercodetesting.com/wormgpt-returns-how-ai-jailbreaks-are-fueling-next-gen-cyberattacks/) – article discussing the resurgence of WormGPT and genetic prompt evolution.
- [AI Jailbreaks: What They Are and How They Can Be Mitigated](https://www.microsoft.com/en-us/security/blog/2024/06/04/ai-jailbreaks-what-they-are-and-how-they-can-be-mitigated/) – Microsoft blog outlining mitigation strategies for evolving jailbreaks.
- [The Big List of AI Jailbreaking References and Resources](https://briandcolwell.com/the-big-list-of-ai-jailbreaking-references-and-resources/) – curated compilation of jailbreak techniques including GA-based approaches.
- [Grok and Mixtral AI Models Hijacked by WormGPT Clones via Prompt Jailbreaks](https://winbuzzer.com/2025/06/18/grok-and-mixtral-ai-models-hijacked-by-wormgpt-clones-via-prompt-jailbreaks-xcxwbn/) – news report on how wormgpt variants exploit prompts using evolutionary methods.
- [New CCA Jailbreak Method Works Against Most AI Models](https://www.securityweek.com/new-cca-jailbreak-method-works-against-most-ai-models/) – coverage of a cross-context attack showing broad effectiveness.
- [Generative AI Jailbreaks: Catching Up with the Latest Exploits](https://osintteam.blog/generative-ai-jailbreaks-catching-up-with-the-latest-exploits-158df5cd1ea6) – blog post reviewing current exploit patterns based on genetic optimization.
- [Understanding the Complexity of Jailbreaks in the Era of Generative AI](https://techstrong.ai/articles/understanding-the-complexity-of-jailbreaks-in-the-era-of-generative-ai/) – analysis exploring new evolutionary strategies for bypassing safeguards.
- [HackEvolve](https://devpost.com/software/hackevolve) – community competition showcasing genetic algorithm frameworks for LLM jailbreaks.
