---
title: "Evolutionary Algorithm Resources 2037"
category: "Optimization"
source_url: ""
date_collected: 2025-06-28
license: "CC-BY-4.0"
---

The references below compile newly surfaced papers and articles on evolutionary and genetic algorithm approaches for jailbreaking or defending large language models (LLMs). These sources expand the catalog beyond the 2036 snapshot.

- [Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers](https://openreview.net/forum?id=ZG3RaNIsO8) – explores hybrid approaches where LLMs guide GA search for optimized jailbreak prompts.
- [XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](https://arxiv.org/abs/2504.21700) – proposes explainable evolutionary techniques to craft and analyze attacks.
- [Jailbreaking large language models: models, origins, and evolution of attacks and defenses](https://www.sciengine.com/doi/10.1360/SSI-2024-0196) – survey detailing how genetic algorithms drive modern jailbreak methods.
- [Explaining LLM Insecurity: Why We Can Jailbreak Every Major Model](https://www.cdotrends.com/story/4568/explaining-llm-insecurity-why-we-can-jailbreak-every-major-model) – news coverage highlighting GA-based fuzzing frameworks that compromise major models.
- [Anthropic has a new way to protect large language models against jailbreaks](https://www.technologyreview.com/2025/02/03/1110849/anthropic-has-a-new-way-to-protect-large-language-models-against-jailbreaks/) – discusses countermeasures against evolving genetic attacks.
- [LLM Jailbreak Detection Guide 2025](https://www.onlinehashcrack.com/guides/ai-security/llm-jailbreak-detection-guide-2025.php) – guide to spotting evolutionary prompt manipulation and injection attempts.
- [Breaking the Rules: Jailbreak Attacks on Large Language Models](https://www.fuzzylabs.ai/blog-post/jailbreak-attacks-on-large-language-models) – technical blog outlining GA-based search strategies and their defenses.
- [Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring](https://aclanthology.org/2025.naacl-long.88.pdf) – introduces a mirroring technique that can bootstrap evolutionary jailbreak discovery.
