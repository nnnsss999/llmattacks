---
title: "Evolutionary Algorithm Resources 2030"
category: "Optimization"
source_url: ""
date_collected: 2025-06-21
license: "CC-BY-4.0"
---

The following references expand on genetic and evolutionary algorithm techniques used to jailbreak or subvert large language models (LLMs) beyond the 2025 snapshot.

- [Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models](https://huggingface.co/papers/2501.01830) – proposes progressive reward tracking with evolutionary search.
- [RLBreaker: When LLM Meets DRL](https://proceedings.neurips.cc/paper_files/paper/2024/hash/2f1486343c2c942a617e4f5bb0cc64c8-Abstract-Conference.html) – combines deep reinforcement learning with genetic algorithms for efficient attacks.
- [Adaptive Strategy Evolution for Generating Tailored Jailbreaks](https://openreview.net/forum?id=xF5st2HtYP) – explores genetic strategies for customizing jailbreak prompts.
- [Genetic Scenario Shift Jailbreak | LLM Security Database](https://www.promptfoo.dev/lm-security-db/vuln/genetic-scenario-shift-jailbreak-2588802d) – documents black-box attacks using optimized scenario shifts.
- [Auto-Ea-Jailbreak](https://github.com/LoganBolton/Auto-Ea-Jailbreak) – open-source project evolving jailbreak prompts for robust model exploitation.

These additions illustrate the continued development of evolutionary approaches for automated prompt generation and model compromise.
